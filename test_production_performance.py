#!/usr/bin/env python3
"""
ç”Ÿäº§ç¯å¢ƒæ€§èƒ½æµ‹è¯•è„šæœ¬

æµ‹è¯•åˆ†è¡¨æ¨¡å¼åœ¨ç”Ÿäº§ç¯å¢ƒä¸‹çš„æŸ¥è¯¢æ€§èƒ½å’Œç¨³å®šæ€§
"""

import argparse
import time
import statistics
from pathlib import Path
from sqlalchemy import create_engine, text
import pandas as pd
from concurrent.futures import ThreadPoolExecutor, as_completed

class PerformanceTester:
    def __init__(self, dsn, view_name='clips_bbox_unified'):
        self.dsn = dsn
        self.view_name = view_name
        self.eng = create_engine(dsn, future=True)
        self.test_results = []
    
    def execute_query_with_timing(self, query_name, sql_query, iterations=3):
        """æ‰§è¡ŒæŸ¥è¯¢å¹¶è®°å½•æ€§èƒ½"""
        print(f"\nğŸ” æµ‹è¯•æŸ¥è¯¢: {query_name}")
        
        times = []
        results = []
        
        for i in range(iterations):
            try:
                start_time = time.time()
                
                with self.eng.connect() as conn:
                    result = conn.execute(text(sql_query))
                    rows = result.fetchall()
                
                end_time = time.time()
                execution_time = end_time - start_time
                times.append(execution_time)
                results.append(len(rows))
                
                print(f"  ç¬¬{i+1}æ¬¡: {execution_time:.2f}ç§’ ({len(rows)}æ¡è®°å½•)")
                
            except Exception as e:
                print(f"  ç¬¬{i+1}æ¬¡: å¤±è´¥ - {str(e)}")
                times.append(None)
                results.append(0)
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        valid_times = [t for t in times if t is not None]
        if valid_times:
            avg_time = statistics.mean(valid_times)
            min_time = min(valid_times)
            max_time = max(valid_times)
            
            print(f"  ğŸ“Š å¹³å‡: {avg_time:.2f}ç§’, æœ€å¿«: {min_time:.2f}ç§’, æœ€æ…¢: {max_time:.2f}ç§’")
            
            self.test_results.append({
                'query_name': query_name,
                'avg_time': avg_time,
                'min_time': min_time,
                'max_time': max_time,
                'success_rate': len(valid_times) / iterations,
                'avg_records': statistics.mean([r for r in results if r > 0]) if results else 0
            })
            
            return True
        else:
            print(f"  âŒ æ‰€æœ‰æŸ¥è¯¢éƒ½å¤±è´¥äº†")
            return False
    
    def test_basic_queries(self):
        """æµ‹è¯•åŸºç¡€æŸ¥è¯¢æ€§èƒ½"""
        print("ğŸ¯ åŸºç¡€æŸ¥è¯¢æ€§èƒ½æµ‹è¯•")
        print("=" * 60)
        
        queries = [
            {
                "name": "æ€»è®°å½•æ•°ç»Ÿè®¡",
                "sql": f"SELECT COUNT(*) FROM {self.view_name};"
            },
            {
                "name": "å­æ•°æ®é›†ç»Ÿè®¡",
                "sql": f"""
                    SELECT subdataset_name, COUNT(*) as count 
                    FROM {self.view_name} 
                    GROUP BY subdataset_name 
                    ORDER BY count DESC;
                """
            },
            {
                "name": "æœ‰æ•ˆæ•°æ®ç»Ÿè®¡",
                "sql": f"""
                    SELECT all_good, COUNT(*) as count 
                    FROM {self.view_name} 
                    GROUP BY all_good;
                """
            },
            {
                "name": "å‡ ä½•æ•°æ®ç»Ÿè®¡",
                "sql": f"""
                    SELECT 
                        COUNT(*) as total,
                        COUNT(geometry) as with_geometry
                    FROM {self.view_name};
                """
            }
        ]
        
        for query in queries:
            self.execute_query_with_timing(query["name"], query["sql"])
    
    def test_spatial_queries(self):
        """æµ‹è¯•ç©ºé—´æŸ¥è¯¢æ€§èƒ½"""
        print("\nğŸ—ºï¸  ç©ºé—´æŸ¥è¯¢æ€§èƒ½æµ‹è¯•")
        print("=" * 60)
        
        # å…ˆè·å–æ•°æ®èŒƒå›´
        bbox_query = f"""
            SELECT 
                ST_XMin(ST_Extent(geometry)) as min_x,
                ST_YMin(ST_Extent(geometry)) as min_y,
                ST_XMax(ST_Extent(geometry)) as max_x,
                ST_YMax(ST_Extent(geometry)) as max_y
            FROM {self.view_name} 
            WHERE geometry IS NOT NULL;
        """
        
        try:
            with self.eng.connect() as conn:
                result = conn.execute(text(bbox_query))
                bbox = result.fetchone()
                if bbox:
                    min_x, min_y, max_x, max_y = bbox
                    print(f"ğŸ“ æ•°æ®èŒƒå›´: X({min_x:.6f}, {max_x:.6f}) Y({min_y:.6f}, {max_y:.6f})")
                    
                    # è®¡ç®—æµ‹è¯•åŒºåŸŸï¼ˆä¸­å¿ƒåŒºåŸŸçš„1/4ï¼‰
                    center_x = (min_x + max_x) / 2
                    center_y = (min_y + max_y) / 2
                    quarter_width = (max_x - min_x) / 4
                    quarter_height = (max_y - min_y) / 4
                    
                    test_queries = [
                        {
                            "name": "ç©ºé—´èŒƒå›´æŸ¥è¯¢ï¼ˆä¸­å¿ƒ1/4åŒºåŸŸï¼‰",
                            "sql": f"""
                                SELECT COUNT(*) 
                                FROM {self.view_name} 
                                WHERE ST_Intersects(
                                    geometry, 
                                    ST_MakeEnvelope({center_x - quarter_width}, {center_y - quarter_height}, 
                                                   {center_x + quarter_width}, {center_y + quarter_height}, 4326)
                                );
                            """
                        },
                        {
                            "name": "ç©ºé—´è·ç¦»æŸ¥è¯¢ï¼ˆ500ç±³ç¼“å†²åŒºï¼‰",
                            "sql": f"""
                                SELECT COUNT(*) 
                                FROM {self.view_name} 
                                WHERE ST_DWithin(
                                    geometry::geography, 
                                    ST_Point({center_x}, {center_y})::geography, 
                                    500
                                );
                            """
                        },
                        {
                            "name": "è¾¹ç•Œæ¡†æå–",
                            "sql": f"""
                                SELECT 
                                    ST_XMin(geometry) as min_x,
                                    ST_YMin(geometry) as min_y,
                                    ST_XMax(geometry) as max_x,
                                    ST_YMax(geometry) as max_y
                                FROM {self.view_name} 
                                WHERE geometry IS NOT NULL 
                                LIMIT 1000;
                            """
                        }
                    ]
                    
                    for query in test_queries:
                        self.execute_query_with_timing(query["name"], query["sql"])
                        
        except Exception as e:
            print(f"âŒ è·å–æ•°æ®èŒƒå›´å¤±è´¥: {str(e)}")
    
    def test_filtering_queries(self):
        """æµ‹è¯•è¿‡æ»¤æŸ¥è¯¢æ€§èƒ½"""
        print("\nğŸ” è¿‡æ»¤æŸ¥è¯¢æ€§èƒ½æµ‹è¯•")
        print("=" * 60)
        
        # å…ˆè·å–ä¸€äº›å­æ•°æ®é›†åç§°
        try:
            with self.eng.connect() as conn:
                result = conn.execute(text(f"""
                    SELECT subdataset_name, COUNT(*) as count
                    FROM {self.view_name} 
                    GROUP BY subdataset_name 
                    ORDER BY count DESC 
                    LIMIT 5;
                """))
                top_subdatasets = result.fetchall()
                
                if top_subdatasets:
                    # ä½¿ç”¨ç¬¬ä¸€ä¸ªå­æ•°æ®é›†è¿›è¡Œæµ‹è¯•
                    test_subdataset = top_subdatasets[0][0]
                    
                    filter_queries = [
                        {
                            "name": f"æŒ‰å­æ•°æ®é›†è¿‡æ»¤ ({test_subdataset})",
                            "sql": f"""
                                SELECT COUNT(*) 
                                FROM {self.view_name} 
                                WHERE subdataset_name = '{test_subdataset}';
                            """
                        },
                        {
                            "name": "æŒ‰æœ‰æ•ˆæ€§è¿‡æ»¤ (all_good=true)",
                            "sql": f"""
                                SELECT COUNT(*) 
                                FROM {self.view_name} 
                                WHERE all_good = true;
                            """
                        },
                        {
                            "name": "ç»„åˆè¿‡æ»¤ (å­æ•°æ®é›†+æœ‰æ•ˆæ€§)",
                            "sql": f"""
                                SELECT COUNT(*) 
                                FROM {self.view_name} 
                                WHERE subdataset_name = '{test_subdataset}' 
                                AND all_good = true;
                            """
                        },
                        {
                            "name": "æ¨¡ç³ŠåŒ¹é…è¿‡æ»¤",
                            "sql": f"""
                                SELECT COUNT(*) 
                                FROM {self.view_name} 
                                WHERE subdataset_name LIKE '%{test_subdataset[:10]}%';
                            """
                        }
                    ]
                    
                    for query in filter_queries:
                        self.execute_query_with_timing(query["name"], query["sql"])
                        
        except Exception as e:
            print(f"âŒ è¿‡æ»¤æŸ¥è¯¢æµ‹è¯•å¤±è´¥: {str(e)}")
    
    def test_concurrent_queries(self, max_workers=4):
        """æµ‹è¯•å¹¶å‘æŸ¥è¯¢æ€§èƒ½"""
        print(f"\nğŸš€ å¹¶å‘æŸ¥è¯¢æ€§èƒ½æµ‹è¯• ({max_workers} workers)")
        print("=" * 60)
        
        # å‡†å¤‡å¹¶å‘æŸ¥è¯¢
        concurrent_queries = [
            f"SELECT COUNT(*) FROM {self.view_name} WHERE all_good = true;",
            f"SELECT COUNT(*) FROM {self.view_name} WHERE all_good = false;",
            f"SELECT COUNT(DISTINCT subdataset_name) FROM {self.view_name};",
            f"SELECT COUNT(*) FROM {self.view_name} WHERE geometry IS NOT NULL;"
        ]
        
        def execute_single_query(query_idx, sql):
            try:
                start_time = time.time()
                eng = create_engine(self.dsn, future=True)
                with eng.connect() as conn:
                    result = conn.execute(text(sql))
                    rows = result.fetchall()
                end_time = time.time()
                return {
                    'query_idx': query_idx,
                    'execution_time': end_time - start_time,
                    'success': True,
                    'record_count': len(rows)
                }
            except Exception as e:
                return {
                    'query_idx': query_idx,
                    'execution_time': None,
                    'success': False,
                    'error': str(e)
                }
        
        start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = []
            for i, query in enumerate(concurrent_queries):
                future = executor.submit(execute_single_query, i, query)
                futures.append(future)
            
            results = []
            for future in as_completed(futures):
                result = future.result()
                results.append(result)
        
        total_time = time.time() - start_time
        
        successful_results = [r for r in results if r['success']]
        failed_results = [r for r in results if not r['success']]
        
        print(f"  ğŸ“Š æ€»ä½“æ—¶é—´: {total_time:.2f}ç§’")
        print(f"  âœ… æˆåŠŸæŸ¥è¯¢: {len(successful_results)}/{len(concurrent_queries)}")
        
        if successful_results:
            avg_time = statistics.mean([r['execution_time'] for r in successful_results])
            print(f"  â±ï¸  å¹³å‡æŸ¥è¯¢æ—¶é—´: {avg_time:.2f}ç§’")
        
        if failed_results:
            print(f"  âŒ å¤±è´¥æŸ¥è¯¢: {len(failed_results)}")
            for result in failed_results:
                print(f"    æŸ¥è¯¢{result['query_idx']}: {result.get('error', 'Unknown error')}")
    
    def generate_performance_report(self):
        """ç”Ÿæˆæ€§èƒ½æµ‹è¯•æŠ¥å‘Š"""
        print("\nğŸ“Š æ€§èƒ½æµ‹è¯•æŠ¥å‘Š")
        print("=" * 60)
        
        if not self.test_results:
            print("âŒ æ²¡æœ‰æµ‹è¯•ç»“æœå¯æŠ¥å‘Š")
            return
        
        # æŒ‰æ€§èƒ½æ’åº
        sorted_results = sorted(self.test_results, key=lambda x: x['avg_time'])
        
        print(f"{'æŸ¥è¯¢åç§°':<30} {'å¹³å‡æ—¶é—´':<10} {'æˆåŠŸç‡':<8} {'è®°å½•æ•°':<10}")
        print("-" * 60)
        
        for result in sorted_results:
            avg_time = f"{result['avg_time']:.2f}s"
            success_rate = f"{result['success_rate']*100:.0f}%"
            avg_records = f"{result['avg_records']:.0f}"
            
            print(f"{result['query_name']:<30} {avg_time:<10} {success_rate:<8} {avg_records:<10}")
        
        # æ€§èƒ½è¯„ä¼°
        print(f"\nğŸ¯ æ€§èƒ½è¯„ä¼°:")
        fast_queries = [r for r in self.test_results if r['avg_time'] < 1.0]
        slow_queries = [r for r in self.test_results if r['avg_time'] > 5.0]
        
        print(f"  - å¿«é€ŸæŸ¥è¯¢ï¼ˆ<1ç§’ï¼‰: {len(fast_queries)} ä¸ª")
        print(f"  - æ…¢æŸ¥è¯¢ï¼ˆ>5ç§’ï¼‰: {len(slow_queries)} ä¸ª")
        
        if slow_queries:
            print(f"  âš ï¸  éœ€è¦ä¼˜åŒ–çš„æ…¢æŸ¥è¯¢:")
            for query in slow_queries:
                print(f"    - {query['query_name']}: {query['avg_time']:.2f}ç§’")

def main():
    parser = argparse.ArgumentParser(description="ç”Ÿäº§ç¯å¢ƒæ€§èƒ½æµ‹è¯•")
    parser.add_argument('--dsn', default='postgresql+psycopg://postgres:postgres@local_pg:5432/postgres',
                       help='æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²')
    parser.add_argument('--view-name', default='clips_bbox_unified', help='ç»Ÿä¸€è§†å›¾åç§°')
    parser.add_argument('--iterations', type=int, default=3, help='æ¯ä¸ªæŸ¥è¯¢çš„é‡å¤æ¬¡æ•°')
    parser.add_argument('--concurrent-workers', type=int, default=4, help='å¹¶å‘æŸ¥è¯¢workeræ•°é‡')
    parser.add_argument('--skip-spatial', action='store_true', help='è·³è¿‡ç©ºé—´æŸ¥è¯¢æµ‹è¯•')
    parser.add_argument('--skip-concurrent', action='store_true', help='è·³è¿‡å¹¶å‘æŸ¥è¯¢æµ‹è¯•')
    
    args = parser.parse_args()
    
    print("ğŸ­ ç”Ÿäº§ç¯å¢ƒæ€§èƒ½æµ‹è¯•å¼€å§‹")
    print("=" * 60)
    
    tester = PerformanceTester(args.dsn, args.view_name)
    
    # åŸºç¡€æŸ¥è¯¢æµ‹è¯•
    tester.test_basic_queries()
    
    # ç©ºé—´æŸ¥è¯¢æµ‹è¯•
    if not args.skip_spatial:
        tester.test_spatial_queries()
    
    # è¿‡æ»¤æŸ¥è¯¢æµ‹è¯•
    tester.test_filtering_queries()
    
    # å¹¶å‘æŸ¥è¯¢æµ‹è¯•
    if not args.skip_concurrent:
        tester.test_concurrent_queries(args.concurrent_workers)
    
    # ç”ŸæˆæŠ¥å‘Š
    tester.generate_performance_report()
    
    print("\nâœ… ç”Ÿäº§ç¯å¢ƒæ€§èƒ½æµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    main() 