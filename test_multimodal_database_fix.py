#!/usr/bin/env python3
"""
å¤šæ¨¡æ€è½¨è¿¹æ£€ç´¢æ•°æ®åº“ä¿®å¤éªŒè¯æµ‹è¯•è„šæœ¬

æ­¤è„šæœ¬ç”¨äºå…¨é¢æµ‹è¯•æ•°æ®åº“é…ç½®ä¿®å¤åçš„å¤šæ¨¡æ€è½¨è¿¹æ£€ç´¢åŠŸèƒ½ï¼š
1. éªŒè¯æ•°æ®åº“è¿æ¥æ˜¯å¦æ­£å¸¸
2. æµ‹è¯•è½¨è¿¹è¡¨åˆ›å»ºåŠŸèƒ½
3. æ‰§è¡Œå®Œæ•´çš„å¤šæ¨¡æ€è½¨è¿¹æ£€ç´¢æµç¨‹
4. éªŒè¯ç»“æœä¿å­˜åˆ°æ•°æ®åº“

ä½¿ç”¨æ–¹æ³•:
python test_multimodal_database_fix.py [--quick] [--cleanup]

å‚æ•°:
--quick: å¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼Œè·³è¿‡è€—æ—¶çš„æ£€ç´¢è¿‡ç¨‹
--cleanup: æµ‹è¯•åæ¸…ç†åˆ›å»ºçš„æµ‹è¯•è¡¨
"""

import argparse
import sys
import logging
import subprocess
import time
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional

import psycopg
from sqlalchemy import create_engine, text

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class MultimodalDatabaseTester:
    """å¤šæ¨¡æ€æ•°æ®åº“åŠŸèƒ½æµ‹è¯•å™¨"""
    
    def __init__(self, quick_mode: bool = False, cleanup: bool = False):
        self.quick_mode = quick_mode
        self.cleanup = cleanup
        self.test_table = f"test_discovered_trajectories_{int(time.time())}"
        
        # æµ‹è¯•é…ç½®
        self.db_configs = [
            "postgresql+psycopg://postgres:postgres@localhost:5432/postgres",
            "postgresql+psycopg://postgres:postgres@127.0.0.1:5432/postgres"
        ]
        
        self.working_engine = None
        
        self.test_results = {
            'database_connection': False,
            'table_creation': False,
            'multimodal_execution': False,
            'data_saved': False,
            'execution_time': 0,
            'error_messages': [],
            'recommendations': []
        }
    
    def run_comprehensive_test(self) -> Dict[str, Any]:
        """è¿è¡Œç»¼åˆæµ‹è¯•"""
        logger.info("ğŸ§ª å¼€å§‹å¤šæ¨¡æ€è½¨è¿¹æ£€ç´¢æ•°æ®åº“ä¿®å¤éªŒè¯")
        logger.info(f"   æµ‹è¯•æ¨¡å¼: {'å¿«é€Ÿ' if self.quick_mode else 'å®Œæ•´'}")
        logger.info(f"   æµ‹è¯•è¡¨å: {self.test_table}")
        
        start_time = time.time()
        
        try:
            # æ­¥éª¤1: æµ‹è¯•æ•°æ®åº“è¿æ¥
            if not self.test_database_connection():
                return self.test_results
            
            # æ­¥éª¤2: æµ‹è¯•è¡¨åˆ›å»ºåŠŸèƒ½
            if not self.test_table_creation():
                return self.test_results
            
            # æ­¥éª¤3: æµ‹è¯•å¤šæ¨¡æ€è½¨è¿¹æ£€ç´¢
            if not self.test_multimodal_execution():
                return self.test_results
            
            # æ­¥éª¤4: éªŒè¯æ•°æ®ä¿å­˜
            if not self.test_data_verification():
                return self.test_results
            
            self.test_results['execution_time'] = time.time() - start_time
            logger.info(f"âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ€»ç”¨æ—¶: {self.test_results['execution_time']:.2f}ç§’")
            
        except Exception as e:
            logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            self.test_results['error_messages'].append(str(e))
        
        finally:
            # æ¸…ç†æµ‹è¯•æ•°æ®
            if self.cleanup:
                self.cleanup_test_data()
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        self.generate_test_report()
        
        return self.test_results
    
    def test_database_connection(self) -> bool:
        """æµ‹è¯•æ•°æ®åº“è¿æ¥"""
        logger.info("ğŸ”Œ æµ‹è¯•æ•°æ®åº“è¿æ¥...")
        
        for dsn in self.db_configs:
            try:
                logger.info(f"   å°è¯•è¿æ¥: {dsn}")
                engine = create_engine(dsn, future=True)
                
                with engine.connect() as conn:
                    result = conn.execute(text("SELECT version()"))
                    version = result.scalar()
                
                self.working_engine = engine
                self.test_results['database_connection'] = True
                logger.info(f"   âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
                logger.info(f"   PostgreSQLç‰ˆæœ¬: {version[:100]}...")
                return True
                
            except Exception as e:
                logger.warning(f"   âŒ è¿æ¥å¤±è´¥: {e}")
                continue
        
        logger.error("âŒ æ‰€æœ‰æ•°æ®åº“è¿æ¥å‡å¤±è´¥")
        self.test_results['error_messages'].append("æ•°æ®åº“è¿æ¥å¤±è´¥")
        return False
    
    def test_table_creation(self) -> bool:
        """æµ‹è¯•è½¨è¿¹è¡¨åˆ›å»ºåŠŸèƒ½"""
        logger.info("ğŸ—ï¸ æµ‹è¯•è½¨è¿¹è¡¨åˆ›å»ºåŠŸèƒ½...")
        
        if not self.working_engine:
            logger.error("æ²¡æœ‰å¯ç”¨çš„æ•°æ®åº“è¿æ¥")
            return False
        
        try:
            # æ¨¡æ‹Ÿè½¨è¿¹è¡¨åˆ›å»ºSQLï¼ˆæ¥è‡ªpolygon_trajectory_query.pyï¼‰
            create_sql = text(f"""
                CREATE TABLE IF NOT EXISTS {self.test_table} (
                    id serial PRIMARY KEY,
                    scene_id text NOT NULL,
                    dataset_name text NOT NULL,
                    total_points integer DEFAULT 0,
                    total_duration numeric(10,2),
                    start_time bigint,
                    end_time bigint,
                    created_at timestamp DEFAULT CURRENT_TIMESTAMP
                );
            """)
            
            # æ·»åŠ å‡ ä½•åˆ—çš„SQL
            add_geom_sql = text(f"""
                SELECT AddGeometryColumn('public', '{self.test_table}', 'geometry', 4326, 'LINESTRING', 2);
            """)
            
            # æ‰§è¡Œåˆ›å»º
            with self.working_engine.connect() as conn:
                conn.execute(create_sql)
                conn.commit()
                logger.info("   âœ… åŸºç¡€è¡¨åˆ›å»ºæˆåŠŸ")
                
                # å°è¯•æ·»åŠ å‡ ä½•åˆ—ï¼ˆå¯èƒ½å¤±è´¥ï¼Œä½†ä¸å½±å“ä¸»è¦åŠŸèƒ½ï¼‰
                try:
                    conn.execute(add_geom_sql)
                    conn.commit()
                    logger.info("   âœ… å‡ ä½•åˆ—æ·»åŠ æˆåŠŸ")
                except Exception as e:
                    logger.warning(f"   âš ï¸ å‡ ä½•åˆ—æ·»åŠ å¤±è´¥ï¼ˆä¸å½±å“ä¸»è¦åŠŸèƒ½ï¼‰: {e}")
            
            self.test_results['table_creation'] = True
            logger.info(f"   âœ… æµ‹è¯•è¡¨åˆ›å»ºæˆåŠŸ: {self.test_table}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ è¡¨åˆ›å»ºå¤±è´¥: {e}")
            self.test_results['error_messages'].append(f"è¡¨åˆ›å»ºå¤±è´¥: {e}")
            return False
    
    def test_multimodal_execution(self) -> bool:
        """æµ‹è¯•å¤šæ¨¡æ€è½¨è¿¹æ£€ç´¢æ‰§è¡Œ"""
        logger.info("ğŸš€ æµ‹è¯•å¤šæ¨¡æ€è½¨è¿¹æ£€ç´¢æ‰§è¡Œ...")
        
        # æ„å»ºæµ‹è¯•å‘½ä»¤
        cmd_args = [
            sys.executable, "-m", "spdatalab.fusion.multimodal_trajectory_retrieval",
            "--text", "bicycle crossing intersection",
            "--collection", "ddi_collection_camera_encoded_1",
            "--output-table", self.test_table,
            "--verbose"
        ]
        
        if self.quick_mode:
            # å¿«é€Ÿæ¨¡å¼ï¼šæ·»åŠ é™åˆ¶å‚æ•°ï¼ˆå¦‚æœæ”¯æŒçš„è¯ï¼‰
            logger.info("   ä½¿ç”¨å¿«é€Ÿæµ‹è¯•æ¨¡å¼")
        
        try:
            logger.info("   æ‰§è¡Œå‘½ä»¤: " + " ".join(cmd_args))
            
            # æ‰§è¡Œå‘½ä»¤
            result = subprocess.run(
                cmd_args,
                capture_output=True,
                text=True,
                timeout=600 if not self.quick_mode else 180  # å¿«é€Ÿæ¨¡å¼3åˆ†é’Ÿï¼Œå®Œæ•´æ¨¡å¼10åˆ†é’Ÿ
            )
            
            # åˆ†ææ‰§è¡Œç»“æœ
            if result.returncode == 0:
                logger.info("   âœ… å¤šæ¨¡æ€è½¨è¿¹æ£€ç´¢æ‰§è¡ŒæˆåŠŸ")
                self.test_results['multimodal_execution'] = True
                
                # åˆ†æè¾“å‡ºä¿¡æ¯
                if "æ•°æ®åº“ä¿å­˜æˆåŠŸ" in result.stdout:
                    logger.info("   âœ… å‘ç°æ•°æ®åº“ä¿å­˜æˆåŠŸçš„æ—¥å¿—")
                elif "âŒ æ•°æ®åº“ä¿å­˜å¤±è´¥" in result.stdout:
                    logger.warning("   âš ï¸ æ£€æµ‹åˆ°æ•°æ®åº“ä¿å­˜å¤±è´¥")
                    self.test_results['error_messages'].append("å¤šæ¨¡æ€æ‰§è¡Œä¸­æ•°æ®åº“ä¿å­˜å¤±è´¥")
                
                # ä¿å­˜è¾“å‡ºæ—¥å¿—
                self.save_execution_log(result.stdout, result.stderr)
                return True
            else:
                logger.error(f"   âŒ å¤šæ¨¡æ€è½¨è¿¹æ£€ç´¢æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
                if result.stderr:
                    logger.error(f"   é”™è¯¯ä¿¡æ¯: {result.stderr}")
                    self.test_results['error_messages'].append(f"æ‰§è¡Œå¤±è´¥: {result.stderr}")
                
                self.save_execution_log(result.stdout, result.stderr)
                return False
                
        except subprocess.TimeoutExpired:
            logger.error("   âŒ å¤šæ¨¡æ€è½¨è¿¹æ£€ç´¢æ‰§è¡Œè¶…æ—¶")
            self.test_results['error_messages'].append("æ‰§è¡Œè¶…æ—¶")
            return False
        except Exception as e:
            logger.error(f"   âŒ å¤šæ¨¡æ€è½¨è¿¹æ£€ç´¢æ‰§è¡Œå¼‚å¸¸: {e}")
            self.test_results['error_messages'].append(f"æ‰§è¡Œå¼‚å¸¸: {e}")
            return False
    
    def test_data_verification(self) -> bool:
        """éªŒè¯æ•°æ®æ˜¯å¦æ­£ç¡®ä¿å­˜åˆ°æ•°æ®åº“"""
        logger.info("ğŸ” éªŒè¯æ•°æ®åº“æ•°æ®ä¿å­˜...")
        
        if not self.working_engine:
            logger.error("æ²¡æœ‰å¯ç”¨çš„æ•°æ®åº“è¿æ¥")
            return False
        
        try:
            # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨å¹¶æœ‰æ•°æ®
            check_sql = text(f"""
                SELECT COUNT(*) as record_count
                FROM {self.test_table}
            """)
            
            with self.working_engine.connect() as conn:
                result = conn.execute(check_sql)
                count = result.scalar()
            
            if count > 0:
                logger.info(f"   âœ… æ•°æ®éªŒè¯æˆåŠŸ: å‘ç° {count} æ¡è½¨è¿¹è®°å½•")
                self.test_results['data_saved'] = True
                
                # è·å–ä¸€äº›æ ·ä¾‹æ•°æ®
                sample_sql = text(f"""
                    SELECT scene_id, dataset_name, total_points, created_at
                    FROM {self.test_table}
                    LIMIT 3
                """)
                
                with self.working_engine.connect() as conn:
                    sample_result = conn.execute(sample_sql)
                    samples = sample_result.fetchall()
                
                logger.info("   æ ·ä¾‹è®°å½•:")
                for sample in samples:
                    logger.info(f"     {dict(sample)}")
                
                return True
            else:
                logger.warning("   âš ï¸ è¡¨å·²åˆ›å»ºä½†æ— æ•°æ®è®°å½•")
                self.test_results['error_messages'].append("è½¨è¿¹è¡¨æ— æ•°æ®")
                return False
                
        except Exception as e:
            logger.error(f"   âŒ æ•°æ®éªŒè¯å¤±è´¥: {e}")
            self.test_results['error_messages'].append(f"æ•°æ®éªŒè¯å¤±è´¥: {e}")
            return False
    
    def save_execution_log(self, stdout: str, stderr: str):
        """ä¿å­˜æ‰§è¡Œæ—¥å¿—"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜æ ‡å‡†è¾“å‡º
        if stdout:
            log_file = f"multimodal_test_output_{timestamp}.log"
            with open(log_file, 'w', encoding='utf-8') as f:
                f.write(stdout)
            logger.info(f"   ğŸ“ æ‰§è¡Œæ—¥å¿—å·²ä¿å­˜: {log_file}")
        
        # ä¿å­˜é”™è¯¯è¾“å‡º
        if stderr:
            error_file = f"multimodal_test_error_{timestamp}.log"
            with open(error_file, 'w', encoding='utf-8') as f:
                f.write(stderr)
            logger.warning(f"   ğŸ“ é”™è¯¯æ—¥å¿—å·²ä¿å­˜: {error_file}")
    
    def cleanup_test_data(self):
        """æ¸…ç†æµ‹è¯•æ•°æ®"""
        logger.info("ğŸ§¹ æ¸…ç†æµ‹è¯•æ•°æ®...")
        
        if not self.working_engine:
            return
        
        try:
            drop_sql = text(f"DROP TABLE IF EXISTS {self.test_table}")
            
            with self.working_engine.connect() as conn:
                conn.execute(drop_sql)
                conn.commit()
            
            logger.info(f"   âœ… æµ‹è¯•è¡¨å·²æ¸…ç†: {self.test_table}")
            
        except Exception as e:
            logger.warning(f"   âš ï¸ æ¸…ç†å¤±è´¥: {e}")
    
    def generate_test_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ“‹ å¤šæ¨¡æ€è½¨è¿¹æ£€ç´¢æ•°æ®åº“ä¿®å¤éªŒè¯æŠ¥å‘Š")
        logger.info("="*60)
        
        # æµ‹è¯•ç»“æœæ¦‚è¿°
        logger.info(f"\nğŸ§ª æµ‹è¯•ç»“æœæ¦‚è¿°:")
        logger.info(f"   æ•°æ®åº“è¿æ¥: {'âœ…' if self.test_results['database_connection'] else 'âŒ'}")
        logger.info(f"   è¡¨åˆ›å»ºåŠŸèƒ½: {'âœ…' if self.test_results['table_creation'] else 'âŒ'}")
        logger.info(f"   å¤šæ¨¡æ€æ‰§è¡Œ: {'âœ…' if self.test_results['multimodal_execution'] else 'âŒ'}")
        logger.info(f"   æ•°æ®ä¿å­˜éªŒè¯: {'âœ…' if self.test_results['data_saved'] else 'âŒ'}")
        
        if self.test_results['execution_time'] > 0:
            logger.info(f"   æ€»æ‰§è¡Œæ—¶é—´: {self.test_results['execution_time']:.2f}ç§’")
        
        # é”™è¯¯ä¿¡æ¯
        if self.test_results['error_messages']:
            logger.warning(f"\nâŒ é”™è¯¯ä¿¡æ¯:")
            for error in self.test_results['error_messages']:
                logger.warning(f"   {error}")
        
        # æœ€ç»ˆç»“è®º
        all_passed = all([
            self.test_results['database_connection'],
            self.test_results['table_creation'],
            self.test_results['multimodal_execution'],
            self.test_results['data_saved']
        ])
        
        logger.info(f"\nğŸ¯ æœ€ç»ˆç»“è®º:")
        if all_passed:
            logger.info("   âœ… æ•°æ®åº“é…ç½®ä¿®å¤æˆåŠŸï¼å¤šæ¨¡æ€è½¨è¿¹æ£€ç´¢åŠŸèƒ½æ­£å¸¸")
            logger.info("   âœ… å¯ä»¥æ­£å¸¸ä½¿ç”¨åŸå§‹å‘½ä»¤è¿›è¡Œè½¨è¿¹æ£€ç´¢")
        else:
            logger.warning("   âš ï¸ éƒ¨åˆ†åŠŸèƒ½å­˜åœ¨é—®é¢˜ï¼Œéœ€è¦è¿›ä¸€æ­¥æ’æŸ¥")
            logger.info("   ğŸ’¡ å»ºè®®:")
            logger.info("     1. æ£€æŸ¥PostgreSQLæœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ")
            logger.info("     2. éªŒè¯æ•°æ®åº“è¿æ¥é…ç½®æ˜¯å¦æ­£ç¡®")
            logger.info("     3. ç¡®è®¤ç›¸å…³Pythonä¾èµ–åŒ…æ˜¯å¦å®‰è£…å®Œæ•´")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="å¤šæ¨¡æ€è½¨è¿¹æ£€ç´¢æ•°æ®åº“ä¿®å¤éªŒè¯æµ‹è¯•")
    parser.add_argument(
        '--quick', 
        action='store_true',
        help='å¿«é€Ÿæµ‹è¯•æ¨¡å¼'
    )
    parser.add_argument(
        '--cleanup', 
        action='store_true',
        help='æµ‹è¯•åæ¸…ç†æ•°æ®'
    )
    
    args = parser.parse_args()
    
    print("ğŸ§ª å¤šæ¨¡æ€è½¨è¿¹æ£€ç´¢æ•°æ®åº“ä¿®å¤éªŒè¯æµ‹è¯•")
    print("="*60)
    
    # è¿è¡Œæµ‹è¯•
    tester = MultimodalDatabaseTester(
        quick_mode=args.quick,
        cleanup=args.cleanup
    )
    
    results = tester.run_comprehensive_test()
    
    # æä¾›åç»­å»ºè®®
    print("\n" + "="*60)
    print("ğŸ¯ åç»­æ“ä½œå»ºè®®:")
    print("="*60)
    
    if results.get('data_saved', False):
        print("âœ… æµ‹è¯•é€šè¿‡ï¼ç°åœ¨å¯ä»¥æ­£å¸¸ä½¿ç”¨å¤šæ¨¡æ€è½¨è¿¹æ£€ç´¢åŠŸèƒ½ï¼š")
        print("")
        print("python -m spdatalab.fusion.multimodal_trajectory_retrieval \\")
        print("  --text 'bicycle crossing intersection' \\")
        print("  --collection 'ddi_collection_camera_encoded_1' \\")
        print("  --output-table 'discovered_trajectories' \\")
        print("  --verbose")
    else:
        print("âŒ æµ‹è¯•æœªå®Œå…¨é€šè¿‡ï¼Œå»ºè®®:")
        print("1. æ£€æŸ¥PostgreSQLæœåŠ¡çŠ¶æ€")
        print("2. é‡æ–°è¿è¡Œæ•°æ®åº“è¿æ¥è¯Šæ–­:")
        print("   python database_connection_diagnostic.py")
        print("3. å¦‚éœ€è¦ï¼Œé‡æ–°è¿è¡Œé…ç½®ä¿®å¤:")
        print("   python fix_database_config.py")

if __name__ == "__main__":
    main()
