#!/usr/bin/env python3
"""
æ•°æ®åº“é…ç½®ä¿®å¤è„šæœ¬

æ­¤è„šæœ¬ç”¨äºä¿®å¤å¤šæ¨¡æ€è½¨è¿¹æ£€ç´¢ä¸­çš„æ•°æ®åº“è¿æ¥é…ç½®é—®é¢˜ï¼š
- å°† local_pg ä¸»æœºåæ›¿æ¢ä¸º localhost æˆ– 127.0.0.1
- è‡ªåŠ¨å¤‡ä»½åŸå§‹æ–‡ä»¶
- éªŒè¯ä¿®å¤æ•ˆæœ

ä½¿ç”¨æ–¹æ³•:
1. å…ˆè¿è¡Œè¯Šæ–­: python database_connection_diagnostic.py
2. æ ¹æ®è¯Šæ–­ç»“æœè¿è¡Œä¿®å¤: python fix_database_config.py [--host localhost|127.0.0.1]
3. é‡æ–°æµ‹è¯•å¤šæ¨¡æ€è½¨è¿¹æ£€ç´¢åŠŸèƒ½
"""

import argparse
import re
import logging
import shutil
from pathlib import Path
from datetime import datetime
from typing import Optional, List, Tuple

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class DatabaseConfigFixer:
    """æ•°æ®åº“é…ç½®ä¿®å¤å™¨"""
    
    def __init__(self, target_host: str = "localhost"):
        self.target_host = target_host
        self.target_files = [
            "src/spdatalab/dataset/polygon_trajectory_query.py",
            "src/spdatalab/fusion/multimodal_trajectory_retrieval.py"
        ]
        
        # åŒ¹é…æ¨¡å¼
        self.patterns = [
            {
                'name': 'LOCAL_DSNé…ç½®',
                'pattern': r'LOCAL_DSN\s*=\s*["\']postgresql\+psycopg://([^@]+)@local_pg:(\d+)/([^"\']+)["\']',
                'replacement': lambda m: f'LOCAL_DSN = "postgresql+psycopg://{m.group(1)}@{self.target_host}:{m.group(2)}/{m.group(3)}"'
            },
            {
                'name': 'å…¶ä»–local_pgå¼•ç”¨',
                'pattern': r'local_pg:(\d+)',
                'replacement': lambda m: f'{self.target_host}:{m.group(1)}'
            }
        ]
        
        self.fix_results = {
            'files_processed': 0,
            'changes_made': 0,
            'backup_files': [],
            'errors': []
        }
    
    def run_fix(self) -> bool:
        """è¿è¡Œä¿®å¤æµç¨‹"""
        logger.info(f"ğŸ”§ å¼€å§‹æ•°æ®åº“é…ç½®ä¿®å¤ (ç›®æ ‡ä¸»æœº: {self.target_host})")
        
        success = True
        
        for file_path in self.target_files:
            try:
                if self.fix_file(file_path):
                    self.fix_results['files_processed'] += 1
                else:
                    success = False
            except Exception as e:
                logger.error(f"ä¿®å¤æ–‡ä»¶å¤±è´¥: {file_path} - {e}")
                self.fix_results['errors'].append(f"{file_path}: {e}")
                success = False
        
        self.generate_fix_report()
        return success
    
    def fix_file(self, file_path: str) -> bool:
        """ä¿®å¤å•ä¸ªæ–‡ä»¶"""
        target_file = Path(file_path)
        
        if not target_file.exists():
            logger.warning(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {file_path}")
            return True  # ä¸ç®—ä½œé”™è¯¯
        
        logger.info(f"ğŸ”„ å¤„ç†æ–‡ä»¶: {file_path}")
        
        try:
            # è¯»å–åŸå§‹å†…å®¹
            with open(target_file, 'r', encoding='utf-8') as f:
                original_content = f.read()
            
            # åº”ç”¨ä¿®å¤æ¨¡å¼
            modified_content = original_content
            changes_in_file = 0
            
            for pattern_info in self.patterns:
                pattern = pattern_info['pattern']
                replacement_func = pattern_info['replacement']
                
                # æŸ¥æ‰¾åŒ¹é…é¡¹
                matches = list(re.finditer(pattern, modified_content))
                
                if matches:
                    logger.info(f"   å‘ç° {len(matches)} ä¸ªåŒ¹é…é¡¹: {pattern_info['name']}")
                    
                    # åº”ç”¨æ›¿æ¢
                    modified_content = re.sub(pattern, replacement_func, modified_content)
                    changes_in_file += len(matches)
            
            # å¦‚æœæœ‰ä¿®æ”¹ï¼Œåˆ›å»ºå¤‡ä»½å¹¶å†™å…¥æ–°å†…å®¹
            if changes_in_file > 0:
                # åˆ›å»ºå¤‡ä»½
                backup_path = self.create_backup(target_file)
                self.fix_results['backup_files'].append(str(backup_path))
                
                # å†™å…¥ä¿®å¤åçš„å†…å®¹
                with open(target_file, 'w', encoding='utf-8') as f:
                    f.write(modified_content)
                
                self.fix_results['changes_made'] += changes_in_file
                logger.info(f"   âœ… æ–‡ä»¶ä¿®å¤å®Œæˆ: {changes_in_file} å¤„ä¿®æ”¹")
                logger.info(f"   ğŸ“ å¤‡ä»½åˆ›å»º: {backup_path}")
            else:
                logger.info(f"   â„¹ï¸ æ–‡ä»¶æ— éœ€ä¿®æ”¹")
            
            return True
            
        except Exception as e:
            logger.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥: {file_path} - {e}")
            return False
    
    def create_backup(self, original_file: Path) -> Path:
        """åˆ›å»ºå¤‡ä»½æ–‡ä»¶"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_path = original_file.with_suffix(f'.backup_{timestamp}.py')
        
        shutil.copy2(original_file, backup_path)
        return backup_path
    
    def generate_fix_report(self):
        """ç”Ÿæˆä¿®å¤æŠ¥å‘Š"""
        logger.info("\n" + "="*60)
        logger.info("ğŸ“‹ æ•°æ®åº“é…ç½®ä¿®å¤æŠ¥å‘Š")
        logger.info("="*60)
        
        logger.info(f"\nğŸ”§ ä¿®å¤æ¦‚è¿°:")
        logger.info(f"   ç›®æ ‡ä¸»æœº: {self.target_host}")
        logger.info(f"   å¤„ç†æ–‡ä»¶æ•°: {self.fix_results['files_processed']}")
        logger.info(f"   ä¿®æ”¹æ•°é‡: {self.fix_results['changes_made']}")
        logger.info(f"   é”™è¯¯æ•°é‡: {len(self.fix_results['errors'])}")
        
        if self.fix_results['backup_files']:
            logger.info(f"\nğŸ“ å¤‡ä»½æ–‡ä»¶:")
            for backup in self.fix_results['backup_files']:
                logger.info(f"   {backup}")
        
        if self.fix_results['errors']:
            logger.warning(f"\nâŒ é”™è¯¯åˆ—è¡¨:")
            for error in self.fix_results['errors']:
                logger.warning(f"   {error}")
        
        if self.fix_results['changes_made'] > 0:
            logger.info(f"\nâœ… ä¿®å¤æˆåŠŸï¼å¯ä»¥é‡æ–°æµ‹è¯•å¤šæ¨¡æ€è½¨è¿¹æ£€ç´¢åŠŸèƒ½")
        else:
            logger.info(f"\nâ„¹ï¸ æœªå‘ç°éœ€è¦ä¿®å¤çš„é…ç½®")

def create_test_script():
    """åˆ›å»ºæµ‹è¯•è„šæœ¬"""
    test_script = '''#!/usr/bin/env python3
"""
å¤šæ¨¡æ€è½¨è¿¹æ£€ç´¢æ•°æ®åº“ä¿®å¤æµ‹è¯•è„šæœ¬

æ­¤è„šæœ¬ç”¨äºéªŒè¯æ•°æ®åº“é…ç½®ä¿®å¤åçš„åŠŸèƒ½æ˜¯å¦æ­£å¸¸
"""

import sys
import logging
import subprocess
from pathlib import Path

logger = logging.getLogger(__name__)

def test_multimodal_trajectory_retrieval():
    """æµ‹è¯•å¤šæ¨¡æ€è½¨è¿¹æ£€ç´¢åŠŸèƒ½"""
    logger.info("ğŸ§ª æµ‹è¯•å¤šæ¨¡æ€è½¨è¿¹æ£€ç´¢åŠŸèƒ½...")
    
    # æµ‹è¯•å‘½ä»¤
    test_cmd = [
        sys.executable, "-m", "spdatalab.fusion.multimodal_trajectory_retrieval",
        "--text", "bicycle crossing intersection",
        "--collection", "ddi_collection_camera_encoded_1", 
        "--output-table", "discovered_trajectories_test",
        "--verbose"
    ]
    
    try:
        logger.info("è¿è¡Œå‘½ä»¤: " + " ".join(test_cmd))
        
        result = subprocess.run(
            test_cmd,
            capture_output=True,
            text=True,
            timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
        )
        
        logger.info(f"è¿”å›ä»£ç : {result.returncode}")
        
        if result.stdout:
            logger.info("æ ‡å‡†è¾“å‡º:")
            logger.info(result.stdout)
        
        if result.stderr:
            logger.warning("é”™è¯¯è¾“å‡º:")
            logger.warning(result.stderr)
        
        if result.returncode == 0:
            logger.info("âœ… å¤šæ¨¡æ€è½¨è¿¹æ£€ç´¢æµ‹è¯•æˆåŠŸ")
            return True
        else:
            logger.error("âŒ å¤šæ¨¡æ€è½¨è¿¹æ£€ç´¢æµ‹è¯•å¤±è´¥")
            return False
            
    except subprocess.TimeoutExpired:
        logger.error("âŒ æµ‹è¯•è¶…æ—¶")
        return False
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    logging.basicConfig(level=logging.INFO)
    
    print("ğŸ§ª å¤šæ¨¡æ€è½¨è¿¹æ£€ç´¢æ•°æ®åº“ä¿®å¤æµ‹è¯•")
    print("="*50)
    
    # æ£€æŸ¥ä¿®å¤åçš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    target_file = Path("src/spdatalab/dataset/polygon_trajectory_query.py")
    if not target_file.exists():
        logger.error(f"ç›®æ ‡æ–‡ä»¶ä¸å­˜åœ¨: {target_file}")
        return False
    
    # è¿è¡Œæµ‹è¯•
    success = test_multimodal_trajectory_retrieval()
    
    if success:
        print("\\nğŸ‰ æµ‹è¯•é€šè¿‡ï¼æ•°æ®åº“é…ç½®ä¿®å¤æˆåŠŸ")
    else:
        print("\\nâŒ æµ‹è¯•å¤±è´¥ï¼Œå¯èƒ½éœ€è¦è¿›ä¸€æ­¥æ’æŸ¥")
    
    return success

if __name__ == "__main__":
    main()
'''
    
    with open('test_database_fix.py', 'w', encoding='utf-8') as f:
        f.write(test_script)
    
    logger.info("âœ… å·²åˆ›å»ºæµ‹è¯•è„šæœ¬: test_database_fix.py")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="ä¿®å¤spdatalabæ•°æ®åº“è¿æ¥é…ç½®")
    parser.add_argument(
        '--host', 
        choices=['localhost', '127.0.0.1'], 
        default='localhost',
        help='ç›®æ ‡æ•°æ®åº“ä¸»æœº (é»˜è®¤: localhost)'
    )
    parser.add_argument(
        '--test', 
        action='store_true',
        help='ä¿®å¤åè‡ªåŠ¨è¿è¡Œæµ‹è¯•'
    )
    
    args = parser.parse_args()
    
    print("ğŸ”§ spdatalab æ•°æ®åº“é…ç½®ä¿®å¤å·¥å…·")
    print("="*50)
    
    # è¿è¡Œä¿®å¤
    fixer = DatabaseConfigFixer(target_host=args.host)
    success = fixer.run_fix()
    
    if success:
        # åˆ›å»ºæµ‹è¯•è„šæœ¬
        create_test_script()
        
        print("\n" + "="*60)
        print("ğŸ¯ ä¸‹ä¸€æ­¥æ“ä½œå»ºè®®:")
        print("="*60)
        print("1. è¿è¡Œæµ‹è¯•éªŒè¯ä¿®å¤æ•ˆæœ:")
        print("   python test_database_fix.py")
        print("")
        print("2. æˆ–æ‰‹åŠ¨æµ‹è¯•å¤šæ¨¡æ€è½¨è¿¹æ£€ç´¢:")
        print("   python -m spdatalab.fusion.multimodal_trajectory_retrieval \\")
        print("     --text 'bicycle crossing intersection' \\")
        print("     --collection 'ddi_collection_camera_encoded_1' \\")
        print("     --output-table 'discovered_trajectories' \\")
        print("     --verbose")
        
        # è‡ªåŠ¨è¿è¡Œæµ‹è¯•
        if args.test:
            print("\nğŸ§ª è‡ªåŠ¨è¿è¡Œæµ‹è¯•...")
            subprocess.run([sys.executable, 'test_database_fix.py'])
    
    else:
        print("\nâŒ ä¿®å¤å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

if __name__ == "__main__":
    main()
