#!/usr/bin/env python3
"""
è¯Šæ–­parquetæ–‡ä»¶é—®é¢˜çš„è„šæœ¬
"""

import sys
import pandas as pd
from pathlib import Path
import json

def diagnose_parquet_file(file_path):
    """è¯Šæ–­parquetæ–‡ä»¶çš„é—®é¢˜"""
    print(f"ğŸ” è¯Šæ–­parquetæ–‡ä»¶: {file_path}")
    
    file_path = Path(file_path)
    
    # 1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not file_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return False
    
    # 2. æ£€æŸ¥æ–‡ä»¶å¤§å°
    file_size = file_path.stat().st_size
    print(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_size} bytes ({file_size/1024:.2f} KB)")
    
    # 3. æ£€æŸ¥æ–‡ä»¶å¤´éƒ¨
    try:
        with open(file_path, 'rb') as f:
            header = f.read(4)
            print(f"ğŸ”¤ æ–‡ä»¶å¤´éƒ¨: {header}")
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤´éƒ¨å¤±è´¥: {e}")
        return False
    
    # 4. å°è¯•è¯»å–parquetæ–‡ä»¶
    try:
        print("ğŸ“– å°è¯•è¯»å–parquetæ–‡ä»¶...")
        df = pd.read_parquet(file_path)
        print(f"âœ… æˆåŠŸè¯»å–parquetæ–‡ä»¶!")
        print(f"   - è¡Œæ•°: {len(df)}")
        print(f"   - åˆ—æ•°: {len(df.columns)}")
        print(f"   - åˆ—å: {list(df.columns)}")
        
        if 'scene_id' in df.columns:
            unique_scene_ids = df['scene_id'].nunique()
            print(f"   - å”¯ä¸€scene_idæ•°é‡: {unique_scene_ids}")
        
        # æ˜¾ç¤ºå‰å‡ è¡Œ
        print("\nğŸ“‹ å‰5è¡Œæ•°æ®:")
        print(df.head())
        
        return True
        
    except Exception as e:
        print(f"âŒ è¯»å–parquetæ–‡ä»¶å¤±è´¥: {e}")
        print(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
        return False

def test_bbox_load_function(file_path):
    """æµ‹è¯•bboxæ¨¡å—çš„åŠ è½½å‡½æ•°"""
    print(f"\nğŸ§ª æµ‹è¯•bboxåŠ è½½å‡½æ•°...")
    
    try:
        # å¯¼å…¥bboxæ¨¡å—çš„å‡½æ•°
        sys.path.insert(0, 'src')
        from spdatalab.dataset.bbox import load_scene_ids_from_parquet
        
        scene_ids = load_scene_ids_from_parquet(file_path)
        print(f"âœ… bboxåŠ è½½æˆåŠŸ! åŠ è½½äº† {len(scene_ids)} ä¸ªscene_id")
        return True
        
    except Exception as e:
        print(f"âŒ bboxåŠ è½½å¤±è´¥: {e}")
        print(f"   é”™è¯¯ç±»å‹: {type(e).__name__}")
        return False

def compare_with_meta_file(parquet_path):
    """æ¯”è¾ƒparquetæ–‡ä»¶å’Œmetaæ–‡ä»¶çš„ä¿¡æ¯"""
    meta_path = Path(parquet_path).with_suffix('.meta.json')
    
    if meta_path.exists():
        print(f"\nğŸ“Š æ£€æŸ¥metaæ–‡ä»¶: {meta_path}")
        try:
            with open(meta_path, 'r', encoding='utf-8') as f:
                meta_data = json.load(f)
            
            print("Metaæ–‡ä»¶å†…å®¹:")
            for key, value in meta_data.items():
                print(f"  {key}: {value}")
            
        except Exception as e:
            print(f"âŒ è¯»å–metaæ–‡ä»¶å¤±è´¥: {e}")
    else:
        print(f"âš ï¸ Metaæ–‡ä»¶ä¸å­˜åœ¨: {meta_path}")

if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("ç”¨æ³•: python diagnose_parquet.py <parquet_file_path>")
        sys.exit(1)
    
    parquet_file = sys.argv[1]
    
    print("=" * 60)
    print("ğŸ©º Parquetæ–‡ä»¶è¯Šæ–­å·¥å…·")
    print("=" * 60)
    
    # è¯Šæ–­parquetæ–‡ä»¶
    success = diagnose_parquet_file(parquet_file)
    
    if success:
        # æµ‹è¯•bboxåŠ è½½å‡½æ•°
        test_bbox_load_function(parquet_file)
    
    # æ£€æŸ¥metaæ–‡ä»¶
    compare_with_meta_file(parquet_file)
    
    print("\n" + "=" * 60)
    print("ğŸ è¯Šæ–­å®Œæˆ")
    print("=" * 60)
