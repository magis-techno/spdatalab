#!/usr/bin/env python3
"""
æµ‹è¯•scene_idå­—æ®µåŠŸèƒ½

éªŒè¯è½¨è¿¹æ•°æ®ä¸­scene_idå­—æ®µçš„æ·»åŠ åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import logging
import json
from pathlib import Path
from src.spdatalab.dataset.polygon_trajectory_query import (
    HighPerformancePolygonTrajectoryQuery, 
    PolygonTrajectoryConfig
)

def create_test_polygon():
    """åˆ›å»ºæµ‹è¯•polygon"""
    test_polygon = {
        "type": "FeatureCollection",
        "features": [
            {
                "type": "Feature",
                "properties": {
                    "id": "test_scene_id_feature",
                    "name": "scene_idå­—æ®µæµ‹è¯•åŒºåŸŸ"
                },
                "geometry": {
                    "type": "Polygon", 
                    "coordinates": [[
                        [116.3, 39.9],
                        [116.4, 39.9], 
                        [116.4, 40.0],
                        [116.3, 40.0],
                        [116.3, 39.9]
                    ]]
                }
            }
        ]
    }
    
    # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
    test_file = "test_scene_id_polygon.geojson"
    with open(test_file, 'w', encoding='utf-8') as f:
        json.dump(test_polygon, f, ensure_ascii=False, indent=2)
    
    return test_file

def test_scene_id_feature():
    """æµ‹è¯•scene_idå­—æ®µåŠŸèƒ½"""
    
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    logger = logging.getLogger(__name__)
    
    logger.info("=== scene_idå­—æ®µåŠŸèƒ½æµ‹è¯• ===")
    
    try:
        # åˆ›å»ºæµ‹è¯•polygon
        polygon_file = create_test_polygon()
        logger.info(f"âœ… åˆ›å»ºæµ‹è¯•polygonæ–‡ä»¶: {polygon_file}")
        
        # é…ç½®æŸ¥è¯¢å¤„ç†å™¨
        config = PolygonTrajectoryConfig(
            limit_per_polygon=50,  # é™åˆ¶æ•°é‡ä»¥ä¾¿å¿«é€Ÿæµ‹è¯•
            fetch_complete_trajectories=False  # å…ˆæµ‹è¯•åŸºæœ¬åŠŸèƒ½
        )
        
        query_processor = HighPerformancePolygonTrajectoryQuery(config)
        
        # æ‰§è¡ŒæŸ¥è¯¢
        logger.info("ğŸš€ æ‰§è¡Œè½¨è¿¹æŸ¥è¯¢...")
        trajectories, stats = query_processor.process_complete_workflow(
            polygon_geojson=polygon_file,
            output_table=None  # ä¸ä¿å­˜åˆ°æ•°æ®åº“ï¼Œä»…æµ‹è¯•æ•°æ®ç»“æ„
        )
        
        logger.info(f"ğŸ“Š æŸ¥è¯¢ç»“æœ:")
        logger.info(f"   - è½¨è¿¹æ•°é‡: {len(trajectories)}")
        logger.info(f"   - æŸ¥è¯¢ç­–ç•¥: {stats.get('strategy', 'unknown')}")
        logger.info(f"   - æ€»ç‚¹æ•°: {stats.get('total_points', 0)}")
        logger.info(f"   - æ•°æ®é›†æ•°: {stats.get('unique_datasets', 0)}")
        logger.info(f"   - æŸ¥è¯¢æ—¶é—´: {stats.get('query_time', 0):.2f}s")
        
        # æ£€æŸ¥è½¨è¿¹æ•°æ®ç»“æ„
        if trajectories:
            logger.info("\nğŸ” æ£€æŸ¥è½¨è¿¹æ•°æ®ç»“æ„:")
            first_trajectory = trajectories[0]
            
            # æ£€æŸ¥å¿…è¦å­—æ®µ
            required_fields = ['dataset_name', 'scene_id', 'start_time', 'end_time', 'geometry']
            missing_fields = []
            present_fields = []
            
            for field in required_fields:
                if field in first_trajectory:
                    present_fields.append(field)
                else:
                    missing_fields.append(field)
            
            logger.info(f"   âœ… å­˜åœ¨å­—æ®µ: {present_fields}")
            if missing_fields:
                logger.warning(f"   âŒ ç¼ºå¤±å­—æ®µ: {missing_fields}")
            
            # è¯¦ç»†æ£€æŸ¥å‰å‡ æ¡è½¨è¿¹çš„scene_id
            logger.info("\nğŸ“‹ å‰å‡ æ¡è½¨è¿¹çš„scene_idä¿¡æ¯:")
            for i, traj in enumerate(trajectories[:5], 1):
                dataset_name = traj.get('dataset_name', 'unknown')
                scene_id = traj.get('scene_id', None)
                point_count = traj.get('point_count', 0)
                
                if scene_id:
                    logger.info(f"   {i}. {dataset_name} -> scene_id: {scene_id} ({point_count} ç‚¹)")
                else:
                    logger.warning(f"   {i}. {dataset_name} -> scene_id: None ({point_count} ç‚¹)")
            
            # ç»Ÿè®¡scene_idæƒ…å†µ
            total_trajectories = len(trajectories)
            trajectories_with_scene_id = sum(1 for traj in trajectories if traj.get('scene_id'))
            trajectories_without_scene_id = total_trajectories - trajectories_with_scene_id
            
            logger.info(f"\nğŸ“Š scene_idç»Ÿè®¡:")
            logger.info(f"   - æ€»è½¨è¿¹æ•°: {total_trajectories}")
            logger.info(f"   - æœ‰scene_id: {trajectories_with_scene_id} ({trajectories_with_scene_id/total_trajectories*100:.1f}%)")
            logger.info(f"   - æ— scene_id: {trajectories_without_scene_id} ({trajectories_without_scene_id/total_trajectories*100:.1f}%)")
            
            if trajectories_with_scene_id > 0:
                logger.info("âœ… scene_idå­—æ®µåŠŸèƒ½æ­£å¸¸å·¥ä½œï¼")
            else:
                logger.warning("âš ï¸ æ‰€æœ‰è½¨è¿¹éƒ½æ²¡æœ‰scene_idï¼Œå¯èƒ½æ˜¯æŸ¥è¯¢å¤±è´¥æˆ–æ•°æ®é—®é¢˜")
        else:
            logger.warning("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•è½¨è¿¹æ•°æ®")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        Path(polygon_file).unlink(missing_ok=True)
        logger.info(f"ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {polygon_file}")
        
        logger.info("\nâœ… scene_idå­—æ®µåŠŸèƒ½æµ‹è¯•å®Œæˆ!")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        return False

if __name__ == '__main__':
    success = test_scene_id_feature()
    exit(0 if success else 1) 