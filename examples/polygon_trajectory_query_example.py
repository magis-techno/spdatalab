"""
é«˜æ€§èƒ½Polygonè½¨è¿¹æŸ¥è¯¢ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ä¼˜åŒ–çš„polygon_trajectory_queryæ¨¡å—è¿›è¡Œæ‰¹é‡è½¨è¿¹æŸ¥è¯¢
å±•ç¤ºä¸åŒé…ç½®é€‰é¡¹å’Œæ€§èƒ½ç‰¹æ€§
"""

import json
import logging
from pathlib import Path
from spdatalab.dataset.polygon_trajectory_query import (
    process_polygon_trajectory_query,
    PolygonTrajectoryConfig,
    HighPerformancePolygonTrajectoryQuery
)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def create_sample_geojson():
    """åˆ›å»ºç¤ºä¾‹GeoJSONæ–‡ä»¶"""
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„çŸ©å½¢polygonï¼ˆåŒ—äº¬é™„è¿‘åŒºåŸŸï¼‰
    sample_polygon = {
        "type": "FeatureCollection",
        "features": [
            {
                "type": "Feature",
                "properties": {
                    "id": "beijing_area_1",
                    "name": "åŒ—äº¬æµ‹è¯•åŒºåŸŸ1"
                },
                "geometry": {
                    "type": "Polygon",
                    "coordinates": [[
                        [116.3, 39.9],   # è¥¿å—è§’
                        [116.4, 39.9],   # ä¸œå—è§’
                        [116.4, 40.0],   # ä¸œåŒ—è§’
                        [116.3, 40.0],   # è¥¿åŒ—è§’
                        [116.3, 39.9]    # å›åˆ°èµ·å§‹ç‚¹
                    ]]
                }
            },
            {
                "type": "Feature", 
                "properties": {
                    "id": "beijing_area_2",
                    "name": "åŒ—äº¬æµ‹è¯•åŒºåŸŸ2"
                },
                "geometry": {
                    "type": "Polygon",
                    "coordinates": [[
                        [116.35, 39.85],
                        [116.45, 39.85],
                        [116.45, 39.95],
                        [116.35, 39.95],
                        [116.35, 39.85]
                    ]]
                }
            }
        ]
    }
    
    # ä¿å­˜ç¤ºä¾‹æ–‡ä»¶
    sample_file = Path("sample_polygons.geojson")
    with open(sample_file, 'w', encoding='utf-8') as f:
        json.dump(sample_polygon, f, ensure_ascii=False, indent=2)
    
    logger.info(f"åˆ›å»ºç¤ºä¾‹GeoJSONæ–‡ä»¶: {sample_file}")
    return str(sample_file)

def run_basic_example():
    """è¿è¡ŒåŸºç¡€ç¤ºä¾‹"""
    logger.info("=== åŸºç¡€Polygonè½¨è¿¹æŸ¥è¯¢ç¤ºä¾‹ ===")
    
    try:
        # 1. åˆ›å»ºç¤ºä¾‹GeoJSONæ–‡ä»¶
        geojson_file = create_sample_geojson()
        
        # 2. ä½¿ç”¨é»˜è®¤é…ç½®å¤„ç†
        logger.info("ä½¿ç”¨é»˜è®¤é…ç½®è¿›è¡Œpolygonè½¨è¿¹æŸ¥è¯¢...")
        
        stats = process_polygon_trajectory_query(
            geojson_file=geojson_file,
            output_table="polygon_trajectories_basic_example",
            output_geojson="trajectories_basic_result.geojson"
        )
        
        # 3. è¾“å‡ºç»“æœç»Ÿè®¡
        display_results(stats, "åŸºç¡€ç¤ºä¾‹")
        
        # 4. æ¸…ç†ç¤ºä¾‹æ–‡ä»¶
        Path(geojson_file).unlink(missing_ok=True)
        Path("trajectories_basic_result.geojson").unlink(missing_ok=True)
        
        return stats.get('success', False)
        
    except Exception as e:
        logger.error(f"åŸºç¡€ç¤ºä¾‹è¿è¡Œå¤±è´¥: {str(e)}")
        return False

def run_performance_example():
    """è¿è¡Œé«˜æ€§èƒ½é…ç½®ç¤ºä¾‹"""
    logger.info("=== é«˜æ€§èƒ½é…ç½®ç¤ºä¾‹ ===")
    
    try:
        # 1. åˆ›å»ºç¤ºä¾‹GeoJSONæ–‡ä»¶
        geojson_file = create_sample_geojson()
        
        # 2. åˆ›å»ºé«˜æ€§èƒ½é…ç½®
        config = PolygonTrajectoryConfig(
            batch_threshold=30,          # é™ä½æ‰¹é‡é˜ˆå€¼
            chunk_size=10,               # è¾ƒå°åˆ†å—
            limit_per_polygon=20000,     # æ›´å¤šè½¨è¿¹ç‚¹
            batch_insert_size=500,       # è¾ƒå°æ‰¹æ¬¡æ’å…¥
            min_points_per_trajectory=3, # è‡³å°‘3ä¸ªç‚¹
            enable_speed_stats=True,     # å¯ç”¨é€Ÿåº¦ç»Ÿè®¡
            enable_avp_stats=True        # å¯ç”¨AVPç»Ÿè®¡
        )
        
        logger.info("ä½¿ç”¨é«˜æ€§èƒ½é…ç½®:")
        logger.info(f"  â€¢ æ‰¹é‡é˜ˆå€¼: {config.batch_threshold}")
        logger.info(f"  â€¢ åˆ†å—å¤§å°: {config.chunk_size}")
        logger.info(f"  â€¢ è½¨è¿¹ç‚¹é™åˆ¶: {config.limit_per_polygon:,}")
        logger.info(f"  â€¢ æ‰¹é‡æ’å…¥: {config.batch_insert_size}")
        
        # 3. æ‰§è¡Œé«˜æ€§èƒ½æŸ¥è¯¢
        stats = process_polygon_trajectory_query(
            geojson_file=geojson_file,
            output_table="polygon_trajectories_performance_example",
            config=config
        )
        
        # 4. è¾“å‡ºè¯¦ç»†ç»“æœ
        display_results(stats, "é«˜æ€§èƒ½ç¤ºä¾‹")
        
        # 5. æ¸…ç†ç¤ºä¾‹æ–‡ä»¶
        Path(geojson_file).unlink(missing_ok=True)
        
        return stats.get('success', False)
        
    except Exception as e:
        logger.error(f"é«˜æ€§èƒ½ç¤ºä¾‹è¿è¡Œå¤±è´¥: {str(e)}")
        return False

def run_direct_api_example():
    """è¿è¡Œç›´æ¥APIè°ƒç”¨ç¤ºä¾‹"""
    logger.info("=== ç›´æ¥APIè°ƒç”¨ç¤ºä¾‹ ===")
    
    try:
        # 1. åˆ›å»ºç¤ºä¾‹GeoJSONæ–‡ä»¶
        geojson_file = create_sample_geojson()
        
        # 2. åˆ›å»ºæŸ¥è¯¢å™¨å®ä¾‹
        config = PolygonTrajectoryConfig(
            batch_threshold=5,  # å°é˜ˆå€¼ä¾¿äºæ¼”ç¤ºåˆ†å—
            chunk_size=1,
            limit_per_polygon=1000
        )
        
        query_processor = HighPerformancePolygonTrajectoryQuery(config)
        
        # 3. åˆ†æ­¥æ‰§è¡Œ
        from spdatalab.dataset.polygon_trajectory_query import load_polygons_from_geojson
        
        logger.info("æ­¥éª¤1: åŠ è½½polygon...")
        polygons = load_polygons_from_geojson(geojson_file)
        logger.info(f"åŠ è½½äº† {len(polygons)} ä¸ªpolygon")
        
        logger.info("æ­¥éª¤2: æŸ¥è¯¢è½¨è¿¹ç‚¹...")
        points_df, query_stats = query_processor.query_intersecting_trajectory_points(polygons)
        logger.info(f"æŸ¥è¯¢ç»Ÿè®¡: {query_stats}")
        
        if not points_df.empty:
            logger.info("æ­¥éª¤3: æ„å»ºè½¨è¿¹...")
            trajectories, build_stats = query_processor.build_trajectories_from_points(points_df)
            logger.info(f"æ„å»ºç»Ÿè®¡: {build_stats}")
            
            logger.info("æ­¥éª¤4: ä¿å­˜åˆ°æ•°æ®åº“...")
            saved_count, save_stats = query_processor.save_trajectories_to_table(
                trajectories, "polygon_trajectories_api_example"
            )
            logger.info(f"ä¿å­˜ç»Ÿè®¡: {save_stats}")
        else:
            logger.info("æ²¡æœ‰æ‰¾åˆ°è½¨è¿¹ç‚¹æ•°æ®")
        
        # 4. æ¸…ç†ç¤ºä¾‹æ–‡ä»¶
        Path(geojson_file).unlink(missing_ok=True)
        
        return True
        
    except Exception as e:
        logger.error(f"ç›´æ¥APIç¤ºä¾‹è¿è¡Œå¤±è´¥: {str(e)}")
        return False

def display_results(stats: dict, example_name: str):
    """æ˜¾ç¤ºå¤„ç†ç»“æœ"""
    logger.info(f"=== {example_name}å¤„ç†ç»“æœ ===")
    
    if not stats.get('success', False):
        logger.error("âŒ å¤„ç†å¤±è´¥")
        if 'error' in stats:
            logger.error(f"é”™è¯¯ä¿¡æ¯: {stats['error']}")
        return
    
    logger.info(f"âœ… å¤„ç†æˆåŠŸå®Œæˆï¼")
    logger.info(f"ğŸ“Š åŸºæœ¬ç»Ÿè®¡:")
    logger.info(f"   â€¢ Polygonæ•°é‡: {stats.get('polygon_count', 0)}")
    
    query_stats = stats.get('query_stats', {})
    if query_stats:
        logger.info(f"ğŸ” æŸ¥è¯¢ç»Ÿè®¡:")
        logger.info(f"   â€¢ æŸ¥è¯¢ç­–ç•¥: {query_stats.get('strategy', 'unknown')}")
        logger.info(f"   â€¢ è½¨è¿¹ç‚¹æ€»æ•°: {query_stats.get('total_points', 0):,}")
        logger.info(f"   â€¢ æ•°æ®é›†æ•°é‡: {query_stats.get('unique_datasets', 0)}")
        logger.info(f"   â€¢ æŸ¥è¯¢ç”¨æ—¶: {query_stats.get('query_time', 0):.2f}s")
    
    build_stats = stats.get('build_stats', {})
    if build_stats:
        logger.info(f"ğŸ”§ æ„å»ºç»Ÿè®¡:")
        logger.info(f"   â€¢ æœ‰æ•ˆè½¨è¿¹æ•°: {build_stats.get('valid_trajectories', 0)}")
        logger.info(f"   â€¢ è·³è¿‡è½¨è¿¹æ•°: {build_stats.get('skipped_trajectories', 0)}")
        logger.info(f"   â€¢ æ„å»ºç”¨æ—¶: {build_stats.get('build_time', 0):.2f}s")
    
    save_stats = stats.get('save_stats', {})
    if save_stats and not save_stats.get('skipped', False):
        logger.info(f"ğŸ’¾ ä¿å­˜ç»Ÿè®¡:")
        logger.info(f"   â€¢ ä¿å­˜è®°å½•æ•°: {save_stats.get('saved_records', 0)}")
        logger.info(f"   â€¢ æ‰¹æ¬¡æ•°é‡: {save_stats.get('batch_count', 0)}")
        logger.info(f"   â€¢ ä¿å­˜ç”¨æ—¶: {save_stats.get('save_time', 0):.2f}s")
    
    total_time = stats.get('total_duration', 0)
    if total_time > 0:
        logger.info(f"â±ï¸ æ€»ç”¨æ—¶: {total_time:.2f}s")
        
        total_points = query_stats.get('total_points', 0)
        if total_points > 0:
            logger.info(f"ğŸš€ å¤„ç†é€Ÿåº¦: {total_points/total_time:.1f} ç‚¹/ç§’")

def show_usage_examples():
    """æ˜¾ç¤ºå‘½ä»¤è¡Œä½¿ç”¨ç¤ºä¾‹"""
    print("\n=== å‘½ä»¤è¡Œä½¿ç”¨ç¤ºä¾‹ ===")
    print("1. æŸ¥è¯¢è½¨è¿¹å¹¶ä¿å­˜åˆ°æ•°æ®åº“è¡¨:")
    print("   python -m spdatalab.dataset.polygon_trajectory_query --input polygons.geojson --table my_trajectories")
    
    print("\n2. æŸ¥è¯¢è½¨è¿¹å¹¶å¯¼å‡ºåˆ°GeoJSONæ–‡ä»¶:")
    print("   python -m spdatalab.dataset.polygon_trajectory_query --input polygons.geojson --output trajectories.geojson")
    
    print("\n3. åŒæ—¶ä¿å­˜åˆ°æ•°æ®åº“å’Œæ–‡ä»¶:")
    print("   python -m spdatalab.dataset.polygon_trajectory_query --input polygons.geojson --table my_trajectories --output trajectories.geojson")
    
    print("\n4. è®¾ç½®æ¯ä¸ªpolygonçš„è½¨è¿¹ç‚¹é™åˆ¶:")
    print("   python -m spdatalab.dataset.polygon_trajectory_query --input polygons.geojson --table my_trajectories --limit 20000")
    
    print("\n5. å¯ç”¨è¯¦ç»†æ—¥å¿—:")
    print("   python -m spdatalab.dataset.polygon_trajectory_query --input polygons.geojson --table my_trajectories --verbose")

if __name__ == "__main__":
    # æ˜¾ç¤ºä½¿ç”¨ç¤ºä¾‹
    show_usage_examples()
    
    print("\n=== é«˜æ€§èƒ½Polygonè½¨è¿¹æŸ¥è¯¢ç¤ºä¾‹ ===")
    print("è¯·é€‰æ‹©è¦è¿è¡Œçš„ç¤ºä¾‹:")
    print("1. åŸºç¡€ç¤ºä¾‹ - ä½¿ç”¨é»˜è®¤é…ç½®")
    print("2. é«˜æ€§èƒ½ç¤ºä¾‹ - å±•ç¤ºä¼˜åŒ–é…ç½®")
    print("3. ç›´æ¥APIç¤ºä¾‹ - åˆ†æ­¥è°ƒç”¨API")
    print("4. è¿è¡Œæ‰€æœ‰ç¤ºä¾‹")
    print("0. è·³è¿‡ç¤ºä¾‹è¿è¡Œ")
    
    try:
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (0-4): ").strip()
        
        if choice == '0':
            print("è·³è¿‡ç¤ºä¾‹è¿è¡Œ")
        elif choice == '1':
            logger.info("è¿è¡ŒåŸºç¡€ç¤ºä¾‹...")
            success = run_basic_example()
            print("âœ… åŸºç¡€ç¤ºä¾‹è¿è¡ŒæˆåŠŸï¼" if success else "âŒ åŸºç¡€ç¤ºä¾‹è¿è¡Œå¤±è´¥ï¼")
        elif choice == '2':
            logger.info("è¿è¡Œé«˜æ€§èƒ½ç¤ºä¾‹...")
            success = run_performance_example()
            print("âœ… é«˜æ€§èƒ½ç¤ºä¾‹è¿è¡ŒæˆåŠŸï¼" if success else "âŒ é«˜æ€§èƒ½ç¤ºä¾‹è¿è¡Œå¤±è´¥ï¼")
        elif choice == '3':
            logger.info("è¿è¡Œç›´æ¥APIç¤ºä¾‹...")
            success = run_direct_api_example()
            print("âœ… ç›´æ¥APIç¤ºä¾‹è¿è¡ŒæˆåŠŸï¼" if success else "âŒ ç›´æ¥APIç¤ºä¾‹è¿è¡Œå¤±è´¥ï¼")
        elif choice == '4':
            logger.info("è¿è¡Œæ‰€æœ‰ç¤ºä¾‹...")
            results = []
            
            logger.info("\n" + "="*50)
            results.append(("åŸºç¡€ç¤ºä¾‹", run_basic_example()))
            
            logger.info("\n" + "="*50)
            results.append(("é«˜æ€§èƒ½ç¤ºä¾‹", run_performance_example()))
            
            logger.info("\n" + "="*50)
            results.append(("ç›´æ¥APIç¤ºä¾‹", run_direct_api_example()))
            
            logger.info("\n" + "="*50)
            logger.info("ğŸ¯ æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
            logger.info("ğŸ“Š ç»“æœæ±‡æ€»:")
            for name, success in results:
                status = "âœ… æˆåŠŸ" if success else "âŒ å¤±è´¥"
                logger.info(f"   â€¢ {name}: {status}")
        else:
            print("æ— æ•ˆé€‰æ‹©ï¼Œè·³è¿‡ç¤ºä¾‹è¿è¡Œ")
            
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºç¤ºä¾‹è¿è¡Œ")
    except Exception as e:
        logger.error(f"ç¤ºä¾‹è¿è¡Œå‡ºé”™: {e}") 