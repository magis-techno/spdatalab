{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Grid轨迹聚类分析\n",
        "\n",
        "基于`city_hotspots`表的热点grid，对每个200m×200m区域内的高质量轨迹进行聚类分析。\n",
        "\n",
        "## 核心特性\n",
        "\n",
        "- ✅ **数据源优化**：使用city_hotspots（前1%热点）\n",
        "- ✅ **质量过滤**：workstage=2 + 原地不动/GPS跳点检测  \n",
        "- ✅ **切分策略**：距离优先(50米) + 时长上限(15秒)\n",
        "- ✅ **特征提取**：10维特征（速度、加速度、航向、形态）\n",
        "- ✅ **DBSCAN聚类**：自动识别噪声点\n",
        "\n",
        "## 分析流程\n",
        "\n",
        "1. 环境准备和数据检查\n",
        "2. 单Grid深度分析\n",
        "3. 参数调优实验\n",
        "4. 批量处理（可选）\n",
        "5. 结果可视化\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 环境准备\n",
        "\n",
        "首先导入必要的库并设置环境。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 导入库\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 添加bbox_examples目录到路径\n",
        "bbox_examples_path = Path.cwd().parent / 'dataset' / 'bbox_examples'\n",
        "sys.path.insert(0, str(bbox_examples_path))\n",
        "\n",
        "# 导入核心模块（grid_trajectory_clustering.py在bbox_examples目录下）\n",
        "from grid_trajectory_clustering import (\n",
        "    GridTrajectoryClusterer, \n",
        "    ClusterConfig\n",
        ")\n",
        "\n",
        "# 数据处理和可视化\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sqlalchemy import create_engine, text\n",
        "\n",
        "# 设置可视化样式\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"✅ 环境准备完成！\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 检查数据源\n",
        "\n",
        "检查`city_hotspots`表和`ddi_data_points`表是否可用。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 创建数据库连接\n",
        "LOCAL_DSN = \"postgresql+psycopg://postgres:postgres@local_pg:5432/postgres\"\n",
        "engine = create_engine(LOCAL_DSN, future=True)\n",
        "\n",
        "# 检查city_hotspots表\n",
        "with engine.connect() as conn:\n",
        "    result = conn.execute(text(\"\"\"\n",
        "        SELECT city_id, COUNT(*) as grid_count \n",
        "        FROM city_hotspots \n",
        "        GROUP BY city_id \n",
        "        ORDER BY grid_count DESC \n",
        "        LIMIT 10;\n",
        "    \"\"\"))\n",
        "    hotspots_df = pd.DataFrame(result.fetchall(), columns=['city_id', 'grid_count'])\n",
        "\n",
        "print(\"📊 City Hotspots表统计:\")\n",
        "display(hotspots_df)\n",
        "\n",
        "# 检查ddi_data_points表\n",
        "with engine.connect() as conn:\n",
        "    result = conn.execute(text(\"\"\"\n",
        "        SELECT \n",
        "            COUNT(*) as total_points,\n",
        "            COUNT(*) FILTER (WHERE workstage = 2) as quality_points,\n",
        "            ROUND(100.0 * COUNT(*) FILTER (WHERE workstage = 2) / COUNT(*), 2) as quality_ratio\n",
        "        FROM ddi_data_points\n",
        "        WHERE point_lla IS NOT NULL\n",
        "        LIMIT 1;\n",
        "    \"\"\"))\n",
        "    points_stats = result.fetchone()\n",
        "\n",
        "print(f\"\\n📍 轨迹点统计:\")\n",
        "print(f\"   总点数: {points_stats.total_points:,}\")\n",
        "print(f\"   高质量点数 (workstage=2): {points_stats.quality_points:,}\")\n",
        "print(f\"   质量比例: {points_stats.quality_ratio}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 单Grid深度分析\n",
        "\n",
        "选择一个grid进行详细分析，了解完整的处理流程。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 创建聚类器\n",
        "config = ClusterConfig(\n",
        "    min_distance=50,      # 主切分：50米\n",
        "    max_duration=15,      # 强制切分：15秒\n",
        "    min_points=5,         # 最少点数\n",
        "    eps=0.4,              # DBSCAN距离阈值\n",
        "    min_samples=3         # DBSCAN最小样本数\n",
        ")\n",
        "\n",
        "clusterer = GridTrajectoryClusterer(config)\n",
        "\n",
        "# 加载一个grid（选择第一个城市的第一个grid）\n",
        "CITY_ID = hotspots_df.iloc[0]['city_id']  # 使用数据量最大的城市\n",
        "print(f\"🎯 选择城市: {CITY_ID}\")\n",
        "\n",
        "grids = clusterer.load_hotspot_grids(city_id=CITY_ID, limit=1)\n",
        "grid = grids.iloc[0]\n",
        "\n",
        "print(f\"\\n📋 Grid信息:\")\n",
        "print(f\"   Grid ID: {grid['grid_id']}\")\n",
        "print(f\"   城市: {grid['city_id']}\")\n",
        "print(f\"   BBox数量: {grid['bbox_count']}\")\n",
        "print(f\"   Grid坐标: {grid['grid_coords']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 查询轨迹点并可视化\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 查询grid内的轨迹点\n",
        "points = clusterer.query_trajectory_points(grid['geometry'])\n",
        "\n",
        "print(f\"📍 轨迹点统计:\")\n",
        "print(f\"   总点数: {len(points)}\")\n",
        "print(f\"   轨迹数: {points['dataset_name'].nunique()}\")\n",
        "print(f\"   平均速度: {points['twist_linear'].mean():.2f} m/s\")\n",
        "print(f\"   速度范围: {points['twist_linear'].min():.2f} ~ {points['twist_linear'].max():.2f} m/s\")\n",
        "\n",
        "# 可视化轨迹点\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# 左图：按速度着色\n",
        "scatter1 = axes[0].scatter(points['lon'], points['lat'], \n",
        "                           c=points['twist_linear'], cmap='viridis', \n",
        "                           s=2, alpha=0.6)\n",
        "axes[0].set_xlabel('经度')\n",
        "axes[0].set_ylabel('纬度')\n",
        "axes[0].set_title(f'Grid #{grid[\"grid_id\"]} 轨迹点分布（按速度着色）')\n",
        "plt.colorbar(scatter1, ax=axes[0], label='速度 (m/s)')\n",
        "\n",
        "# 右图：速度分布直方图\n",
        "axes[1].hist(points['twist_linear'], bins=50, edgecolor='black', alpha=0.7)\n",
        "axes[1].axvline(points['twist_linear'].mean(), color='red', \n",
        "                linestyle='--', label=f'平均值: {points[\"twist_linear\"].mean():.2f}')\n",
        "axes[1].set_xlabel('速度 (m/s)')\n",
        "axes[1].set_ylabel('频数')\n",
        "axes[1].set_title('速度分布')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 轨迹切分与质量过滤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 切分轨迹段\n",
        "segments = clusterer.segment_trajectories(points)\n",
        "\n",
        "print(f\"✂️ 切分结果:\")\n",
        "print(f\"   轨迹段总数: {len(segments)}\")\n",
        "\n",
        "# 质量过滤\n",
        "quality_stats = {}\n",
        "valid_segments = []\n",
        "\n",
        "for seg in segments:\n",
        "    is_valid, reason = clusterer.filter_segment_quality(seg)\n",
        "    seg.quality_flag = reason\n",
        "    quality_stats[reason] = quality_stats.get(reason, 0) + 1\n",
        "    \n",
        "    if is_valid:\n",
        "        # 提取特征\n",
        "        seg.features = clusterer.extract_features(seg)\n",
        "        valid_segments.append(seg)\n",
        "\n",
        "print(f\"\\n   有效轨迹段: {len(valid_segments)} ({len(valid_segments)/len(segments)*100:.1f}%)\")\n",
        "print(f\"\\n📋 质量过滤统计:\")\n",
        "for reason, count in sorted(quality_stats.items(), key=lambda x: x[1], reverse=True):\n",
        "    print(f\"   {reason:20s}: {count:4d} ({count/len(segments)*100:.1f}%)\")\n",
        "\n",
        "# 可视化质量过滤结果\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# 左图：饼图\n",
        "axes[0].pie(quality_stats.values(), labels=quality_stats.keys(), autopct='%1.1f%%')\n",
        "axes[0].set_title('质量过滤结果分布')\n",
        "\n",
        "# 右图：可视化有效vs无效轨迹\n",
        "for seg in segments[:50]:  # 只显示前50个\n",
        "    if seg.geometry:\n",
        "        x, y = seg.geometry.xy\n",
        "        color = 'green' if seg.quality_flag == 'valid' else 'red'\n",
        "        alpha = 0.7 if seg.quality_flag == 'valid' else 0.3\n",
        "        axes[1].plot(x, y, color=color, alpha=alpha, linewidth=1.5)\n",
        "axes[1].set_xlabel('经度')\n",
        "axes[1].set_ylabel('纬度')\n",
        "axes[1].set_title('轨迹段可视化（绿色=有效，红色=过滤）前50段')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 DBSCAN聚类分析\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 执行聚类\n",
        "labels = clusterer.perform_clustering(valid_segments)\n",
        "\n",
        "# 生成行为标签\n",
        "cluster_info = clusterer.generate_behavior_labels(valid_segments, labels)\n",
        "\n",
        "print(f\"\\n📊 聚类统计:\")\n",
        "print(f\"   聚类数量: {len([l for l in set(labels) if l >= 0])}\")\n",
        "print(f\"   噪声点: {list(labels).count(-1)} ({list(labels).count(-1)/len(labels)*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\n📋 聚类详情:\")\n",
        "summary_data = []\n",
        "for label in sorted(cluster_info.keys()):\n",
        "    info = cluster_info[label]\n",
        "    summary_data.append({\n",
        "        'cluster': label,\n",
        "        'count': info['segment_count'],\n",
        "        'behavior': info['behavior_label'],\n",
        "        'speed_range': info['speed_range'],\n",
        "        'avg_speed': f\"{info['centroid_avg_speed']:.2f}\",\n",
        "        'avg_accel': f\"{info['centroid_avg_acceleration']:.2f}\"\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "display(summary_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 聚类结果可视化\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 聚类结果可视化\n",
        "fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
        "\n",
        "# 图1：空间分布（按cluster着色）\n",
        "colors = plt.cm.tab10(np.linspace(0, 1, len(set(labels))))\n",
        "for seg, label in zip(valid_segments, labels):\n",
        "    if seg.geometry:\n",
        "        x, y = seg.geometry.xy\n",
        "        if label == -1:\n",
        "            axes[0, 0].plot(x, y, color='gray', alpha=0.3, linewidth=1, label='噪声' if label not in [s[1] for s in zip(valid_segments, labels)[:axes[0,0].get_lines().__len__()]] else \"\")\n",
        "        else:\n",
        "            axes[0, 0].plot(x, y, color=colors[label % 10], alpha=0.7, linewidth=2)\n",
        "axes[0, 0].set_xlabel('经度')\n",
        "axes[0, 0].set_ylabel('纬度')\n",
        "axes[0, 0].set_title('聚类结果空间分布')\n",
        "axes[0, 0].legend()\n",
        "\n",
        "# 图2：特征空间（速度 vs 加速度）\n",
        "speeds = [seg.features[0] for seg in valid_segments]\n",
        "accels = [seg.features[4] for seg in valid_segments]\n",
        "scatter = axes[0, 1].scatter(speeds, accels, c=labels, cmap='tab10', s=50, alpha=0.7)\n",
        "axes[0, 1].set_xlabel('平均速度 (m/s)')\n",
        "axes[0, 1].set_ylabel('平均加速度 (m/s²)')\n",
        "axes[0, 1].set_title('特征空间聚类结果')\n",
        "plt.colorbar(scatter, ax=axes[0, 1], label='cluster_label')\n",
        "\n",
        "# 图3：聚类大小分布\n",
        "cluster_sizes = [info['segment_count'] for info in cluster_info.values()]\n",
        "cluster_labels_list = list(cluster_info.keys())\n",
        "axes[1, 0].bar(range(len(cluster_labels_list)), cluster_sizes, color=colors)\n",
        "axes[1, 0].set_xlabel('Cluster Label')\n",
        "axes[1, 0].set_ylabel('轨迹段数量')\n",
        "axes[1, 0].set_title('聚类大小分布')\n",
        "axes[1, 0].set_xticks(range(len(cluster_labels_list)))\n",
        "axes[1, 0].set_xticklabels(cluster_labels_list)\n",
        "\n",
        "# 图4：速度分布（按cluster）\n",
        "for label in sorted(set(labels)):\n",
        "    if label >= 0:\n",
        "        label_speeds = [seg.features[0] for seg, l in zip(valid_segments, labels) if l == label]\n",
        "        axes[1, 1].hist(label_speeds, bins=20, alpha=0.5, \n",
        "                       label=f'Cluster {label}', edgecolor='black')\n",
        "axes[1, 1].set_xlabel('平均速度 (m/s)')\n",
        "axes[1, 1].set_ylabel('频数')\n",
        "axes[1, 1].set_title('各聚类速度分布')\n",
        "axes[1, 1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.5 保存到数据库\n",
        "\n",
        "将聚类结果保存到数据库，供后续分析使用。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 保存结果\n",
        "analysis_id = f\"notebook_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "\n",
        "clusterer.save_results(\n",
        "    grid_id=grid['grid_id'],\n",
        "    city_id=grid['city_id'],\n",
        "    analysis_id=analysis_id,\n",
        "    segments=valid_segments,\n",
        "    labels=labels,\n",
        "    cluster_info=cluster_info\n",
        ")\n",
        "\n",
        "print(f\"✅ 结果已保存到数据库\")\n",
        "print(f\"   Analysis ID: {analysis_id}\")\n",
        "print(f\"   Grid ID: {grid['grid_id']}\")\n",
        "print(f\"\\n💡 查询结果:\")\n",
        "print(f\"   SELECT * FROM grid_trajectory_segments WHERE grid_id = {grid['grid_id']};\")\n",
        "print(f\"   SELECT * FROM grid_clustering_summary WHERE grid_id = {grid['grid_id']};\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 参数调优实验\n",
        "\n",
        "测试不同的聚类参数，观察对聚类结果的影响。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 测试不同的eps参数\n",
        "eps_values = [0.3, 0.4, 0.6]\n",
        "comparison_results = []\n",
        "\n",
        "fig, axes = plt.subplots(1, len(eps_values), figsize=(18, 5))\n",
        "\n",
        "for idx, eps in enumerate(eps_values):\n",
        "    # 创建临时聚类器\n",
        "    temp_config = ClusterConfig(eps=eps, min_samples=3)\n",
        "    temp_clusterer = GridTrajectoryClusterer(temp_config)\n",
        "    \n",
        "    # 执行聚类\n",
        "    temp_labels = temp_clusterer.perform_clustering(valid_segments)\n",
        "    \n",
        "    # 统计\n",
        "    n_clusters = len([l for l in set(temp_labels) if l >= 0])\n",
        "    n_noise = list(temp_labels).count(-1)\n",
        "    \n",
        "    comparison_results.append({\n",
        "        'eps': eps,\n",
        "        'n_clusters': n_clusters,\n",
        "        'n_noise': n_noise,\n",
        "        'noise_ratio': n_noise / len(temp_labels) * 100\n",
        "    })\n",
        "    \n",
        "    # 可视化\n",
        "    for seg, label in zip(valid_segments, temp_labels):\n",
        "        if seg.geometry:\n",
        "            x, y = seg.geometry.xy\n",
        "            if label == -1:\n",
        "                axes[idx].plot(x, y, color='gray', alpha=0.3, linewidth=1)\n",
        "            else:\n",
        "                axes[idx].plot(x, y, color=colors[label % 10], alpha=0.7, linewidth=2)\n",
        "    axes[idx].set_title(f'eps={eps}\\n聚类数:{n_clusters}, 噪声:{n_noise}')\n",
        "    axes[idx].set_xlabel('经度')\n",
        "    axes[idx].set_ylabel('纬度')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 显示对比表\n",
        "comparison_df = pd.DataFrame(comparison_results)\n",
        "print(\"\\n📊 参数对比:\")\n",
        "display(comparison_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 总结与下一步\n",
        "\n",
        "### 分析要点\n",
        "\n",
        "1. **数据质量**：workstage=2过滤确保了轨迹点的质量\n",
        "2. **切分策略**：50米/15秒的混合策略确保30秒轨迹<5段\n",
        "3. **聚类效果**：DBSCAN自动识别2-5个行为模式和噪声点\n",
        "4. **可解释性**：通过行为标签理解各聚类的驾驶特征\n",
        "\n",
        "### 下一步扩展\n",
        "\n",
        "- **批量处理**：使用命令行工具处理多个grids  \n",
        "  ```bash\n",
        "  python examples/dataset/bbox_examples/grid_clustering_analysis.py --city A72 --top-n 5\n",
        "  ```\n",
        "\n",
        "- **邻接Grid拼接**：合并相邻grid的聚类结果\n",
        "- **时间维度分析**：按时段进行聚类对比\n",
        "- **Parquet标签集成**：引入clip级别的丰富标签\n",
        "- **场景筛选**：基于聚类结果构建数据集\n",
        "\n",
        "### 可视化建议\n",
        "\n",
        "- **QGIS**：加载`grid_trajectory_segments`表，按`cluster_label`着色\n",
        "- **GeoJSON导出**：使用`--export-geojson`参数导出结果\n",
        "- **交互式地图**：可集成folium实现web可视化\n",
        "\n",
        "### 常见问题\n",
        "\n",
        "**Q: 聚类数量太少/太多？**  \n",
        "A: 调整`eps`参数（减小增加聚类数，增大减少聚类数）\n",
        "\n",
        "**Q: 噪声点过多？**  \n",
        "A: 增大`eps`或减小`min_samples`\n",
        "\n",
        "**Q: 有效轨迹段比例低？**  \n",
        "A: 降低质量过滤阈值（`min_movement`, `max_jump`）\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
