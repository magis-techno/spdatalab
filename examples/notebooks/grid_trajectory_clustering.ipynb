{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gridè½¨è¿¹èšç±»åˆ†æ\n",
        "\n",
        "åŸºäº`city_hotspots`è¡¨çš„çƒ­ç‚¹gridï¼Œå¯¹æ¯ä¸ª200mÃ—200måŒºåŸŸå†…çš„é«˜è´¨é‡è½¨è¿¹è¿›è¡Œèšç±»åˆ†æã€‚\n",
        "\n",
        "## æ ¸å¿ƒç‰¹æ€§\n",
        "\n",
        "- âœ… **æ•°æ®æºä¼˜åŒ–**ï¼šä½¿ç”¨city_hotspotsï¼ˆå‰1%çƒ­ç‚¹ï¼‰\n",
        "- âœ… **è´¨é‡è¿‡æ»¤**ï¼šworkstage=2 + åŸåœ°ä¸åŠ¨/GPSè·³ç‚¹æ£€æµ‹  \n",
        "- âœ… **åˆ‡åˆ†ç­–ç•¥**ï¼šè·ç¦»ä¼˜å…ˆ(50ç±³) + æ—¶é•¿ä¸Šé™(15ç§’)\n",
        "- âœ… **ç‰¹å¾æå–**ï¼š10ç»´ç‰¹å¾ï¼ˆé€Ÿåº¦ã€åŠ é€Ÿåº¦ã€èˆªå‘ã€å½¢æ€ï¼‰\n",
        "- âœ… **DBSCANèšç±»**ï¼šè‡ªåŠ¨è¯†åˆ«å™ªå£°ç‚¹\n",
        "\n",
        "## åˆ†ææµç¨‹\n",
        "\n",
        "1. ç¯å¢ƒå‡†å¤‡å’Œæ•°æ®æ£€æŸ¥\n",
        "2. å•Gridæ·±åº¦åˆ†æ\n",
        "3. å‚æ•°è°ƒä¼˜å®éªŒ\n",
        "4. æ‰¹é‡å¤„ç†ï¼ˆå¯é€‰ï¼‰\n",
        "5. ç»“æœå¯è§†åŒ–\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. ç¯å¢ƒå‡†å¤‡\n",
        "\n",
        "é¦–å…ˆå¯¼å…¥å¿…è¦çš„åº“å¹¶è®¾ç½®ç¯å¢ƒã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å¯¼å…¥åº“\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# æ·»åŠ bbox_examplesç›®å½•åˆ°è·¯å¾„\n",
        "bbox_examples_path = Path.cwd().parent / 'dataset' / 'bbox_examples'\n",
        "sys.path.insert(0, str(bbox_examples_path))\n",
        "\n",
        "# å¯¼å…¥æ ¸å¿ƒæ¨¡å—ï¼ˆgrid_trajectory_clustering.pyåœ¨bbox_examplesç›®å½•ä¸‹ï¼‰\n",
        "from grid_trajectory_clustering import (\n",
        "    GridTrajectoryClusterer, \n",
        "    ClusterConfig\n",
        ")\n",
        "\n",
        "# æ•°æ®å¤„ç†å’Œå¯è§†åŒ–\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sqlalchemy import create_engine, text\n",
        "\n",
        "# è®¾ç½®å¯è§†åŒ–æ ·å¼\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"âœ… ç¯å¢ƒå‡†å¤‡å®Œæˆï¼\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1 æ£€æŸ¥æ•°æ®æº\n",
        "\n",
        "æ£€æŸ¥`city_hotspots`è¡¨å’Œ`ddi_data_points`è¡¨æ˜¯å¦å¯ç”¨ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# åˆ›å»ºæ•°æ®åº“è¿æ¥\n",
        "LOCAL_DSN = \"postgresql+psycopg://postgres:postgres@local_pg:5432/postgres\"\n",
        "engine = create_engine(LOCAL_DSN, future=True)\n",
        "\n",
        "# æ£€æŸ¥city_hotspotsè¡¨\n",
        "with engine.connect() as conn:\n",
        "    result = conn.execute(text(\"\"\"\n",
        "        SELECT city_id, COUNT(*) as grid_count \n",
        "        FROM city_hotspots \n",
        "        GROUP BY city_id \n",
        "        ORDER BY grid_count DESC \n",
        "        LIMIT 10;\n",
        "    \"\"\"))\n",
        "    hotspots_df = pd.DataFrame(result.fetchall(), columns=['city_id', 'grid_count'])\n",
        "\n",
        "print(\"ğŸ“Š City Hotspotsè¡¨ç»Ÿè®¡:\")\n",
        "display(hotspots_df)\n",
        "\n",
        "# æ£€æŸ¥ddi_data_pointsè¡¨\n",
        "with engine.connect() as conn:\n",
        "    result = conn.execute(text(\"\"\"\n",
        "        SELECT \n",
        "            COUNT(*) as total_points,\n",
        "            COUNT(*) FILTER (WHERE workstage = 2) as quality_points,\n",
        "            ROUND(100.0 * COUNT(*) FILTER (WHERE workstage = 2) / COUNT(*), 2) as quality_ratio\n",
        "        FROM ddi_data_points\n",
        "        WHERE point_lla IS NOT NULL\n",
        "        LIMIT 1;\n",
        "    \"\"\"))\n",
        "    points_stats = result.fetchone()\n",
        "\n",
        "print(f\"\\nğŸ“ è½¨è¿¹ç‚¹ç»Ÿè®¡:\")\n",
        "print(f\"   æ€»ç‚¹æ•°: {points_stats.total_points:,}\")\n",
        "print(f\"   é«˜è´¨é‡ç‚¹æ•° (workstage=2): {points_stats.quality_points:,}\")\n",
        "print(f\"   è´¨é‡æ¯”ä¾‹: {points_stats.quality_ratio}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. å•Gridæ·±åº¦åˆ†æ\n",
        "\n",
        "é€‰æ‹©ä¸€ä¸ªgridè¿›è¡Œè¯¦ç»†åˆ†æï¼Œäº†è§£å®Œæ•´çš„å¤„ç†æµç¨‹ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# åˆ›å»ºèšç±»å™¨\n",
        "config = ClusterConfig(\n",
        "    min_distance=50,      # ä¸»åˆ‡åˆ†ï¼š50ç±³\n",
        "    max_duration=15,      # å¼ºåˆ¶åˆ‡åˆ†ï¼š15ç§’\n",
        "    min_points=5,         # æœ€å°‘ç‚¹æ•°\n",
        "    eps=0.4,              # DBSCANè·ç¦»é˜ˆå€¼\n",
        "    min_samples=3         # DBSCANæœ€å°æ ·æœ¬æ•°\n",
        ")\n",
        "\n",
        "clusterer = GridTrajectoryClusterer(config)\n",
        "\n",
        "# åŠ è½½ä¸€ä¸ªgridï¼ˆé€‰æ‹©ç¬¬ä¸€ä¸ªåŸå¸‚çš„ç¬¬ä¸€ä¸ªgridï¼‰\n",
        "CITY_ID = hotspots_df.iloc[0]['city_id']  # ä½¿ç”¨æ•°æ®é‡æœ€å¤§çš„åŸå¸‚\n",
        "print(f\"ğŸ¯ é€‰æ‹©åŸå¸‚: {CITY_ID}\")\n",
        "\n",
        "grids = clusterer.load_hotspot_grids(city_id=CITY_ID, limit=1)\n",
        "grid = grids.iloc[0]\n",
        "\n",
        "print(f\"\\nğŸ“‹ Gridä¿¡æ¯:\")\n",
        "print(f\"   Grid ID: {grid['grid_id']}\")\n",
        "print(f\"   åŸå¸‚: {grid['city_id']}\")\n",
        "print(f\"   BBoxæ•°é‡: {grid['bbox_count']}\")\n",
        "print(f\"   Gridåæ ‡: {grid['grid_coords']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 æŸ¥è¯¢è½¨è¿¹ç‚¹å¹¶å¯è§†åŒ–\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æŸ¥è¯¢gridå†…çš„è½¨è¿¹ç‚¹\n",
        "points = clusterer.query_trajectory_points(grid['geometry'])\n",
        "\n",
        "print(f\"ğŸ“ è½¨è¿¹ç‚¹ç»Ÿè®¡:\")\n",
        "print(f\"   æ€»ç‚¹æ•°: {len(points)}\")\n",
        "print(f\"   è½¨è¿¹æ•°: {points['dataset_name'].nunique()}\")\n",
        "print(f\"   å¹³å‡é€Ÿåº¦: {points['twist_linear'].mean():.2f} m/s\")\n",
        "print(f\"   é€Ÿåº¦èŒƒå›´: {points['twist_linear'].min():.2f} ~ {points['twist_linear'].max():.2f} m/s\")\n",
        "\n",
        "# å¯è§†åŒ–è½¨è¿¹ç‚¹\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# å·¦å›¾ï¼šæŒ‰é€Ÿåº¦ç€è‰²\n",
        "scatter1 = axes[0].scatter(points['lon'], points['lat'], \n",
        "                           c=points['twist_linear'], cmap='viridis', \n",
        "                           s=2, alpha=0.6)\n",
        "axes[0].set_xlabel('ç»åº¦')\n",
        "axes[0].set_ylabel('çº¬åº¦')\n",
        "axes[0].set_title(f'Grid #{grid[\"grid_id\"]} è½¨è¿¹ç‚¹åˆ†å¸ƒï¼ˆæŒ‰é€Ÿåº¦ç€è‰²ï¼‰')\n",
        "plt.colorbar(scatter1, ax=axes[0], label='é€Ÿåº¦ (m/s)')\n",
        "\n",
        "# å³å›¾ï¼šé€Ÿåº¦åˆ†å¸ƒç›´æ–¹å›¾\n",
        "axes[1].hist(points['twist_linear'], bins=50, edgecolor='black', alpha=0.7)\n",
        "axes[1].axvline(points['twist_linear'].mean(), color='red', \n",
        "                linestyle='--', label=f'å¹³å‡å€¼: {points[\"twist_linear\"].mean():.2f}')\n",
        "axes[1].set_xlabel('é€Ÿåº¦ (m/s)')\n",
        "axes[1].set_ylabel('é¢‘æ•°')\n",
        "axes[1].set_title('é€Ÿåº¦åˆ†å¸ƒ')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 è½¨è¿¹åˆ‡åˆ†ä¸è´¨é‡è¿‡æ»¤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# åˆ‡åˆ†è½¨è¿¹æ®µ\n",
        "segments = clusterer.segment_trajectories(points)\n",
        "\n",
        "print(f\"âœ‚ï¸ åˆ‡åˆ†ç»“æœ:\")\n",
        "print(f\"   è½¨è¿¹æ®µæ€»æ•°: {len(segments)}\")\n",
        "\n",
        "# è´¨é‡è¿‡æ»¤\n",
        "quality_stats = {}\n",
        "valid_segments = []\n",
        "\n",
        "for seg in segments:\n",
        "    is_valid, reason = clusterer.filter_segment_quality(seg)\n",
        "    seg.quality_flag = reason\n",
        "    quality_stats[reason] = quality_stats.get(reason, 0) + 1\n",
        "    \n",
        "    if is_valid:\n",
        "        # æå–ç‰¹å¾\n",
        "        seg.features = clusterer.extract_features(seg)\n",
        "        valid_segments.append(seg)\n",
        "\n",
        "print(f\"\\n   æœ‰æ•ˆè½¨è¿¹æ®µ: {len(valid_segments)} ({len(valid_segments)/len(segments)*100:.1f}%)\")\n",
        "print(f\"\\nğŸ“‹ è´¨é‡è¿‡æ»¤ç»Ÿè®¡:\")\n",
        "for reason, count in sorted(quality_stats.items(), key=lambda x: x[1], reverse=True):\n",
        "    print(f\"   {reason:20s}: {count:4d} ({count/len(segments)*100:.1f}%)\")\n",
        "\n",
        "# å¯è§†åŒ–è´¨é‡è¿‡æ»¤ç»“æœ\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# å·¦å›¾ï¼šé¥¼å›¾\n",
        "axes[0].pie(quality_stats.values(), labels=quality_stats.keys(), autopct='%1.1f%%')\n",
        "axes[0].set_title('è´¨é‡è¿‡æ»¤ç»“æœåˆ†å¸ƒ')\n",
        "\n",
        "# å³å›¾ï¼šå¯è§†åŒ–æœ‰æ•ˆvsæ— æ•ˆè½¨è¿¹\n",
        "for seg in segments[:50]:  # åªæ˜¾ç¤ºå‰50ä¸ª\n",
        "    if seg.geometry:\n",
        "        x, y = seg.geometry.xy\n",
        "        color = 'green' if seg.quality_flag == 'valid' else 'red'\n",
        "        alpha = 0.7 if seg.quality_flag == 'valid' else 0.3\n",
        "        axes[1].plot(x, y, color=color, alpha=alpha, linewidth=1.5)\n",
        "axes[1].set_xlabel('ç»åº¦')\n",
        "axes[1].set_ylabel('çº¬åº¦')\n",
        "axes[1].set_title('è½¨è¿¹æ®µå¯è§†åŒ–ï¼ˆç»¿è‰²=æœ‰æ•ˆï¼Œçº¢è‰²=è¿‡æ»¤ï¼‰å‰50æ®µ')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 DBSCANèšç±»åˆ†æ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æ‰§è¡Œèšç±»\n",
        "labels = clusterer.perform_clustering(valid_segments)\n",
        "\n",
        "# ç”Ÿæˆè¡Œä¸ºæ ‡ç­¾\n",
        "cluster_info = clusterer.generate_behavior_labels(valid_segments, labels)\n",
        "\n",
        "print(f\"\\nğŸ“Š èšç±»ç»Ÿè®¡:\")\n",
        "print(f\"   èšç±»æ•°é‡: {len([l for l in set(labels) if l >= 0])}\")\n",
        "print(f\"   å™ªå£°ç‚¹: {list(labels).count(-1)} ({list(labels).count(-1)/len(labels)*100:.1f}%)\")\n",
        "\n",
        "print(f\"\\nğŸ“‹ èšç±»è¯¦æƒ…:\")\n",
        "summary_data = []\n",
        "for label in sorted(cluster_info.keys()):\n",
        "    info = cluster_info[label]\n",
        "    summary_data.append({\n",
        "        'cluster': label,\n",
        "        'count': info['segment_count'],\n",
        "        'behavior': info['behavior_label'],\n",
        "        'speed_range': info['speed_range'],\n",
        "        'avg_speed': f\"{info['centroid_avg_speed']:.2f}\",\n",
        "        'avg_accel': f\"{info['centroid_avg_acceleration']:.2f}\"\n",
        "    })\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "display(summary_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 èšç±»ç»“æœå¯è§†åŒ–\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# èšç±»ç»“æœå¯è§†åŒ–\n",
        "fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
        "\n",
        "# å›¾1ï¼šç©ºé—´åˆ†å¸ƒï¼ˆæŒ‰clusterç€è‰²ï¼‰\n",
        "colors = plt.cm.tab10(np.linspace(0, 1, len(set(labels))))\n",
        "for seg, label in zip(valid_segments, labels):\n",
        "    if seg.geometry:\n",
        "        x, y = seg.geometry.xy\n",
        "        if label == -1:\n",
        "            axes[0, 0].plot(x, y, color='gray', alpha=0.3, linewidth=1, label='å™ªå£°' if label not in [s[1] for s in zip(valid_segments, labels)[:axes[0,0].get_lines().__len__()]] else \"\")\n",
        "        else:\n",
        "            axes[0, 0].plot(x, y, color=colors[label % 10], alpha=0.7, linewidth=2)\n",
        "axes[0, 0].set_xlabel('ç»åº¦')\n",
        "axes[0, 0].set_ylabel('çº¬åº¦')\n",
        "axes[0, 0].set_title('èšç±»ç»“æœç©ºé—´åˆ†å¸ƒ')\n",
        "axes[0, 0].legend()\n",
        "\n",
        "# å›¾2ï¼šç‰¹å¾ç©ºé—´ï¼ˆé€Ÿåº¦ vs åŠ é€Ÿåº¦ï¼‰\n",
        "speeds = [seg.features[0] for seg in valid_segments]\n",
        "accels = [seg.features[4] for seg in valid_segments]\n",
        "scatter = axes[0, 1].scatter(speeds, accels, c=labels, cmap='tab10', s=50, alpha=0.7)\n",
        "axes[0, 1].set_xlabel('å¹³å‡é€Ÿåº¦ (m/s)')\n",
        "axes[0, 1].set_ylabel('å¹³å‡åŠ é€Ÿåº¦ (m/sÂ²)')\n",
        "axes[0, 1].set_title('ç‰¹å¾ç©ºé—´èšç±»ç»“æœ')\n",
        "plt.colorbar(scatter, ax=axes[0, 1], label='cluster_label')\n",
        "\n",
        "# å›¾3ï¼šèšç±»å¤§å°åˆ†å¸ƒ\n",
        "cluster_sizes = [info['segment_count'] for info in cluster_info.values()]\n",
        "cluster_labels_list = list(cluster_info.keys())\n",
        "axes[1, 0].bar(range(len(cluster_labels_list)), cluster_sizes, color=colors)\n",
        "axes[1, 0].set_xlabel('Cluster Label')\n",
        "axes[1, 0].set_ylabel('è½¨è¿¹æ®µæ•°é‡')\n",
        "axes[1, 0].set_title('èšç±»å¤§å°åˆ†å¸ƒ')\n",
        "axes[1, 0].set_xticks(range(len(cluster_labels_list)))\n",
        "axes[1, 0].set_xticklabels(cluster_labels_list)\n",
        "\n",
        "# å›¾4ï¼šé€Ÿåº¦åˆ†å¸ƒï¼ˆæŒ‰clusterï¼‰\n",
        "for label in sorted(set(labels)):\n",
        "    if label >= 0:\n",
        "        label_speeds = [seg.features[0] for seg, l in zip(valid_segments, labels) if l == label]\n",
        "        axes[1, 1].hist(label_speeds, bins=20, alpha=0.5, \n",
        "                       label=f'Cluster {label}', edgecolor='black')\n",
        "axes[1, 1].set_xlabel('å¹³å‡é€Ÿåº¦ (m/s)')\n",
        "axes[1, 1].set_ylabel('é¢‘æ•°')\n",
        "axes[1, 1].set_title('å„èšç±»é€Ÿåº¦åˆ†å¸ƒ')\n",
        "axes[1, 1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.5 ä¿å­˜åˆ°æ•°æ®åº“\n",
        "\n",
        "å°†èšç±»ç»“æœä¿å­˜åˆ°æ•°æ®åº“ï¼Œä¾›åç»­åˆ†æä½¿ç”¨ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ä¿å­˜ç»“æœ\n",
        "analysis_id = f\"notebook_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "\n",
        "clusterer.save_results(\n",
        "    grid_id=grid['grid_id'],\n",
        "    city_id=grid['city_id'],\n",
        "    analysis_id=analysis_id,\n",
        "    segments=valid_segments,\n",
        "    labels=labels,\n",
        "    cluster_info=cluster_info\n",
        ")\n",
        "\n",
        "print(f\"âœ… ç»“æœå·²ä¿å­˜åˆ°æ•°æ®åº“\")\n",
        "print(f\"   Analysis ID: {analysis_id}\")\n",
        "print(f\"   Grid ID: {grid['grid_id']}\")\n",
        "print(f\"\\nğŸ’¡ æŸ¥è¯¢ç»“æœ:\")\n",
        "print(f\"   SELECT * FROM grid_trajectory_segments WHERE grid_id = {grid['grid_id']};\")\n",
        "print(f\"   SELECT * FROM grid_clustering_summary WHERE grid_id = {grid['grid_id']};\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. å‚æ•°è°ƒä¼˜å®éªŒ\n",
        "\n",
        "æµ‹è¯•ä¸åŒçš„èšç±»å‚æ•°ï¼Œè§‚å¯Ÿå¯¹èšç±»ç»“æœçš„å½±å“ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æµ‹è¯•ä¸åŒçš„epså‚æ•°\n",
        "eps_values = [0.3, 0.4, 0.6]\n",
        "comparison_results = []\n",
        "\n",
        "fig, axes = plt.subplots(1, len(eps_values), figsize=(18, 5))\n",
        "\n",
        "for idx, eps in enumerate(eps_values):\n",
        "    # åˆ›å»ºä¸´æ—¶èšç±»å™¨\n",
        "    temp_config = ClusterConfig(eps=eps, min_samples=3)\n",
        "    temp_clusterer = GridTrajectoryClusterer(temp_config)\n",
        "    \n",
        "    # æ‰§è¡Œèšç±»\n",
        "    temp_labels = temp_clusterer.perform_clustering(valid_segments)\n",
        "    \n",
        "    # ç»Ÿè®¡\n",
        "    n_clusters = len([l for l in set(temp_labels) if l >= 0])\n",
        "    n_noise = list(temp_labels).count(-1)\n",
        "    \n",
        "    comparison_results.append({\n",
        "        'eps': eps,\n",
        "        'n_clusters': n_clusters,\n",
        "        'n_noise': n_noise,\n",
        "        'noise_ratio': n_noise / len(temp_labels) * 100\n",
        "    })\n",
        "    \n",
        "    # å¯è§†åŒ–\n",
        "    for seg, label in zip(valid_segments, temp_labels):\n",
        "        if seg.geometry:\n",
        "            x, y = seg.geometry.xy\n",
        "            if label == -1:\n",
        "                axes[idx].plot(x, y, color='gray', alpha=0.3, linewidth=1)\n",
        "            else:\n",
        "                axes[idx].plot(x, y, color=colors[label % 10], alpha=0.7, linewidth=2)\n",
        "    axes[idx].set_title(f'eps={eps}\\nèšç±»æ•°:{n_clusters}, å™ªå£°:{n_noise}')\n",
        "    axes[idx].set_xlabel('ç»åº¦')\n",
        "    axes[idx].set_ylabel('çº¬åº¦')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# æ˜¾ç¤ºå¯¹æ¯”è¡¨\n",
        "comparison_df = pd.DataFrame(comparison_results)\n",
        "print(\"\\nğŸ“Š å‚æ•°å¯¹æ¯”:\")\n",
        "display(comparison_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. æ€»ç»“ä¸ä¸‹ä¸€æ­¥\n",
        "\n",
        "### åˆ†æè¦ç‚¹\n",
        "\n",
        "1. **æ•°æ®è´¨é‡**ï¼šworkstage=2è¿‡æ»¤ç¡®ä¿äº†è½¨è¿¹ç‚¹çš„è´¨é‡\n",
        "2. **åˆ‡åˆ†ç­–ç•¥**ï¼š50ç±³/15ç§’çš„æ··åˆç­–ç•¥ç¡®ä¿30ç§’è½¨è¿¹<5æ®µ\n",
        "3. **èšç±»æ•ˆæœ**ï¼šDBSCANè‡ªåŠ¨è¯†åˆ«2-5ä¸ªè¡Œä¸ºæ¨¡å¼å’Œå™ªå£°ç‚¹\n",
        "4. **å¯è§£é‡Šæ€§**ï¼šé€šè¿‡è¡Œä¸ºæ ‡ç­¾ç†è§£å„èšç±»çš„é©¾é©¶ç‰¹å¾\n",
        "\n",
        "### ä¸‹ä¸€æ­¥æ‰©å±•\n",
        "\n",
        "- **æ‰¹é‡å¤„ç†**ï¼šä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·å¤„ç†å¤šä¸ªgrids  \n",
        "  ```bash\n",
        "  python examples/dataset/bbox_examples/grid_clustering_analysis.py --city A72 --top-n 5\n",
        "  ```\n",
        "\n",
        "- **é‚»æ¥Gridæ‹¼æ¥**ï¼šåˆå¹¶ç›¸é‚»gridçš„èšç±»ç»“æœ\n",
        "- **æ—¶é—´ç»´åº¦åˆ†æ**ï¼šæŒ‰æ—¶æ®µè¿›è¡Œèšç±»å¯¹æ¯”\n",
        "- **Parquetæ ‡ç­¾é›†æˆ**ï¼šå¼•å…¥clipçº§åˆ«çš„ä¸°å¯Œæ ‡ç­¾\n",
        "- **åœºæ™¯ç­›é€‰**ï¼šåŸºäºèšç±»ç»“æœæ„å»ºæ•°æ®é›†\n",
        "\n",
        "### å¯è§†åŒ–å»ºè®®\n",
        "\n",
        "- **QGIS**ï¼šåŠ è½½`grid_trajectory_segments`è¡¨ï¼ŒæŒ‰`cluster_label`ç€è‰²\n",
        "- **GeoJSONå¯¼å‡º**ï¼šä½¿ç”¨`--export-geojson`å‚æ•°å¯¼å‡ºç»“æœ\n",
        "- **äº¤äº’å¼åœ°å›¾**ï¼šå¯é›†æˆfoliumå®ç°webå¯è§†åŒ–\n",
        "\n",
        "### å¸¸è§é—®é¢˜\n",
        "\n",
        "**Q: èšç±»æ•°é‡å¤ªå°‘/å¤ªå¤šï¼Ÿ**  \n",
        "A: è°ƒæ•´`eps`å‚æ•°ï¼ˆå‡å°å¢åŠ èšç±»æ•°ï¼Œå¢å¤§å‡å°‘èšç±»æ•°ï¼‰\n",
        "\n",
        "**Q: å™ªå£°ç‚¹è¿‡å¤šï¼Ÿ**  \n",
        "A: å¢å¤§`eps`æˆ–å‡å°`min_samples`\n",
        "\n",
        "**Q: æœ‰æ•ˆè½¨è¿¹æ®µæ¯”ä¾‹ä½ï¼Ÿ**  \n",
        "A: é™ä½è´¨é‡è¿‡æ»¤é˜ˆå€¼ï¼ˆ`min_movement`, `max_jump`ï¼‰\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
