{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# åŸå¸‚çƒ­ç‚¹åˆ†æ - æ‰¹é‡Gridå¯†åº¦åˆ†æ\n",
        "\n",
        "## ğŸ“‹ åˆ†æç›®æ ‡\n",
        "- éå†æ‰€æœ‰åŸå¸‚ï¼Œç”Ÿæˆgridå¯†åº¦æ•°æ®\n",
        "- æå–æ¯ä¸ªåŸå¸‚çš„topçƒ­ç‚¹åŒºåŸŸï¼ˆæ”¯æŒtop-næˆ–top-percentæ¨¡å¼ï¼‰\n",
        "- ç”Ÿæˆæ±‡æ€»è¡¨ç”¨äºåç»­åˆ†æå’Œå¯è§†åŒ–\n",
        "- æ”¯æŒæŒ‡å®šåŸå¸‚åˆ—è¡¨æˆ–å…¨é‡åˆ†æ\n",
        "\n",
        "## ğŸ“Š æ•°æ®æº\n",
        "- **è¾“å…¥è¡¨**: `clips_bbox_unified` - åŸå¸‚bboxæ•°æ®\n",
        "- **åˆ†æè¡¨**: `bbox_overlap_analysis_results` - é‡å åˆ†æç»“æœ\n",
        "- **å¯†åº¦è¡¨**: `city_grid_density` - åŸå¸‚ç½‘æ ¼å¯†åº¦ç»Ÿè®¡\n",
        "- **è¾“å‡ºè¡¨**: `city_hotspots` - åŸå¸‚çƒ­ç‚¹æ±‡æ€»ï¼ˆé»˜è®¤è¡¨åï¼‰\n",
        "\n",
        "## âš™ï¸ è¿è¡Œè¯´æ˜\n",
        "- æœ¬notebookåŸºäº `batch_grid_analysis.py` æ”¹é€ \n",
        "- å¯ä»¥é€æ­¥æ‰§è¡ŒæŸ¥çœ‹ä¸­é—´ç»“æœ\n",
        "- æ”¯æŒå‚æ•°è°ƒæ•´å’Œç»“æœéªŒè¯\n",
        "- ä¸æŒ‡å®šåŸå¸‚æ—¶è‡ªåŠ¨åˆ†ææ‰€æœ‰åŸå¸‚\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. ç¯å¢ƒè®¾ç½®å’Œå¯¼å…¥\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import subprocess\n",
        "import time\n",
        "import json\n",
        "\n",
        "# æ·»åŠ é¡¹ç›®è·¯å¾„\n",
        "project_root = Path().resolve().parent.parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "sys.path.insert(0, str(project_root / \"src\"))\n",
        "\n",
        "from spdatalab.dataset.bbox import LOCAL_DSN\n",
        "from sqlalchemy import create_engine, text\n",
        "import pandas as pd\n",
        "\n",
        "print(f\"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {project_root}\")\n",
        "print(f\"ğŸ”— æ•°æ®åº“è¿æ¥: {LOCAL_DSN[:50]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. å‚æ•°é…ç½®\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ğŸ¯ åˆ†æå‚æ•°é…ç½®\n",
        "CONFIG = {\n",
        "    'output_table': 'city_top1_hotspots',  # è¾“å‡ºæ±‡æ€»è¡¨å\n",
        "    'target_cities': None,  # æŒ‡å®šåŸå¸‚åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºåˆ†ææ‰€æœ‰åŸå¸‚\n",
        "    'max_cities': 3,     # æœ€å¤šåˆ†æåŸå¸‚æ•°é‡ï¼ŒNoneè¡¨ç¤ºæ— é™åˆ¶ (æµ‹è¯•ç”¨è®¾ä¸º3)\n",
        "    'grid_size': '0.002',   # ç½‘æ ¼å¤§å°\n",
        "    'density_threshold': '5', # å¯†åº¦é˜ˆå€¼\n",
        "    'batch_rest_interval': 10  # æ¯Nä¸ªåŸå¸‚ä¼‘æ¯ä¸€ä¸‹\n",
        "}\n",
        "\n",
        "print(\"ğŸ“‹ å½“å‰é…ç½®:\")\n",
        "for key, value in CONFIG.items():\n",
        "    print(f\"   {key}: {value}\")\n",
        "    \n",
        "print(\"\\nğŸ’¡ æç¤º: é¦–æ¬¡è¿è¡Œå»ºè®®ä¿æŒ max_cities=3 è¿›è¡Œæµ‹è¯•\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. æ•°æ®åº“è¿æ¥å’ŒåŸºç¡€æŸ¥è¯¢\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# å»ºç«‹æ•°æ®åº“è¿æ¥\n",
        "engine = create_engine(LOCAL_DSN, future=True)\n",
        "conn = engine.connect()\n",
        "\n",
        "print(\"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. åˆ›å»ºæ±‡æ€»è¡¨\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_top1_summary_table(conn, table_name):\n",
        "    \"\"\"åˆ›å»ºtop1æ±‡æ€»è¡¨\"\"\"\n",
        "    print(f\"ğŸ“‹ åˆ›å»ºæ±‡æ€»è¡¨: {table_name}\")\n",
        "    \n",
        "    # å…ˆæ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨\n",
        "    check_table_sql = text(f\"\"\"\n",
        "        SELECT EXISTS (\n",
        "            SELECT FROM information_schema.tables \n",
        "            WHERE table_schema = 'public' \n",
        "            AND table_name = '{table_name}'\n",
        "        );\n",
        "    \"\"\")\n",
        "    \n",
        "    table_exists = conn.execute(check_table_sql).scalar()\n",
        "    \n",
        "    if not table_exists:\n",
        "        # åˆ›å»ºæ–°è¡¨\n",
        "        create_sql = text(f\"\"\"\n",
        "            CREATE TABLE {table_name} (\n",
        "                id SERIAL PRIMARY KEY,\n",
        "                city_id VARCHAR(50) NOT NULL,\n",
        "                analysis_id VARCHAR(100),\n",
        "                bbox_count INTEGER,\n",
        "                subdataset_count INTEGER,\n",
        "                scene_count INTEGER,\n",
        "                total_overlap_area NUMERIC,\n",
        "                grid_coords TEXT,\n",
        "                analysis_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        "            );\n",
        "        \"\"\")\n",
        "        conn.execute(create_sql)\n",
        "        print(f\"âœ… è¡¨ {table_name} åˆ›å»ºæˆåŠŸ\")\n",
        "    else:\n",
        "        print(f\"ğŸ“‹ è¡¨ {table_name} å·²å­˜åœ¨ï¼Œæ£€æŸ¥å­—æ®µç»“æ„...\")\n",
        "        \n",
        "        # æ£€æŸ¥å¿…è¦å­—æ®µæ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™æ·»åŠ \n",
        "        required_fields = {\n",
        "            'analysis_id': 'VARCHAR(100)',\n",
        "            'bbox_count': 'INTEGER',\n",
        "            'subdataset_count': 'INTEGER', \n",
        "            'scene_count': 'INTEGER',\n",
        "            'total_overlap_area': 'NUMERIC',\n",
        "            'grid_coords': 'TEXT'\n",
        "        }\n",
        "        \n",
        "        for field_name, field_type in required_fields.items():\n",
        "            check_field_sql = text(f\"\"\"\n",
        "                SELECT EXISTS (\n",
        "                    SELECT 1 FROM information_schema.columns \n",
        "                    WHERE table_name = '{table_name}' \n",
        "                    AND column_name = '{field_name}'\n",
        "                    AND table_schema = 'public'\n",
        "                );\n",
        "            \"\"\")\n",
        "            \n",
        "            field_exists = conn.execute(check_field_sql).scalar()\n",
        "            \n",
        "            if not field_exists:\n",
        "                add_field_sql = text(f\"\"\"\n",
        "                    ALTER TABLE {table_name} \n",
        "                    ADD COLUMN {field_name} {field_type};\n",
        "                \"\"\")\n",
        "                conn.execute(add_field_sql)\n",
        "                print(f\"   âœ… æ·»åŠ å­—æ®µ: {field_name} {field_type}\")\n",
        "    \n",
        "    # æ·»åŠ å‡ ä½•åˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰\n",
        "    geometry_sql = text(f\"\"\"\n",
        "        DO $$\n",
        "        BEGIN\n",
        "            IF NOT EXISTS (\n",
        "                SELECT 1 FROM information_schema.columns \n",
        "                WHERE table_name = '{table_name}' \n",
        "                AND column_name = 'geometry'\n",
        "                AND table_schema = 'public'\n",
        "            ) THEN\n",
        "                PERFORM AddGeometryColumn('public', '{table_name}', 'geometry', 4326, 'GEOMETRY', 2);\n",
        "                RAISE NOTICE 'å‡ ä½•åˆ—å·²æ·»åŠ åˆ° {table_name} è¡¨';\n",
        "            END IF;\n",
        "        END $$;\n",
        "    \"\"\")\n",
        "    conn.execute(geometry_sql)\n",
        "    \n",
        "    # åˆ›å»ºç´¢å¼•\n",
        "    index_sql = text(f\"\"\"\n",
        "        CREATE INDEX IF NOT EXISTS idx_{table_name}_city_id ON {table_name} (city_id);\n",
        "        CREATE INDEX IF NOT EXISTS idx_{table_name}_bbox_count ON {table_name} (bbox_count);\n",
        "        CREATE INDEX IF NOT EXISTS idx_{table_name}_geom ON {table_name} USING GIST (geometry);\n",
        "    \"\"\")\n",
        "    conn.execute(index_sql)\n",
        "    \n",
        "    conn.commit()\n",
        "    print(f\"âœ… è¡¨ {table_name} ç»“æ„æ£€æŸ¥å®Œæˆ\")\n",
        "\n",
        "# åˆ›å»ºæ±‡æ€»è¡¨\n",
        "create_top1_summary_table(conn, CONFIG['output_table'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. è·å–åŸå¸‚åˆ—è¡¨\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_all_cities(conn):\n",
        "    \"\"\"è·å–æ‰€æœ‰åŸå¸‚\"\"\"\n",
        "    print(f\"ğŸ” æŸ¥æ‰¾æ‰€æœ‰åŸå¸‚...\")\n",
        "    \n",
        "    cities_sql = text(\"\"\"\n",
        "        SELECT \n",
        "            city_id,\n",
        "            COUNT(*) as bbox_count,\n",
        "            COUNT(*) FILTER (WHERE all_good = true) as good_bbox_count\n",
        "        FROM clips_bbox_unified\n",
        "        WHERE city_id IS NOT NULL \n",
        "        GROUP BY city_id\n",
        "        ORDER BY COUNT(*) DESC;\n",
        "    \"\"\")\n",
        "    \n",
        "    cities_df = pd.read_sql(cities_sql, conn)\n",
        "    return cities_df\n",
        "\n",
        "# è·å–åŸå¸‚æ•°æ®\n",
        "cities_df = get_all_cities(conn)\n",
        "\n",
        "print(f\"ğŸ“Š æ‰¾åˆ° {len(cities_df)} ä¸ªåŸå¸‚:\")\n",
        "print(cities_df.head(10))\n",
        "\n",
        "if len(cities_df) > 10:\n",
        "    print(f\"... è¿˜æœ‰ {len(cities_df) - 10} ä¸ªåŸå¸‚\")\n",
        "\n",
        "# ç¡®å®šè¦åˆ†æçš„åŸå¸‚åˆ—è¡¨\n",
        "if CONFIG['target_cities']:\n",
        "    print(f\"ğŸ¯ æŒ‡å®šåˆ†æåŸå¸‚: {CONFIG['target_cities']}\")\n",
        "    cities_to_analyze = CONFIG['target_cities']\n",
        "else:\n",
        "    all_cities = cities_df['city_id'].tolist()\n",
        "    if CONFIG['max_cities']:\n",
        "        cities_to_analyze = all_cities[:CONFIG['max_cities']]\n",
        "        print(f\"ğŸ¯ åˆ†æå‰ {CONFIG['max_cities']} ä¸ªåŸå¸‚\")\n",
        "    else:\n",
        "        cities_to_analyze = all_cities\n",
        "        print(f\"ğŸ¯ åˆ†ææ‰€æœ‰ {len(all_cities)} ä¸ªåŸå¸‚\")\n",
        "\n",
        "print(f\"\\nğŸ“‹ å°†è¦åˆ†æçš„åŸå¸‚ ({len(cities_to_analyze)} ä¸ª):\")\n",
        "print(cities_to_analyze)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
