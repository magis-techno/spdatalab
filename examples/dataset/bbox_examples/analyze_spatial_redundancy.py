#!/usr/bin/env python3
"""
ç©ºé—´å†—ä½™åˆ†æè„šæœ¬
===============================

åŠŸèƒ½ï¼š
1. åˆ›å»ºcity_grid_densityåŸºç¡€è¡¨
2. è®¡ç®—åŸå¸‚ç©ºé—´å†—ä½™åº¦æŒ‡æ ‡

ä½¿ç”¨æ–¹æ³•ï¼š
    # é¦–æ¬¡è¿è¡Œï¼šåˆ›å»ºè¡¨
    python analyze_spatial_redundancy.py --create-table
    
    # åˆ†æå†—ä½™åº¦ï¼ˆé»˜è®¤top1%ï¼Œè‡ªåŠ¨ä½¿ç”¨æœ€æ–°æ—¥æœŸï¼‰
    python analyze_spatial_redundancy.py
    
    # æŒ‰sceneæ•°é‡æ’åºï¼ˆä¼šå¢åŠ å‡ ç§’å¯åŠ¨æ—¶é—´ï¼‰
    python analyze_spatial_redundancy.py --sort-by-scenes
    
    # åˆ†ætop5%
    python analyze_spatial_redundancy.py --top-percent 5
    
    # æŒ‡å®šåˆ†ææ—¥æœŸ
    python analyze_spatial_redundancy.py --analysis-date 2025-10-09
    
    # æŒ‡å®šåŸå¸‚
    python analyze_spatial_redundancy.py --cities A263 B001
    
    # å¯¼å‡ºCSV
    python analyze_spatial_redundancy.py --export-csv
    
    # ç»„åˆä½¿ç”¨
    python analyze_spatial_redundancy.py --sort-by-scenes --analysis-date 2025-10-09 --export-csv
"""

import sys
from pathlib import Path
import argparse

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

try:
    from spdatalab.dataset.bbox import LOCAL_DSN
except ImportError:
    sys.path.insert(0, str(project_root / "src"))
    from spdatalab.dataset.bbox import LOCAL_DSN

from sqlalchemy import create_engine, text
import pandas as pd

# å¸¸é‡å®šä¹‰
# Grid å¤§å°ï¼š0.002åº¦ Ã— 0.002åº¦
GRID_SIZE_DEGREES = 0.002
# 1åº¦çº¦ç­‰äº111kmï¼ˆåœ¨èµ¤é“é™„è¿‘ï¼‰
KM_PER_DEGREE = 111.0
# å•ä¸ª grid çš„é¢ç§¯ï¼ˆkmÂ²ï¼‰
SINGLE_GRID_AREA_KM2 = (GRID_SIZE_DEGREES * KM_PER_DEGREE) ** 2  # â‰ˆ 0.049 kmÂ²


def create_density_table(conn):
    """åˆ›å»ºcity_grid_densityåŸºç¡€è¡¨"""
    
    print("ğŸ”¨ åˆ›å»º city_grid_density è¡¨...")
    
    create_sql = text("""
        -- åˆ›å»ºåŸå¸‚ç½‘æ ¼å¯†åº¦è¡¨
        CREATE TABLE IF NOT EXISTS city_grid_density (
            id SERIAL PRIMARY KEY,
            city_id VARCHAR(50) NOT NULL,
            analysis_date DATE DEFAULT CURRENT_DATE,
            grid_x INTEGER NOT NULL,
            grid_y INTEGER NOT NULL,
            grid_size NUMERIC DEFAULT 0.002,
            bbox_count INTEGER NOT NULL,
            subdataset_count INTEGER,
            scene_count INTEGER,
            involved_subdatasets TEXT[],
            involved_scenes TEXT[],
            total_bbox_area NUMERIC,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(city_id, analysis_date, grid_x, grid_y)
        );
        
        -- æ·»åŠ å‡ ä½•åˆ—
        DO $$
        BEGIN
            IF NOT EXISTS (
                SELECT 1 FROM information_schema.columns 
                WHERE table_name = 'city_grid_density' AND column_name = 'geometry'
            ) THEN
                PERFORM AddGeometryColumn('public', 'city_grid_density', 'geometry', 4326, 'POLYGON', 2);
            END IF;
        END $$;
        
        -- åˆ›å»ºç´¢å¼•
        CREATE INDEX IF NOT EXISTS idx_city_grid_city_date ON city_grid_density (city_id, analysis_date);
        CREATE INDEX IF NOT EXISTS idx_city_grid_bbox_count ON city_grid_density (bbox_count DESC);
        CREATE INDEX IF NOT EXISTS idx_city_grid_scene_count ON city_grid_density (scene_count DESC);
        CREATE INDEX IF NOT EXISTS idx_city_grid_geom ON city_grid_density USING GIST (geometry);
    """)
    
    conn.execute(create_sql)
    conn.commit()
    print("âœ… è¡¨åˆ›å»ºæˆåŠŸ")


def calculate_city_redundancy(conn, city_id: str, top_percent: float = 1.0, analysis_date=None):
    """è®¡ç®—å•ä¸ªåŸå¸‚çš„å†—ä½™åº¦æŒ‡æ ‡
    
    ä½¿ç”¨ grid é¢ç§¯ç»Ÿä¸€è®¡ç®—ï¼Œé¿å…åˆ†å­åˆ†æ¯ä¸ä¸€è‡´çš„é—®é¢˜ã€‚
    
    Args:
        conn: æ•°æ®åº“è¿æ¥
        city_id: åŸå¸‚ID
        top_percent: topç™¾åˆ†æ¯”
        analysis_date: åˆ†ææ—¥æœŸï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨CURRENT_DATE
    """
    
    # 1. åŸå¸‚æ€»ä½“ç»Ÿè®¡ï¼ˆåªéœ€è¦ scene å’Œ bbox æ•°é‡ï¼‰
    total_sql = text("""
        SELECT 
            COUNT(DISTINCT scene_token) as total_scenes,
            COUNT(*) as total_bboxes
        FROM clips_bbox_unified
        WHERE city_id = :city_id AND all_good = true
    """)
    
    total = conn.execute(total_sql, {'city_id': city_id}).fetchone()
    
    if not total or total.total_scenes == 0:
        return None
    
    # 2. è·å–è¯¥åŸå¸‚æœ‰æ•°æ®çš„ grid ç»Ÿè®¡
    if analysis_date:
        grid_count_sql = text("""
            SELECT COUNT(*) FROM city_grid_density
            WHERE city_id = :city_id AND analysis_date = :analysis_date
        """)
        grid_count = conn.execute(grid_count_sql, {'city_id': city_id, 'analysis_date': analysis_date}).scalar()
    else:
        # ä½¿ç”¨å­æŸ¥è¯¢è·å–æœ€æ–°æ—¥æœŸï¼Œé¿å…æ—¥æœŸç±»å‹ä¼ é€’é—®é¢˜
        grid_count_sql = text("""
            SELECT COUNT(*) FROM city_grid_density
            WHERE city_id = :city_id 
            AND analysis_date = (SELECT MAX(analysis_date) FROM city_grid_density)
        """)
        grid_count = conn.execute(grid_count_sql, {'city_id': city_id}).scalar()
    
    if not grid_count or grid_count == 0:
        return None
    
    # è®¡ç®— top N% å¯¹åº”çš„ grid æ•°é‡
    top_n = max(1, int(grid_count * top_percent / 100.0))
    
    # 3. é€šè¿‡ç©ºé—´è¿æ¥è®¡ç®— top N% ç½‘æ ¼å†…çš„å®é™… scene æ•°
    if analysis_date:
        hotspot_sql = text("""
            WITH top_grids AS (
                SELECT geometry
                FROM city_grid_density
                WHERE city_id = :city_id AND analysis_date = :analysis_date
                ORDER BY bbox_count DESC
                LIMIT :top_n
            )
            SELECT 
                COUNT(DISTINCT b.scene_token) as hotspot_scenes,
                COUNT(b.*) as hotspot_bboxes
            FROM top_grids tg
            LEFT JOIN clips_bbox_unified b ON ST_Intersects(tg.geometry, b.geometry)
            WHERE b.city_id = :city_id AND b.all_good = true
        """)
        hotspot = conn.execute(hotspot_sql, {
            'city_id': city_id,
            'top_n': top_n,
            'analysis_date': analysis_date
        }).fetchone()
    else:
        # ä½¿ç”¨å­æŸ¥è¯¢è·å–æœ€æ–°æ—¥æœŸï¼Œé¿å…æ—¥æœŸç±»å‹ä¼ é€’é—®é¢˜
        hotspot_sql = text("""
            WITH top_grids AS (
                SELECT geometry
                FROM city_grid_density
                WHERE city_id = :city_id 
                AND analysis_date = (SELECT MAX(analysis_date) FROM city_grid_density)
                ORDER BY bbox_count DESC
                LIMIT :top_n
            )
            SELECT 
                COUNT(DISTINCT b.scene_token) as hotspot_scenes,
                COUNT(b.*) as hotspot_bboxes
            FROM top_grids tg
            LEFT JOIN clips_bbox_unified b ON ST_Intersects(tg.geometry, b.geometry)
            WHERE b.city_id = :city_id AND b.all_good = true
        """)
        hotspot = conn.execute(hotspot_sql, {
            'city_id': city_id,
            'top_n': top_n
        }).fetchone()
    
    if not hotspot:
        return None
    
    # 4. ä½¿ç”¨ grid é¢ç§¯ç»Ÿä¸€è®¡ç®—æŒ‡æ ‡
    # åˆ†æ¯ï¼šæ‰€æœ‰æœ‰æ•°æ®çš„ grid çš„æ€»é¢ç§¯
    total_grid_area_km2 = grid_count * SINGLE_GRID_AREA_KM2
    
    # åˆ†å­ï¼štop N% grid çš„æ€»é¢ç§¯
    hotspot_grid_area_km2 = top_n * SINGLE_GRID_AREA_KM2
    
    # é¢ç§¯ç™¾åˆ†æ¯”ï¼ˆç†è®ºä¸Šåº”è¯¥æ¥è¿‘ top_percentï¼‰
    area_pct = (top_n / grid_count) * 100 if grid_count > 0 else 0
    
    # Scene ç™¾åˆ†æ¯”
    scene_pct = (hotspot.hotspot_scenes / total.total_scenes) * 100 if total.total_scenes > 0 else 0
    
    # BBox ç™¾åˆ†æ¯”
    bbox_pct = (hotspot.hotspot_bboxes / total.total_bboxes) * 100 if total.total_bboxes > 0 else 0
    
    # å†—ä½™æŒ‡æ•° = sceneå æ¯” / é¢ç§¯å æ¯”
    redundancy = scene_pct / area_pct if area_pct > 0 else 0
    
    return {
        'city_id': city_id,
        'total_scenes': int(total.total_scenes),
        'total_bboxes': int(total.total_bboxes),
        'total_grids': grid_count,
        'total_grid_area_km2': round(total_grid_area_km2, 2),
        'top_n_grids': top_n,
        'hotspot_grid_area_km2': round(hotspot_grid_area_km2, 2),
        'hotspot_scenes': int(hotspot.hotspot_scenes),
        'hotspot_bboxes': int(hotspot.hotspot_bboxes),
        'area_percentage': round(area_pct, 2),
        'scene_percentage': round(scene_pct, 2),
        'bbox_percentage': round(bbox_pct, 2),
        'redundancy_index': round(redundancy, 2),
    }


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ç©ºé—´å†—ä½™åˆ†æ')
    parser.add_argument('--create-table', action='store_true',
                       help='åˆ›å»ºcity_grid_densityè¡¨')
    parser.add_argument('--top-percent', type=float, default=1.0,
                       help='åˆ†æçš„topç™¾åˆ†æ¯”ï¼ˆé»˜è®¤1%%ï¼‰')
    parser.add_argument('--cities', nargs='+',
                       help='æŒ‡å®šåˆ†æçš„åŸå¸‚åˆ—è¡¨')
    parser.add_argument('--sort-by-scenes', action='store_true',
                       help='æŒ‰sceneæ•°é‡ä»å¤šåˆ°å°‘æ’åºåŸå¸‚ï¼ˆä¼šå¢åŠ å¯åŠ¨æ—¶é—´ï¼‰')
    parser.add_argument('--analysis-date', type=str,
                       help='æŒ‡å®šåˆ†ææ—¥æœŸï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰ï¼Œé»˜è®¤ä½¿ç”¨è¡¨ä¸­æœ€æ–°æ—¥æœŸ')
    parser.add_argument('--export-csv', action='store_true',
                       help='å¯¼å‡ºCSVæŠ¥å‘Š')
    
    args = parser.parse_args()
    
    engine = create_engine(LOCAL_DSN, future=True)
    
    try:
        with engine.connect() as conn:
            
            # å¦‚æœéœ€è¦åˆ›å»ºè¡¨
            if args.create_table:
                create_density_table(conn)
                print("\nğŸ’¡ è¡¨åˆ›å»ºå®Œæˆï¼Œç°åœ¨å¯ä»¥è¿è¡Œåˆ†æï¼š")
                print("   1. å…ˆç”Ÿæˆgridæ•°æ®: python batch_grid_analysis.py")
                print("   2. å†åˆ†æå†—ä½™: python analyze_spatial_redundancy.py")
                return 0
            
            # å¦åˆ™è¿›è¡Œå†—ä½™åˆ†æ
            print(f"ğŸš€ ç©ºé—´å†—ä½™åˆ†æ (Top {args.top_percent}%)")
            print("=" * 60)
            
            # ç¡®å®šåˆ†ææ—¥æœŸ
            if args.analysis_date:
                target_date = args.analysis_date
                print(f"ğŸ“… ä½¿ç”¨æŒ‡å®šæ—¥æœŸ: {target_date}")
            else:
                # è‡ªåŠ¨è·å–è¡¨ä¸­æœ€æ–°æ—¥æœŸ
                max_date_sql = text("""
                    SELECT MAX(analysis_date) 
                    FROM city_grid_density
                """)
                target_date = conn.execute(max_date_sql).scalar()
                
                if not target_date:
                    print("\nâŒ city_grid_density è¡¨ä¸­æ²¡æœ‰æ•°æ®")
                    print("ğŸ’¡ æç¤º:")
                    print("   1. å…ˆè¿è¡Œ: python analyze_spatial_redundancy.py --create-table")
                    print("   2. å†è¿è¡Œ: python batch_grid_analysis.py")
                    print("   3. æœ€åè¿è¡Œ: python analyze_spatial_redundancy.py")
                    return 1
                
                print(f"ğŸ“… è‡ªåŠ¨ä½¿ç”¨æœ€æ–°æ—¥æœŸ: {target_date}")
            
            # è·å–åŸå¸‚åˆ—è¡¨
            if args.cities:
                cities = args.cities
                print(f"ğŸ¯ åˆ†ææŒ‡å®šåŸå¸‚: {cities}")
            else:
                if args.sort_by_scenes:
                    # æŒ‰ scene æ•°é‡ä»å¤šåˆ°å°‘æ’åºï¼ˆè¾ƒæ…¢ï¼Œéœ€è¦ç»Ÿè®¡ï¼‰
                    print(f"â³ æ­£åœ¨ç»Ÿè®¡å„åŸå¸‚sceneæ•°é‡...")
                    # ä½¿ç”¨å­æŸ¥è¯¢é¿å…æ—¥æœŸç±»å‹ä¼ é€’é—®é¢˜
                    if args.analysis_date:
                        result = conn.execute(text("""
                            SELECT 
                                city_id,
                                COUNT(DISTINCT scene_token) as scene_count
                            FROM clips_bbox_unified
                            WHERE city_id IN (
                                SELECT DISTINCT city_id 
                                FROM city_grid_density 
                                WHERE analysis_date = :target_date
                            )
                            AND all_good = true
                            GROUP BY city_id
                            ORDER BY scene_count DESC, city_id
                        """), {'target_date': target_date})
                    else:
                        result = conn.execute(text("""
                            SELECT 
                                city_id,
                                COUNT(DISTINCT scene_token) as scene_count
                            FROM clips_bbox_unified
                            WHERE city_id IN (
                                SELECT DISTINCT city_id 
                                FROM city_grid_density 
                                WHERE analysis_date = (SELECT MAX(analysis_date) FROM city_grid_density)
                            )
                            AND all_good = true
                            GROUP BY city_id
                            ORDER BY scene_count DESC, city_id
                        """))
                    cities = [row.city_id for row in result]
                    print(f"ğŸ“Š åˆ†ææ‰€æœ‰åŸå¸‚: å…± {len(cities)} ä¸ªï¼ˆæŒ‰sceneæ•°é‡æ’åºï¼‰")
                else:
                    # å¿«é€Ÿæ¨¡å¼ï¼šä¸æ’åº
                    # ä½¿ç”¨å­æŸ¥è¯¢é¿å…æ—¥æœŸç±»å‹ä¼ é€’é—®é¢˜
                    if args.analysis_date:
                        result = conn.execute(text("""
                            SELECT DISTINCT city_id 
                            FROM city_grid_density
                            WHERE analysis_date = :target_date
                            ORDER BY city_id
                        """), {'target_date': target_date})
                    else:
                        result = conn.execute(text("""
                            SELECT DISTINCT city_id 
                            FROM city_grid_density
                            WHERE analysis_date = (SELECT MAX(analysis_date) FROM city_grid_density)
                            ORDER BY city_id
                        """))
                    cities = [row.city_id for row in result]
                    print(f"ğŸ“Š åˆ†ææ‰€æœ‰åŸå¸‚: å…± {len(cities)} ä¸ª")
            
            if not cities:
                print("\nâŒ æ²¡æœ‰æ‰¾åˆ°åŸå¸‚æ•°æ®")
                print("ğŸ’¡ æç¤º:")
                print("   1. å…ˆè¿è¡Œ: python analyze_spatial_redundancy.py --create-table")
                print("   2. å†è¿è¡Œ: python batch_grid_analysis.py")
                print("   3. æœ€åè¿è¡Œ: python analyze_spatial_redundancy.py")
                return 1
            
            # é€åŸå¸‚åˆ†æ
            print(f"\nğŸ”„ è®¡ç®—å†—ä½™åº¦æŒ‡æ ‡...\n")
            results = []
            
            for city_id in cities:
                metrics = calculate_city_redundancy(conn, city_id, args.top_percent, target_date)
                if metrics:
                    results.append(metrics)
                    print(f"âœ“ {city_id}: å†—ä½™æŒ‡æ•° {metrics['redundancy_index']} "
                          f"({metrics['area_percentage']:.1f}%é¢ç§¯[{metrics['top_n_grids']}/{metrics['total_grids']}grid] "
                          f"â†’ {metrics['scene_percentage']:.1f}%åœºæ™¯[{metrics['hotspot_scenes']}/{metrics['total_scenes']}])")
                else:
                    print(f"âœ— {city_id}: æ— æ•°æ®")
            
            if not results:
                print("\nâŒ æ²¡æœ‰è·å–åˆ°ä»»ä½•æ•°æ®")
                return 1
            
            # æ±‡æ€»ç»Ÿè®¡
            df = pd.DataFrame(results)
            
            print(f"\n" + "=" * 60)
            print(f"ğŸ“ˆ æ±‡æ€»ç»Ÿè®¡")
            print(f"=" * 60)
            print(f"åˆ†æåŸå¸‚æ•°: {len(df)}")
            print(f"æ€»åœºæ™¯æ•°: {df['total_scenes'].sum():,}")
            print(f"æ€»ç½‘æ ¼æ•°: {df['total_grids'].sum():,}")
            print(f"å¹³å‡å†—ä½™æŒ‡æ•°: {df['redundancy_index'].mean():.2f}")
            print(f"ä¸­ä½æ•°: {df['redundancy_index'].median():.2f}")
            print(f"èŒƒå›´: {df['redundancy_index'].min():.2f} ~ {df['redundancy_index'].max():.2f}")
            
            # å†—ä½™åº¦åˆ†çº§
            severe = len(df[df['redundancy_index'] >= 20])
            moderate = len(df[(df['redundancy_index'] >= 10) & (df['redundancy_index'] < 20)])
            normal = len(df[df['redundancy_index'] < 10])
            
            print(f"\nå†—ä½™åº¦åˆ†çº§:")
            print(f"  - ä¸¥é‡å†—ä½™ (â‰¥20): {severe} ä¸ªåŸå¸‚")
            print(f"  - ä¸­åº¦å†—ä½™ (10-20): {moderate} ä¸ªåŸå¸‚")
            print(f"  - åˆç†èŒƒå›´ (<10): {normal} ä¸ªåŸå¸‚")
            
            # Top 5
            print(f"\nğŸ” Top 5 é«˜å†—ä½™åŸå¸‚:")
            top5 = df.nlargest(5, 'redundancy_index')
            for i, row in enumerate(top5.itertuples(), 1):
                print(f"  {i}. {row.city_id}: å†—ä½™æŒ‡æ•° {row.redundancy_index} "
                      f"({row.area_percentage:.1f}%é¢ç§¯[{row.top_n_grids}grid/{row.total_grid_area_km2:.1f}kmÂ²] "
                      f"åŒ…å«{row.scene_percentage:.1f}%åœºæ™¯[{row.hotspot_scenes}/{row.total_scenes}])")
            
            # å¯¼å‡ºCSV
            if args.export_csv:
                output_file = f'redundancy_report_top{int(args.top_percent)}pct.csv'
                df_sorted = df.sort_values('redundancy_index', ascending=False)
                df_sorted.to_csv(output_file, index=False, encoding='utf-8-sig')
                print(f"\nğŸ“„ å·²å¯¼å‡º: {output_file}")
            
            print(f"\nğŸ’¡ è®¡ç®—æ–¹æ³•è¯´æ˜:")
            print(f"   - é¢ç§¯è®¡ç®—ï¼šä½¿ç”¨ç½‘æ ¼(grid)é¢ç§¯ç»Ÿä¸€è®¡ç®—")
            print(f"   - å•ä¸ªgridï¼š{GRID_SIZE_DEGREES}Â° Ã— {GRID_SIZE_DEGREES}Â° â‰ˆ {SINGLE_GRID_AREA_KM2:.3f} kmÂ²")
            print(f"   - å†—ä½™æŒ‡æ•°ï¼šsceneå æ¯” / é¢ç§¯å æ¯”ï¼ˆè¶Šé«˜è¡¨ç¤ºæ•°æ®è¶Šé›†ä¸­ï¼‰")
            print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥:")
            print(f"   - åœ¨Jupyter Notebookä¸­è¿›è¡Œå¯è§†åŒ–åˆ†æ")
            print(f"   - åœ¨QGISä¸­åŠ è½½ city_grid_density è¡¨æŸ¥çœ‹ç©ºé—´åˆ†å¸ƒ")
            print("=" * 60)
            
    except Exception as e:
        print(f"\nâŒ åˆ†æå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    sys.exit(main())

