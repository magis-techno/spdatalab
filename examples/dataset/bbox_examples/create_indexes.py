#!/usr/bin/env python3
"""
BBoxæ€§èƒ½ç´¢å¼•åˆ›å»ºè„šæœ¬
==================

ä¸ºbboxåˆ†è¡¨åˆ›å»ºä¼˜åŒ–ç´¢å¼•ï¼Œæå‡overlapåˆ†ææ€§èƒ½

ä½¿ç”¨æ–¹æ³•ï¼š
    python examples/dataset/bbox_examples/create_indexes.py
    
    # åªä¼˜åŒ–å‰10ä¸ªè¡¨ï¼ˆå¿«é€Ÿæ¨¡å¼ï¼‰
    python examples/dataset/bbox_examples/create_indexes.py --quick
    
    # æŒ‡å®šè¡¨æ•°é‡
    python examples/dataset/bbox_examples/create_indexes.py --limit 20
    
    # åªæ£€æŸ¥ï¼Œä¸åˆ›å»º
    python examples/dataset/bbox_examples/create_indexes.py --check-only
"""

import sys
import argparse
import time
from pathlib import Path
from typing import List, Dict, Tuple

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

try:
    from spdatalab.dataset.bbox import list_bbox_tables, LOCAL_DSN
    from sqlalchemy import create_engine, text
except ImportError:
    sys.path.insert(0, str(project_root / "src"))
    from spdatalab.dataset.bbox import list_bbox_tables, LOCAL_DSN
    from sqlalchemy import create_engine, text

import pandas as pd

class BBoxIndexOptimizer:
    """BBoxåˆ†è¡¨ç´¢å¼•ä¼˜åŒ–å™¨"""
    
    def __init__(self, dsn: str = LOCAL_DSN):
        self.dsn = dsn
        self.engine = create_engine(dsn, future=True)
        
    def get_table_stats(self, table_name: str) -> Dict:
        """è·å–è¡¨çš„ç»Ÿè®¡ä¿¡æ¯"""
        try:
            with self.engine.connect() as conn:
                # è·å–è®°å½•æ•°
                count_sql = text(f"SELECT COUNT(*) FROM {table_name};")
                row_count = conn.execute(count_sql).scalar()
                
                # è·å–ç´¢å¼•ä¿¡æ¯
                index_sql = text(f"""
                    SELECT 
                        COUNT(*) as total_indexes,
                        COUNT(*) FILTER (WHERE indexdef ILIKE '%gist%') as spatial_indexes,
                        COUNT(*) FILTER (WHERE indexdef ILIKE '%city_id%') as city_indexes,
                        COUNT(*) FILTER (WHERE indexdef ILIKE '%all_good%') as quality_indexes,
                        BOOL_OR(indexdef ILIKE '%city_id%all_good%' OR indexdef ILIKE '%all_good%city_id%') as has_composite
                    FROM pg_indexes 
                    WHERE tablename = '{table_name}' AND schemaname = 'public';
                """)
                
                index_stats = conn.execute(index_sql).fetchone()
                
                return {
                    'row_count': row_count,
                    'total_indexes': index_stats.total_indexes,
                    'spatial_indexes': index_stats.spatial_indexes,
                    'city_indexes': index_stats.city_indexes,
                    'quality_indexes': index_stats.quality_indexes,
                    'has_composite': index_stats.has_composite,
                    'needs_optimization': not (index_stats.has_composite and index_stats.spatial_indexes > 0)
                }
                
        except Exception as e:
            return {
                'row_count': 0,
                'error': str(e),
                'needs_optimization': True
            }
    
    def create_indexes_for_table(self, table_name: str) -> Tuple[bool, List[str], str]:
        """ä¸ºå•ä¸ªè¡¨åˆ›å»ºç´¢å¼•
        
        Returns:
            (success, created_indexes, message)
        """
        created_indexes = []
        
        try:
            with self.engine.connect() as conn:
                # 1. ğŸš€ æ ¸å¿ƒå¤åˆç´¢å¼•ï¼š(city_id, all_good)
                composite_index_sql = text(f"""
                    CREATE INDEX IF NOT EXISTS idx_{table_name}_city_good 
                    ON {table_name} (city_id, all_good) 
                    WHERE city_id IS NOT NULL;
                """)
                conn.execute(composite_index_sql)
                created_indexes.append("city_good_composite")
                
                # 2. ğŸš€ ç©ºé—´ç´¢å¼•æ£€æŸ¥å’Œåˆ›å»º
                check_spatial_sql = text(f"""
                    SELECT EXISTS (
                        SELECT 1 FROM pg_indexes 
                        WHERE tablename = '{table_name}' 
                        AND indexdef ILIKE '%gist%geometry%'
                    );
                """)
                
                has_spatial = conn.execute(check_spatial_sql).scalar()
                if not has_spatial:
                    spatial_index_sql = text(f"""
                        CREATE INDEX idx_{table_name}_geom 
                        ON {table_name} USING GIST (geometry);
                    """)
                    conn.execute(spatial_index_sql)
                    created_indexes.append("spatial_geometry")
                
                # 3. ğŸš€ éƒ¨åˆ†ç´¢å¼•ï¼šé«˜è´¨é‡æ•°æ®çš„ç©ºé—´ç´¢å¼•
                partial_index_sql = text(f"""
                    CREATE INDEX IF NOT EXISTS idx_{table_name}_quality_geom 
                    ON {table_name} USING GIST (geometry) 
                    WHERE all_good = true AND city_id IS NOT NULL;
                """)
                conn.execute(partial_index_sql)
                created_indexes.append("quality_spatial")
                
                # 4. ğŸš€ ä¸»é”®ç´¢å¼•æ£€æŸ¥
                check_id_sql = text(f"""
                    SELECT EXISTS (
                        SELECT 1 FROM pg_indexes 
                        WHERE tablename = '{table_name}' 
                        AND indexdef ILIKE '%\\bid\\b%'
                        AND indexdef NOT ILIKE '%city_id%'
                    );
                """)
                
                has_id_index = conn.execute(check_id_sql).scalar()
                if not has_id_index:
                    id_index_sql = text(f"""
                        CREATE INDEX IF NOT EXISTS idx_{table_name}_id 
                        ON {table_name} (id);
                    """)
                    conn.execute(id_index_sql)
                    created_indexes.append("id_primary")
                
                conn.commit()
                
                return True, created_indexes, "æˆåŠŸ"
                
        except Exception as e:
            return False, created_indexes, f"å¤±è´¥: {str(e)}"
    
    def check_all_tables(self, limit: int = None) -> pd.DataFrame:
        """æ£€æŸ¥æ‰€æœ‰è¡¨çš„ç´¢å¼•çŠ¶æ€"""
        print("ğŸ” æ£€æŸ¥bboxåˆ†è¡¨ç´¢å¼•çŠ¶æ€...")
        
        # è·å–åˆ†è¡¨åˆ—è¡¨ï¼ˆæ’é™¤è§†å›¾ï¼‰
        all_tables = list_bbox_tables(self.engine)
        
        # è¿‡æ»¤å‡ºçœŸæ­£çš„è¡¨ï¼Œæ’é™¤è§†å›¾
        bbox_tables = []
        
        # è·å–æ‰€æœ‰è§†å›¾åç§°ï¼Œé¿å…å¯¹è§†å›¾è¿›è¡Œç´¢å¼•æ“ä½œ
        with self.engine.connect() as conn:
            views_sql = text("""
                SELECT table_name 
                FROM information_schema.views 
                WHERE table_schema = 'public' 
                AND table_name LIKE 'clips_bbox%';
            """)
            view_names = {row[0] for row in conn.execute(views_sql).fetchall()}
        
        for table in all_tables:
            if table.startswith('clips_bbox_') and table != 'clips_bbox':
                # æ’é™¤è§†å›¾
                if table not in view_names:
                    bbox_tables.append(table)
                else:
                    print(f"â­ï¸ è·³è¿‡è§†å›¾: {table}")
        
        print(f"ğŸ“‹ æ‰¾åˆ° {len(bbox_tables)} ä¸ªå®é™…åˆ†è¡¨ï¼ˆæ’é™¤ {len(view_names)} ä¸ªè§†å›¾ï¼‰")
        
        if limit:
            bbox_tables = bbox_tables[:limit]
            print(f"ğŸ“‹ æ£€æŸ¥å‰ {len(bbox_tables)} ä¸ªåˆ†è¡¨")
        else:
            print(f"ğŸ“‹ æ£€æŸ¥æ‰€æœ‰ {len(bbox_tables)} ä¸ªåˆ†è¡¨")
        
        results = []
        
        for i, table_name in enumerate(bbox_tables, 1):
            print(f"[{i}/{len(bbox_tables)}] æ£€æŸ¥ {table_name}...")
            
            stats = self.get_table_stats(table_name)
            
            # è®¡ç®—ä¼˜åŒ–çŠ¶æ€
            if 'error' in stats:
                status = "âŒ é”™è¯¯"
            elif stats.get('has_composite') and stats.get('spatial_indexes', 0) > 0:
                status = "ğŸš€ å·²ä¼˜åŒ–"
            elif stats.get('spatial_indexes', 0) > 0 and stats.get('city_indexes', 0) > 0:
                status = "âš¡ éƒ¨åˆ†ä¼˜åŒ–"
            elif stats.get('spatial_indexes', 0) > 0:
                status = "ğŸ“ ä»…ç©ºé—´ç´¢å¼•"
            else:
                status = "âŒ éœ€è¦ä¼˜åŒ–"
            
            results.append({
                'table_name': table_name,
                'row_count': stats.get('row_count', 0),
                'total_indexes': stats.get('total_indexes', 0),
                'spatial_indexes': stats.get('spatial_indexes', 0),
                'city_indexes': stats.get('city_indexes', 0),
                'has_composite': stats.get('has_composite', False),
                'status': status,
                'needs_optimization': stats.get('needs_optimization', True),
                'error': stats.get('error', '')
            })
        
        return pd.DataFrame(results)
    
    def optimize_tables(self, limit: int = None, dry_run: bool = False) -> Dict:
        """ä¼˜åŒ–åˆ†è¡¨ç´¢å¼•"""
        print("ğŸš€ å¼€å§‹bboxåˆ†è¡¨ç´¢å¼•ä¼˜åŒ–...")
        
        # è·å–éœ€è¦ä¼˜åŒ–çš„è¡¨
        df = self.check_all_tables(limit)
        need_optimization = df[df['needs_optimization']].copy()
        
        if need_optimization.empty:
            print("âœ… æ‰€æœ‰è¡¨éƒ½å·²ä¼˜åŒ–ï¼Œæ— éœ€é¢å¤–æ“ä½œ")
            return {
                'total_tables': len(df),
                'optimized_tables': 0,
                'failed_tables': 0,
                'skipped_tables': len(df)
            }
        
        print(f"ğŸ“‹ éœ€è¦ä¼˜åŒ– {len(need_optimization)} ä¸ªè¡¨")
        
        if dry_run:
            print("ğŸ§ª è¯•è¿è¡Œæ¨¡å¼ - åªæ£€æŸ¥ï¼Œä¸æ‰§è¡Œ")
            return {
                'total_tables': len(df),
                'would_optimize': len(need_optimization),
                'dry_run': True
            }
        
        # æ‰§è¡Œä¼˜åŒ–
        optimized = 0
        failed = 0
        
        for i, row in need_optimization.iterrows():
            table_name = row['table_name']
            print(f"\n[{optimized + failed + 1}/{len(need_optimization)}] ğŸ”§ ä¼˜åŒ–è¡¨: {table_name}")
            print(f"   å½“å‰è®°å½•æ•°: {row['row_count']:,}")
            
            start_time = time.time()
            success, created_indexes, message = self.create_indexes_for_table(table_name)
            elapsed = time.time() - start_time
            
            if success:
                print(f"   âœ… {message} (è€—æ—¶: {elapsed:.1f}s)")
                print(f"   ğŸ“Š åˆ›å»ºç´¢å¼•: {', '.join(created_indexes)}")
                optimized += 1
            else:
                print(f"   âŒ {message}")
                failed += 1
        
        print(f"\nâœ… ç´¢å¼•ä¼˜åŒ–å®Œæˆï¼")
        print(f"   æˆåŠŸä¼˜åŒ–: {optimized} ä¸ªè¡¨")
        if failed > 0:
            print(f"   ä¼˜åŒ–å¤±è´¥: {failed} ä¸ªè¡¨")
        
        return {
            'total_tables': len(df),
            'optimized_tables': optimized,
            'failed_tables': failed,
            'skipped_tables': len(df) - len(need_optimization)
        }
    
    def get_optimization_summary(self) -> Dict:
        """è·å–ä¼˜åŒ–æ‘˜è¦"""
        df = self.check_all_tables()
        
        summary = df['status'].value_counts().to_dict()
        
        # è®¡ç®—ç™¾åˆ†æ¯”
        total = len(df)
        for status in summary:
            summary[status] = {
                'count': summary[status],
                'percentage': round(100 * summary[status] / total, 1)
            }
        
        return {
            'total_tables': total,
            'status_distribution': summary,
            'needs_optimization': len(df[df['needs_optimization']]),
            'already_optimized': len(df[~df['needs_optimization']])
        }

def main():
    parser = argparse.ArgumentParser(description='BBoxåˆ†è¡¨ç´¢å¼•ä¼˜åŒ–å·¥å…·')
    parser.add_argument('--quick', action='store_true', help='å¿«é€Ÿæ¨¡å¼ï¼šåªä¼˜åŒ–å‰10ä¸ªè¡¨')
    parser.add_argument('--limit', type=int, help='é™åˆ¶å¤„ç†çš„è¡¨æ•°é‡')
    parser.add_argument('--check-only', action='store_true', help='åªæ£€æŸ¥çŠ¶æ€ï¼Œä¸åˆ›å»ºç´¢å¼•')
    parser.add_argument('--dry-run', action='store_true', help='è¯•è¿è¡Œæ¨¡å¼')
    
    args = parser.parse_args()
    
    print("ğŸ¯ BBoxåˆ†è¡¨ç´¢å¼•ä¼˜åŒ–å·¥å…·")
    print("=" * 50)
    
    optimizer = BBoxIndexOptimizer()
    
    # ç¡®å®šå¤„ç†è¡¨çš„æ•°é‡
    limit = None
    if args.quick:
        limit = 10
        print("ğŸš€ å¿«é€Ÿæ¨¡å¼ï¼šå¤„ç†å‰10ä¸ªè¡¨")
    elif args.limit:
        limit = args.limit
        print(f"ğŸ“Š é™åˆ¶æ¨¡å¼ï¼šå¤„ç†å‰{limit}ä¸ªè¡¨")
    else:
        print("ğŸ“‹ å®Œæ•´æ¨¡å¼ï¼šå¤„ç†æ‰€æœ‰è¡¨")
    
    if args.check_only:
        # åªæ£€æŸ¥çŠ¶æ€
        print("\nğŸ” æ£€æŸ¥ç´¢å¼•çŠ¶æ€...")
        df = optimizer.check_all_tables(limit)
        
        print("\nğŸ“Š ç´¢å¼•çŠ¶æ€æŠ¥å‘Š:")
        print(df[['table_name', 'row_count', 'total_indexes', 'status']].to_string(index=False))
        
        # æ˜¾ç¤ºæ‘˜è¦
        summary = optimizer.get_optimization_summary()
        print(f"\nğŸ“ˆ ä¼˜åŒ–æ‘˜è¦:")
        print(f"   æ€»è¡¨æ•°: {summary['total_tables']}")
        print(f"   éœ€è¦ä¼˜åŒ–: {summary['needs_optimization']}")
        print(f"   å·²ä¼˜åŒ–: {summary['already_optimized']}")
        
        print(f"\nğŸ“Š çŠ¶æ€åˆ†å¸ƒ:")
        for status, info in summary['status_distribution'].items():
            print(f"   {status}: {info['count']} ({info['percentage']}%)")
        
    else:
        # æ‰§è¡Œä¼˜åŒ–
        result = optimizer.optimize_tables(limit, args.dry_run)
        
        if not args.dry_run:
            print(f"\nğŸ¯ æµ‹è¯•å»ºè®®:")
            print(f"   python examples/dataset/bbox_examples/run_overlap_analysis.py --city A86 --intersect-only --top-n 5")

if __name__ == "__main__":
    main()
