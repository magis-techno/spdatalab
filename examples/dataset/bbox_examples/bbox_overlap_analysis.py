#!/usr/bin/env python3
"""
BBoxå ç½®åˆ†æç¤ºä¾‹
===============

æœ¬ç¤ºä¾‹å±•ç¤ºå¦‚ä½•å¯¹bboxåˆ†è¡¨æ•°æ®è¿›è¡Œç©ºé—´å ç½®åˆ†æï¼Œæ‰¾å‡ºé‡å æ•°é‡æœ€é«˜çš„ä½ç½®ã€‚

åŠŸèƒ½ç‰¹æ€§ï¼š
- åŸºäºç»Ÿä¸€è§†å›¾çš„ç©ºé—´å ç½®åˆ†æ
- é‡å çƒ­ç‚¹è¯†åˆ«å’Œæ’åº
- QGISå…¼å®¹çš„ç»“æœå¯¼å‡º
- æ”¯æŒå¤šç§è¿‡æ»¤å’Œåˆ†ç»„æ¡ä»¶

å·¥ä½œæµç¨‹ï¼š
1. ç¡®ä¿bboxç»Ÿä¸€è§†å›¾å­˜åœ¨
2. æ‰§è¡Œç©ºé—´å ç½®åˆ†æSQL
3. ä¿å­˜ç»“æœåˆ°åˆ†æç»“æœè¡¨
4. åˆ›å»ºQGISå…¼å®¹è§†å›¾
5. æä¾›å¯è§†åŒ–æŒ‡å¯¼

ä½¿ç”¨æ–¹æ³•ï¼š
    python examples/dataset/bbox_examples/bbox_overlap_analysis.py
    
    # æˆ–æŒ‡å®šå‚æ•°
    python examples/dataset/bbox_examples/bbox_overlap_analysis.py --city beijing --min-overlap-area 0.0001
"""

import sys
import os
from pathlib import Path
import argparse
from datetime import datetime
import pandas as pd
import logging
from typing import Optional, List, Dict, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„ï¼Œæ”¯æŒå¤šç§ç¯å¢ƒ
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# å°è¯•ç›´æ¥å¯¼å…¥ï¼Œå¦‚æœå¤±è´¥åˆ™æ·»åŠ srcè·¯å¾„
try:
    from spdatalab.dataset.bbox import (
        create_qgis_compatible_unified_view,
        list_bbox_tables,
        LOCAL_DSN
    )
except ImportError:
    # å¦‚æœç›´æ¥å¯¼å…¥å¤±è´¥ï¼Œå°è¯•æ·»åŠ srcè·¯å¾„
    sys.path.insert(0, str(project_root / "src"))
    from spdatalab.dataset.bbox import (
        create_qgis_compatible_unified_view,
        list_bbox_tables,
        LOCAL_DSN
    )

from sqlalchemy import create_engine, text

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class BBoxOverlapAnalyzer:
    """BBoxå ç½®åˆ†æå™¨"""
    
    def __init__(self, dsn: str = LOCAL_DSN):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.dsn = dsn
        self.engine = create_engine(dsn, future=True)
        self.analysis_table = "bbox_overlap_analysis_results"
        self.unified_view = "clips_bbox_unified_qgis"
        self.qgis_view = "qgis_bbox_overlap_hotspots"
        
    def ensure_unified_view(self, force_refresh: bool = False) -> bool:
        """ç¡®ä¿ç»Ÿä¸€è§†å›¾å­˜åœ¨å¹¶ä¸”æ˜¯æœ€æ–°çš„
        
        Args:
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°è§†å›¾
        """
        print("ğŸ” æ£€æŸ¥bboxç»Ÿä¸€è§†å›¾...")
        
        try:
            with self.engine.connect() as conn:
                # 1. æ£€æŸ¥è§†å›¾æ˜¯å¦å­˜åœ¨
                check_view_sql = text(f"""
                    SELECT EXISTS (
                        SELECT FROM information_schema.views 
                        WHERE table_schema = 'public' 
                        AND table_name = '{self.unified_view}'
                    );
                """)
                
                result = conn.execute(check_view_sql)
                view_exists = result.scalar()
                
                # 2. è·å–å½“å‰åˆ†è¡¨æ•°é‡
                current_tables = list_bbox_tables(self.engine)
                bbox_partition_tables = [t for t in current_tables if t.startswith('clips_bbox_') and t != 'clips_bbox']
                current_table_count = len(bbox_partition_tables)
                
                print(f"ğŸ“‹ å‘ç° {current_table_count} ä¸ªbboxåˆ†è¡¨")
                
                # 3. æ£€æŸ¥è§†å›¾æ˜¯å¦éœ€è¦æ›´æ–°
                view_needs_update = False
                
                if not view_exists:
                    print(f"ğŸ“Œ è§†å›¾ {self.unified_view} ä¸å­˜åœ¨ï¼Œéœ€è¦åˆ›å»º")
                    view_needs_update = True
                elif force_refresh:
                    print(f"ğŸ”„ å¼ºåˆ¶åˆ·æ–°æ¨¡å¼ï¼Œå°†é‡æ–°åˆ›å»ºè§†å›¾")
                    view_needs_update = True
                elif current_table_count == 0:
                    print(f"âš ï¸ æ²¡æœ‰å‘ç°bboxåˆ†è¡¨ï¼Œæ— æ³•åˆ›å»ºç»Ÿä¸€è§†å›¾")
                    return False
                else:
                    # æ£€æŸ¥è§†å›¾çš„è¡¨æ•°é‡æ˜¯å¦åŒ¹é…å½“å‰åˆ†è¡¨æ•°é‡
                    try:
                        # å°è¯•ä»è§†å›¾å®šä¹‰ä¸­è·å–è¡¨æ•°é‡ï¼ˆç®€åŒ–æ£€æŸ¥ï¼‰
                        check_count_sql = text(f"SELECT COUNT(DISTINCT source_table) FROM {self.unified_view} LIMIT 1;")
                        view_table_result = conn.execute(check_count_sql)
                        view_table_count = view_table_result.scalar()
                        
                        if view_table_count != current_table_count:
                            print(f"ğŸ”„ è§†å›¾åŒ…å« {view_table_count} ä¸ªè¡¨ï¼Œå½“å‰æœ‰ {current_table_count} ä¸ªåˆ†è¡¨ï¼Œéœ€è¦æ›´æ–°")
                            view_needs_update = True
                    except Exception as e:
                        print(f"âš ï¸ æ£€æŸ¥è§†å›¾çŠ¶æ€å¤±è´¥: {str(e)[:100]}...")
                        print(f"ğŸ”„ ä¸ºå®‰å…¨èµ·è§ï¼Œå°†é‡æ–°åˆ›å»ºè§†å›¾")
                        view_needs_update = True
                
                # 4. åˆ›å»ºæˆ–æ›´æ–°è§†å›¾
                if view_needs_update:
                    if current_table_count == 0:
                        print(f"âŒ æ— æ³•åˆ›å»ºè§†å›¾ï¼šæ²¡æœ‰å¯ç”¨çš„bboxåˆ†è¡¨")
                        return False
                    
                    print(f"ğŸ› ï¸ æ­£åœ¨åˆ›å»º/æ›´æ–°ç»Ÿä¸€è§†å›¾...")
                    success = create_qgis_compatible_unified_view(self.engine, self.unified_view)
                    if not success:
                        print("âŒ åˆ›å»ºç»Ÿä¸€è§†å›¾å¤±è´¥")
                        return False
                    print(f"âœ… ç»Ÿä¸€è§†å›¾ {self.unified_view} åˆ›å»º/æ›´æ–°æˆåŠŸ")
                else:
                    print(f"âœ… ç»Ÿä¸€è§†å›¾ {self.unified_view} å·²æ˜¯æœ€æ–°çŠ¶æ€")
                
                # 5. éªŒè¯è§†å›¾æ•°æ®
                try:
                    count_sql = text(f"SELECT COUNT(*) FROM {self.unified_view};")
                    count_result = conn.execute(count_sql)
                    row_count = count_result.scalar()
                    print(f"ğŸ“Š ç»Ÿä¸€è§†å›¾åŒ…å« {row_count:,} æ¡bboxè®°å½•")
                    
                    if row_count == 0:
                        print(f"âš ï¸ ç»Ÿä¸€è§†å›¾ä¸ºç©ºï¼Œå¯èƒ½åˆ†è¡¨ä¸­æ²¡æœ‰æ•°æ®")
                        return False
                    
                    # æ˜¾ç¤ºæ•°æ®åˆ†å¸ƒæ¦‚å†µ
                    sample_sql = text(f"""
                        SELECT 
                            COUNT(DISTINCT subdataset_name) as subdataset_count,
                            COUNT(DISTINCT city_id) as city_count,
                            MIN(created_at) as earliest_data,
                            MAX(created_at) as latest_data
                        FROM {self.unified_view} 
                        WHERE created_at IS NOT NULL;
                    """)
                    sample_result = conn.execute(sample_sql).fetchone()
                    if sample_result:
                        print(f"ğŸ“ˆ æ•°æ®æ¦‚å†µ: {sample_result.subdataset_count} ä¸ªå­æ•°æ®é›†, {sample_result.city_count} ä¸ªåŸå¸‚")
                    
                    return True
                    
                except Exception as e:
                    print(f"âš ï¸ è§†å›¾æ•°æ®éªŒè¯å¤±è´¥: {str(e)[:100]}...")
                    return False
                
        except Exception as e:
            print(f"âŒ æ£€æŸ¥ç»Ÿä¸€è§†å›¾å¤±è´¥: {str(e)}")
            return False
    
    def create_analysis_table(self) -> bool:
        """åˆ›å»ºåˆ†æç»“æœè¡¨"""
        print("ğŸ› ï¸ åˆ›å»ºåˆ†æç»“æœè¡¨...")
        
        # è¯»å–åˆ›å»ºè¡¨çš„SQLè„šæœ¬
        sql_file = Path(__file__).parent / "sql" / "create_analysis_tables.sql"
        
        try:
            if sql_file.exists():
                # å¦‚æœSQLæ–‡ä»¶å­˜åœ¨ï¼Œä½¿ç”¨æ–‡ä»¶ä¸­çš„SQL
                with open(sql_file, 'r', encoding='utf-8') as f:
                    create_sql = f.read()
            else:
                # å¦åˆ™ä½¿ç”¨å†…ç½®çš„SQL
                create_sql = f"""
                -- åˆ›å»ºbboxå ç½®åˆ†æç»“æœè¡¨
                CREATE TABLE IF NOT EXISTS {self.analysis_table} (
                    id SERIAL PRIMARY KEY,
                    analysis_id VARCHAR(100) NOT NULL,
                    analysis_type VARCHAR(50) DEFAULT 'bbox_overlap',
                    analysis_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    hotspot_rank INTEGER,
                    overlap_count INTEGER,
                    total_overlap_area NUMERIC,
                    subdataset_count INTEGER,
                    scene_count INTEGER,
                    involved_subdatasets TEXT[],
                    involved_scenes TEXT[],
                    analysis_params TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );

                -- æ·»åŠ PostGISå‡ ä½•åˆ—
                DO $$
                BEGIN
                    -- æ£€æŸ¥å‡ ä½•åˆ—æ˜¯å¦å·²å­˜åœ¨
                    IF NOT EXISTS (
                        SELECT 1 FROM information_schema.columns 
                        WHERE table_name = '{self.analysis_table}' 
                        AND column_name = 'geometry'
                    ) THEN
                        PERFORM AddGeometryColumn('public', '{self.analysis_table}', 'geometry', 4326, 'GEOMETRY', 2);
                    END IF;
                END $$;

                -- åˆ›å»ºç´¢å¼•
                CREATE INDEX IF NOT EXISTS idx_bbox_overlap_analysis_id ON {self.analysis_table} (analysis_id);
                CREATE INDEX IF NOT EXISTS idx_bbox_overlap_rank ON {self.analysis_table} (hotspot_rank);
                CREATE INDEX IF NOT EXISTS idx_bbox_overlap_count ON {self.analysis_table} (overlap_count);
                CREATE INDEX IF NOT EXISTS idx_bbox_overlap_geom ON {self.analysis_table} USING GIST (geometry);
                """
            
            with self.engine.connect() as conn:
                conn.execute(text(create_sql))
                conn.commit()
                
            print(f"âœ… åˆ†æç»“æœè¡¨ {self.analysis_table} åˆ›å»ºæˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºåˆ†æç»“æœè¡¨å¤±è´¥: {str(e)}")
            return False
    
    def run_overlap_analysis(
        self, 
        analysis_id: Optional[str] = None,
        city_filter: Optional[str] = None,
        subdataset_filter: Optional[List[str]] = None,
        min_overlap_area: float = 0.0,
        top_n: int = 20
    ) -> str:
        """æ‰§è¡Œå ç½®åˆ†æ
        
        Args:
            analysis_id: åˆ†æIDï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
            city_filter: åŸå¸‚è¿‡æ»¤
            subdataset_filter: å­æ•°æ®é›†è¿‡æ»¤
            min_overlap_area: æœ€å°é‡å é¢ç§¯é˜ˆå€¼
            top_n: è¿”å›çš„çƒ­ç‚¹æ•°é‡
            
        Returns:
            åˆ†æID
        """
        if not analysis_id:
            analysis_id = f"bbox_overlap_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        print(f"ğŸš€ å¼€å§‹å ç½®åˆ†æ: {analysis_id}")
        print(f"å‚æ•°: city_filter={city_filter}, min_overlap_area={min_overlap_area}, top_n={top_n}")
        
        # æ„å»ºè¿‡æ»¤æ¡ä»¶
        where_conditions = []
        if city_filter:
            where_conditions.append(f"a.city_id = '{city_filter}' AND b.city_id = '{city_filter}'")
        
        if subdataset_filter:
            subdataset_list = "', '".join(subdataset_filter)
            where_conditions.append(f"a.subdataset_name IN ('{subdataset_list}') AND b.subdataset_name IN ('{subdataset_list}')")
        
        where_clause = "AND " + " AND ".join(where_conditions) if where_conditions else ""
        
        # è¯»å–åˆ†æSQLè„šæœ¬
        sql_file = Path(__file__).parent / "sql" / "overlap_analysis.sql"
        
        try:
            if sql_file.exists():
                # å¦‚æœSQLæ–‡ä»¶å­˜åœ¨ï¼Œè¯»å–å¹¶æ›¿æ¢å‚æ•°
                with open(sql_file, 'r', encoding='utf-8') as f:
                    analysis_sql_template = f.read()
                
                # æ›¿æ¢å‚æ•°
                analysis_sql = analysis_sql_template.format(
                    unified_view=self.unified_view,
                    analysis_table=self.analysis_table,
                    analysis_id=analysis_id,
                    where_clause=where_clause,
                    min_overlap_area=min_overlap_area,
                    top_n=top_n
                )
            else:
                # å†…ç½®SQL
                analysis_sql = f"""
                WITH overlapping_areas AS (
                    SELECT 
                        a.qgis_id as bbox_a_id,
                        b.qgis_id as bbox_b_id,
                        a.subdataset_name as subdataset_a,
                        b.subdataset_name as subdataset_b,
                        a.scene_token as scene_a,
                        b.scene_token as scene_b,
                        ST_Intersection(a.geometry, b.geometry) as overlap_geometry,
                        ST_Area(ST_Intersection(a.geometry, b.geometry)) as overlap_area
                    FROM {self.unified_view} a
                    JOIN {self.unified_view} b ON a.qgis_id < b.qgis_id
                    WHERE ST_Intersects(a.geometry, b.geometry)
                    AND ST_Area(ST_Intersection(a.geometry, b.geometry)) > {min_overlap_area}
                    {where_clause}
                ),
                overlap_hotspots AS (
                    SELECT 
                        ST_Union(overlap_geometry) as hotspot_geometry,
                        COUNT(*) as overlap_count,
                        ARRAY_AGG(DISTINCT subdataset_a) || ARRAY_AGG(DISTINCT subdataset_b) as involved_subdatasets,
                        ARRAY_AGG(DISTINCT scene_a) || ARRAY_AGG(DISTINCT scene_b) as involved_scenes,
                        SUM(overlap_area) as total_overlap_area
                    FROM overlapping_areas
                    GROUP BY ST_SnapToGrid(overlap_geometry, 0.001)
                    HAVING COUNT(*) >= 2
                )
                INSERT INTO {self.analysis_table} 
                (analysis_id, hotspot_rank, overlap_count, total_overlap_area, 
                 subdataset_count, scene_count, involved_subdatasets, involved_scenes, geometry, analysis_params)
                SELECT 
                    '{analysis_id}' as analysis_id,
                    ROW_NUMBER() OVER (ORDER BY overlap_count DESC) as hotspot_rank,
                    overlap_count,
                    total_overlap_area,
                    ARRAY_LENGTH(involved_subdatasets, 1) as subdataset_count,
                    ARRAY_LENGTH(involved_scenes, 1) as scene_count,
                    involved_subdatasets,
                    involved_scenes,
                    hotspot_geometry as geometry,
                    '{{"city_filter": "{city_filter}", "min_overlap_area": {min_overlap_area}, "top_n": {top_n}}}' as analysis_params
                FROM overlap_hotspots
                ORDER BY overlap_count DESC
                LIMIT {top_n};
                """
            
            with self.engine.connect() as conn:
                result = conn.execute(text(analysis_sql))
                conn.commit()
                
                # è·å–æ’å…¥çš„è®°å½•æ•°
                count_sql = text(f"SELECT COUNT(*) FROM {self.analysis_table} WHERE analysis_id = '{analysis_id}';")
                count_result = conn.execute(count_sql)
                inserted_count = count_result.scalar()
                
            print(f"âœ… å ç½®åˆ†æå®Œæˆï¼Œå‘ç° {inserted_count} ä¸ªé‡å çƒ­ç‚¹")
            return analysis_id
            
        except Exception as e:
            print(f"âŒ å ç½®åˆ†æå¤±è´¥: {str(e)}")
            raise
    
    def create_qgis_view(self, analysis_id: Optional[str] = None) -> bool:
        """åˆ›å»ºQGISå…¼å®¹è§†å›¾"""
        print("ğŸ¨ åˆ›å»ºQGISå…¼å®¹è§†å›¾...")
        
        # è¯»å–è§†å›¾åˆ›å»ºSQL
        sql_file = Path(__file__).parent / "sql" / "qgis_views.sql"
        
        try:
            if sql_file.exists():
                with open(sql_file, 'r', encoding='utf-8') as f:
                    view_sql = f.read()
                    view_sql = view_sql.format(
                        qgis_view=self.qgis_view,
                        analysis_table=self.analysis_table
                    )
            else:
                # å†…ç½®SQL
                where_clause = f"WHERE analysis_id = '{analysis_id}'" if analysis_id else ""
                
                view_sql = f"""
                CREATE OR REPLACE VIEW {self.qgis_view} AS
                SELECT 
                    id as qgis_id,
                    analysis_id,
                    hotspot_rank,
                    overlap_count,
                    total_overlap_area,
                    subdataset_count,
                    scene_count,
                    involved_subdatasets,
                    involved_scenes,
                    CASE 
                        WHEN overlap_count >= 10 THEN 'High Density'
                        WHEN overlap_count >= 5 THEN 'Medium Density'
                        ELSE 'Low Density'
                    END as density_level,
                    geometry,
                    created_at
                FROM {self.analysis_table}
                WHERE analysis_type = 'bbox_overlap'
                {where_clause}
                ORDER BY hotspot_rank;
                """
            
            with self.engine.connect() as conn:
                conn.execute(text(view_sql))
                conn.commit()
                
            print(f"âœ… QGISè§†å›¾ {self.qgis_view} åˆ›å»ºæˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºQGISè§†å›¾å¤±è´¥: {str(e)}")
            return False
    
    def get_analysis_summary(self, analysis_id: str) -> pd.DataFrame:
        """è·å–åˆ†æç»“æœæ‘˜è¦"""
        sql = text(f"""
            SELECT 
                hotspot_rank,
                overlap_count,
                ROUND(total_overlap_area::numeric, 4) as total_overlap_area,
                subdataset_count,
                scene_count,
                involved_subdatasets,
                density_level
            FROM {self.qgis_view}
            WHERE analysis_id = :analysis_id
            ORDER BY hotspot_rank
            LIMIT 10;
        """)
        
        return pd.read_sql(sql, self.engine, params={'analysis_id': analysis_id})
    
    def export_for_qgis(self, analysis_id: str) -> Dict[str, Any]:
        """å¯¼å‡ºQGISå¯è§†åŒ–ä¿¡æ¯"""
        return {
            'analysis_id': analysis_id,
            'qgis_view': self.qgis_view,
            'unified_view': self.unified_view,
            'connection_info': {
                'host': 'local_pg',
                'port': 5432,
                'database': 'postgres',
                'username': 'postgres'
            },
            'visualization_tips': {
                'primary_key': 'qgis_id',
                'geometry_column': 'geometry',
                'style_column': 'density_level',
                'label_column': 'overlap_count',
                'filter_column': 'analysis_id'
            }
        }


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='BBoxå ç½®åˆ†æ')
    parser.add_argument('--city', help='åŸå¸‚è¿‡æ»¤')
    parser.add_argument('--subdatasets', nargs='+', help='å­æ•°æ®é›†è¿‡æ»¤')
    parser.add_argument('--min-overlap-area', type=float, default=0.0, help='æœ€å°é‡å é¢ç§¯é˜ˆå€¼')
    parser.add_argument('--top-n', type=int, default=20, help='è¿”å›çš„çƒ­ç‚¹æ•°é‡')
    parser.add_argument('--analysis-id', help='è‡ªå®šä¹‰åˆ†æID')
    parser.add_argument('--refresh-view', action='store_true', help='å¼ºåˆ¶åˆ·æ–°ç»Ÿä¸€è§†å›¾ï¼ˆé€‚ç”¨äºæ•°æ®æ›´æ–°åï¼‰')
    
    args = parser.parse_args()
    
    print("ğŸ¯ BBoxå ç½®åˆ†æç¤ºä¾‹")
    print("=" * 60)
    
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = BBoxOverlapAnalyzer()
    
    try:
        # 1. ç¡®ä¿ç»Ÿä¸€è§†å›¾å­˜åœ¨
        print("\nğŸ“‹ æ­¥éª¤1: æ£€æŸ¥æ•°æ®å‡†å¤‡")
        # å¯¹äºå¤§é‡æ•°æ®çš„æƒ…å†µï¼Œæˆ‘ä»¬ä¼˜å…ˆä½¿ç”¨ç°æœ‰è§†å›¾ï¼Œåªåœ¨å¿…è¦æ—¶åˆ·æ–°
        force_refresh = args.refresh_view
        if not analyzer.ensure_unified_view(force_refresh=force_refresh):
            print("âŒ ç»Ÿä¸€è§†å›¾æ£€æŸ¥å¤±è´¥ï¼Œé€€å‡º")
            return
        
        # 2. åˆ›å»ºåˆ†æç»“æœè¡¨
        print("\nğŸ› ï¸ æ­¥éª¤2: å‡†å¤‡åˆ†æç¯å¢ƒ")
        if not analyzer.create_analysis_table():
            print("âŒ åˆ†æè¡¨åˆ›å»ºå¤±è´¥ï¼Œé€€å‡º")
            return
        
        # 3. æ‰§è¡Œå ç½®åˆ†æ
        print("\nğŸš€ æ­¥éª¤3: æ‰§è¡Œå ç½®åˆ†æ")
        analysis_id = analyzer.run_overlap_analysis(
            analysis_id=args.analysis_id,
            city_filter=args.city,
            subdataset_filter=args.subdatasets,
            min_overlap_area=args.min_overlap_area,
            top_n=args.top_n
        )
        
        # 4. åˆ›å»ºQGISè§†å›¾
        print("\nğŸ¨ æ­¥éª¤4: åˆ›å»ºQGISè§†å›¾")
        if not analyzer.create_qgis_view(analysis_id):
            print("âŒ QGISè§†å›¾åˆ›å»ºå¤±è´¥")
            return
        
        # 5. æ˜¾ç¤ºåˆ†æç»“æœæ‘˜è¦
        print("\nğŸ“Š æ­¥éª¤5: åˆ†æç»“æœæ‘˜è¦")
        summary = analyzer.get_analysis_summary(analysis_id)
        if not summary.empty:
            print("TOP 10 é‡å çƒ­ç‚¹:")
            print(summary.to_string(index=False))
        else:
            print("æœªå‘ç°é‡å çƒ­ç‚¹")
        
        # 6. æä¾›QGISå¯è§†åŒ–æŒ‡å¯¼
        print("\nğŸ¯ æ­¥éª¤6: QGISå¯è§†åŒ–æŒ‡å¯¼")
        qgis_info = analyzer.export_for_qgis(analysis_id)
        
        print("ğŸ“‹ æ•°æ®åº“è¿æ¥ä¿¡æ¯:")
        conn_info = qgis_info['connection_info']
        for key, value in conn_info.items():
            print(f"   {key}: {value}")
        
        print(f"\nğŸ“Š åœ¨QGISä¸­åŠ è½½ä»¥ä¸‹å›¾å±‚:")
        print(f"   1. {qgis_info['unified_view']} - æ‰€æœ‰bboxæ•°æ®ï¼ˆåº•å›¾ï¼‰")
        print(f"   2. {qgis_info['qgis_view']} - é‡å çƒ­ç‚¹åŒºåŸŸ")
        
        print(f"\nğŸ¨ å¯è§†åŒ–å»ºè®®:")
        vis_tips = qgis_info['visualization_tips']
        print(f"   â€¢ ä¸»é”®: {vis_tips['primary_key']}")
        print(f"   â€¢ å‡ ä½•åˆ—: {vis_tips['geometry_column']}")
        print(f"   â€¢ æŒ‰ {vis_tips['style_column']} å­—æ®µè®¾ç½®é¢œè‰²")
        print(f"   â€¢ æ˜¾ç¤º {vis_tips['label_column']} æ ‡ç­¾")
        print(f"   â€¢ ä½¿ç”¨ {vis_tips['filter_column']} = '{analysis_id}' è¿‡æ»¤")
        
        print(f"\nâœ… å ç½®åˆ†æå®Œæˆï¼åˆ†æID: {analysis_id}")
        print(f"ç°åœ¨å¯ä»¥åœ¨QGISä¸­è¿æ¥æ•°æ®åº“å¹¶åŠ è½½è¿™äº›å›¾å±‚è¿›è¡Œå¯è§†åŒ–åˆ†æã€‚")
        
    except Exception as e:
        print(f"\nâŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯")


if __name__ == "__main__":
    main()
