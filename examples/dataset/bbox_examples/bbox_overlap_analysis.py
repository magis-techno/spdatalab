#!/usr/bin/env python3
"""
BBoxå ç½®åˆ†æç¤ºä¾‹
===============

æœ¬ç¤ºä¾‹å±•ç¤ºå¦‚ä½•å¯¹bboxåˆ†è¡¨æ•°æ®è¿›è¡Œç©ºé—´å ç½®åˆ†æï¼Œæ‰¾å‡ºé‡å æ•°é‡æœ€é«˜çš„ä½ç½®ã€‚

åŠŸèƒ½ç‰¹æ€§ï¼š
- åŸºäºç»Ÿä¸€è§†å›¾çš„ç©ºé—´å ç½®åˆ†æ
- é‡å çƒ­ç‚¹è¯†åˆ«å’Œæ’åº
- QGISå…¼å®¹çš„ç»“æœå¯¼å‡º
- æ”¯æŒå¤šç§è¿‡æ»¤å’Œåˆ†ç»„æ¡ä»¶

å·¥ä½œæµç¨‹ï¼š
1. ç¡®ä¿bboxç»Ÿä¸€è§†å›¾å­˜åœ¨
2. æ‰§è¡Œç©ºé—´å ç½®åˆ†æSQL
3. ä¿å­˜ç»“æœåˆ°åˆ†æç»“æœè¡¨
4. åˆ›å»ºQGISå…¼å®¹è§†å›¾
5. æä¾›å¯è§†åŒ–æŒ‡å¯¼

ä½¿ç”¨æ–¹æ³•ï¼š
    python examples/dataset/bbox_examples/bbox_overlap_analysis.py
    
    # æˆ–æŒ‡å®šå‚æ•°
    python examples/dataset/bbox_examples/bbox_overlap_analysis.py --city beijing --min-overlap-area 0.0001
"""

import sys
import os
import signal
import atexit
from pathlib import Path
import argparse
from datetime import datetime
import pandas as pd
import logging
from typing import Optional, List, Dict, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„ï¼Œæ”¯æŒå¤šç§ç¯å¢ƒ
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# å°è¯•ç›´æ¥å¯¼å…¥ï¼Œå¦‚æœå¤±è´¥åˆ™æ·»åŠ srcè·¯å¾„
try:
    from spdatalab.dataset.bbox import (
        create_unified_view,
        list_bbox_tables,
        LOCAL_DSN
    )
except ImportError:
    # å¦‚æœç›´æ¥å¯¼å…¥å¤±è´¥ï¼Œå°è¯•æ·»åŠ srcè·¯å¾„
    sys.path.insert(0, str(project_root / "src"))
    from spdatalab.dataset.bbox import (
        create_unified_view,
        list_bbox_tables,
        LOCAL_DSN
    )

from sqlalchemy import create_engine, text

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class BBoxOverlapAnalyzer:
    """BBoxå ç½®åˆ†æå™¨"""
    
    def __init__(self, dsn: str = LOCAL_DSN):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.dsn = dsn
        self.engine = create_engine(dsn, future=True)
        self.analysis_table = "bbox_overlap_analysis_results"
        self.unified_view = "clips_bbox_unified"
        self.qgis_view = "qgis_bbox_overlap_hotspots"
        
        # ä¼˜é›…é€€å‡ºæ§åˆ¶
        self.shutdown_requested = False
        self.current_connection = None
        self.current_analysis_id = None
        self.analysis_start_time = None
        
        # è°ƒè¯•æ¨¡å¼
        self.debug_mode = False
        
        # æ³¨å†Œä¿¡å·å¤„ç†å™¨å’Œæ¸…ç†å‡½æ•°
        self._setup_signal_handlers()
        atexit.register(self._cleanup_on_exit)
    
    def _setup_signal_handlers(self):
        """è®¾ç½®ä¿¡å·å¤„ç†å™¨"""
        def signal_handler(signum, frame):
            print(f"\n\nğŸ›‘ æ”¶åˆ°é€€å‡ºä¿¡å· ({signal.Signals(signum).name})")
            self._initiate_graceful_shutdown()
        
        # æ³¨å†Œå¸¸è§çš„é€€å‡ºä¿¡å·
        try:
            signal.signal(signal.SIGINT, signal_handler)   # Ctrl+C
            signal.signal(signal.SIGTERM, signal_handler)  # ç»ˆæ­¢ä¿¡å·
            if hasattr(signal, 'SIGBREAK'):  # Windows
                signal.signal(signal.SIGBREAK, signal_handler)
        except ValueError:
            # åœ¨æŸäº›ç¯å¢ƒä¸­å¯èƒ½æ— æ³•æ³¨å†Œä¿¡å·
            logger.warning("æ— æ³•æ³¨å†Œä¿¡å·å¤„ç†å™¨")
    
    def _initiate_graceful_shutdown(self):
        """å¯åŠ¨ä¼˜é›…é€€å‡ºæµç¨‹"""
        self.shutdown_requested = True
        print(f"ğŸ”„ æ­£åœ¨å®‰å…¨é€€å‡º...")
        
        if self.current_analysis_id:
            print(f"ğŸ“ å½“å‰åˆ†æID: {self.current_analysis_id}")
            
        if self.analysis_start_time:
            elapsed = datetime.now() - self.analysis_start_time
            print(f"â±ï¸ å·²è¿è¡Œæ—¶é—´: {elapsed}")
        
        print(f"ğŸ§¹ æ¸…ç†èµ„æºä¸­...")
        self._cleanup_resources()
        
        print(f"âœ… ä¼˜é›…é€€å‡ºå®Œæˆ")
        sys.exit(0)
    
    def _cleanup_resources(self):
        """æ¸…ç†èµ„æº"""
        try:
            if self.current_connection:
                self.current_connection.close()
                print(f"âœ… æ•°æ®åº“è¿æ¥å·²å…³é—­")
                self.current_connection = None
        except Exception as e:
            print(f"âš ï¸ å…³é—­è¿æ¥æ—¶å‡ºé”™: {e}")
    
    def _cleanup_on_exit(self):
        """ç¨‹åºé€€å‡ºæ—¶çš„æ¸…ç†å‡½æ•°"""
        if not self.shutdown_requested:
            self._cleanup_resources()
    
    def _check_shutdown(self):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦é€€å‡º"""
        if self.shutdown_requested:
            print(f"ğŸ›‘ æ£€æµ‹åˆ°é€€å‡ºè¯·æ±‚ï¼Œåœæ­¢æ‰§è¡Œ")
            raise KeyboardInterrupt("ç”¨æˆ·è¯·æ±‚é€€å‡º")
        
    def ensure_unified_view(self, force_refresh: bool = False) -> bool:
        """ç¡®ä¿ç»Ÿä¸€è§†å›¾å­˜åœ¨å¹¶ä¸”æ˜¯æœ€æ–°çš„
        
        Args:
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°è§†å›¾
        """
        print("ğŸ” æ£€æŸ¥bboxç»Ÿä¸€è§†å›¾...")
        
        try:
            with self.engine.connect() as conn:
                # 1. æ£€æŸ¥è§†å›¾æ˜¯å¦å­˜åœ¨
                check_view_sql = text(f"""
                    SELECT EXISTS (
                        SELECT FROM information_schema.views 
                        WHERE table_schema = 'public' 
                        AND table_name = '{self.unified_view}'
                    );
                """)
                
                result = conn.execute(check_view_sql)
                view_exists = result.scalar()
                
                # 2. è·å–å½“å‰åˆ†è¡¨æ•°é‡
                current_tables = list_bbox_tables(self.engine)
                bbox_partition_tables = [t for t in current_tables if t.startswith('clips_bbox_') and t != 'clips_bbox']
                current_table_count = len(bbox_partition_tables)
                
                print(f"ğŸ“‹ å‘ç° {current_table_count} ä¸ªbboxåˆ†è¡¨")
                
                # 3. æ£€æŸ¥è§†å›¾æ˜¯å¦éœ€è¦æ›´æ–°
                view_needs_update = False
                
                if not view_exists:
                    print(f"ğŸ“Œ è§†å›¾ {self.unified_view} ä¸å­˜åœ¨ï¼Œéœ€è¦åˆ›å»º")
                    view_needs_update = True
                elif force_refresh:
                    print(f"ğŸ”„ å¼ºåˆ¶åˆ·æ–°æ¨¡å¼ï¼Œå°†é‡æ–°åˆ›å»ºè§†å›¾")
                    view_needs_update = True
                elif current_table_count == 0:
                    print(f"âš ï¸ æ²¡æœ‰å‘ç°bboxåˆ†è¡¨ï¼Œæ— æ³•åˆ›å»ºç»Ÿä¸€è§†å›¾")
                    return False
                else:
                    # æ£€æŸ¥è§†å›¾çš„è¡¨æ•°é‡æ˜¯å¦åŒ¹é…å½“å‰åˆ†è¡¨æ•°é‡
                    try:
                        # å°è¯•ä»è§†å›¾å®šä¹‰ä¸­è·å–è¡¨æ•°é‡ï¼ˆç®€åŒ–æ£€æŸ¥ï¼‰
                        check_count_sql = text(f"SELECT COUNT(DISTINCT source_table) FROM {self.unified_view} LIMIT 1;")
                        view_table_result = conn.execute(check_count_sql)
                        view_table_count = view_table_result.scalar()
                        
                        if view_table_count != current_table_count:
                            print(f"ğŸ”„ è§†å›¾åŒ…å« {view_table_count} ä¸ªè¡¨ï¼Œå½“å‰æœ‰ {current_table_count} ä¸ªåˆ†è¡¨ï¼Œéœ€è¦æ›´æ–°")
                            view_needs_update = True
                    except Exception as e:
                        print(f"âš ï¸ æ£€æŸ¥è§†å›¾çŠ¶æ€å¤±è´¥: {str(e)[:100]}...")
                        print(f"ğŸ”„ ä¸ºå®‰å…¨èµ·è§ï¼Œå°†é‡æ–°åˆ›å»ºè§†å›¾")
                        view_needs_update = True
                
                # 4. åˆ›å»ºæˆ–æ›´æ–°è§†å›¾
                if view_needs_update:
                    if current_table_count == 0:
                        print(f"âŒ æ— æ³•åˆ›å»ºè§†å›¾ï¼šæ²¡æœ‰å¯ç”¨çš„bboxåˆ†è¡¨")
                        return False
                    
                    print(f"ğŸ› ï¸ æ­£åœ¨åˆ›å»º/æ›´æ–°ç»Ÿä¸€è§†å›¾...")
                    success = create_unified_view(self.engine, self.unified_view)
                    if not success:
                        print("âŒ åˆ›å»ºç»Ÿä¸€è§†å›¾å¤±è´¥")
                        return False
                    print(f"âœ… ç»Ÿä¸€è§†å›¾ {self.unified_view} åˆ›å»º/æ›´æ–°æˆåŠŸ")
                else:
                    print(f"âœ… ç»Ÿä¸€è§†å›¾ {self.unified_view} å·²æ˜¯æœ€æ–°çŠ¶æ€")
                
                # 5. è·³è¿‡è€—æ—¶çš„æ•°æ®ç»Ÿè®¡ï¼Œç›´æ¥éªŒè¯å¯ç”¨æ€§
                try:
                    # å¿«é€Ÿæ£€æŸ¥ï¼šåªæŸ¥çœ‹è§†å›¾æ˜¯å¦å¯è®¿é—®
                    sample_sql = text(f"SELECT 1 FROM {self.unified_view} LIMIT 1;")
                    conn.execute(sample_sql)
                    print(f"ğŸ“Š ç»Ÿä¸€è§†å›¾å·²å°±ç»ªä¸”å¯è®¿é—®")
                    
                    # è·³è¿‡è€—æ—¶çš„æ•°æ®ç»Ÿè®¡
                    print(f"ğŸ’¡ ç»Ÿä¸€è§†å›¾å·²å°±ç»ªï¼Œè·³è¿‡æ•°æ®ç»Ÿè®¡ä»¥èŠ‚çœæ—¶é—´")
                    
                    return True
                    
                except Exception as e:
                    print(f"âš ï¸ è§†å›¾æ•°æ®éªŒè¯å¤±è´¥: {str(e)[:100]}...")
                    return False
                
        except Exception as e:
            print(f"âŒ æ£€æŸ¥ç»Ÿä¸€è§†å›¾å¤±è´¥: {str(e)}")
            return False
    
    def create_analysis_table(self) -> bool:
        """åˆ›å»ºåˆ†æç»“æœè¡¨"""
        print("ğŸ› ï¸ åˆ›å»ºåˆ†æç»“æœè¡¨...")
        
        # è¯»å–åˆ›å»ºè¡¨çš„SQLè„šæœ¬
        sql_file = Path(__file__).parent / "sql" / "create_analysis_tables.sql"
        
        try:
            if sql_file.exists():
                # å¦‚æœSQLæ–‡ä»¶å­˜åœ¨ï¼Œä½¿ç”¨æ–‡ä»¶ä¸­çš„SQL
                with open(sql_file, 'r', encoding='utf-8') as f:
                    create_sql = f.read()
            else:
                # å¦åˆ™ä½¿ç”¨å†…ç½®çš„SQL
                create_sql = f"""
                -- åˆ›å»ºbboxå ç½®åˆ†æç»“æœè¡¨
                CREATE TABLE IF NOT EXISTS {self.analysis_table} (
                    id SERIAL PRIMARY KEY,
                    analysis_id VARCHAR(100) NOT NULL,
                    analysis_type VARCHAR(50) DEFAULT 'bbox_overlap',
                    analysis_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    hotspot_rank INTEGER,
                    overlap_count INTEGER,
                    total_overlap_area NUMERIC,
                    subdataset_count INTEGER,
                    scene_count INTEGER,
                    involved_subdatasets TEXT[],
                    involved_scenes TEXT[],
                    analysis_params TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );

                -- æ·»åŠ PostGISå‡ ä½•åˆ—
                DO $$
                BEGIN
                    -- æ£€æŸ¥å‡ ä½•åˆ—æ˜¯å¦å·²å­˜åœ¨
                    IF NOT EXISTS (
                        SELECT 1 FROM information_schema.columns 
                        WHERE table_name = '{self.analysis_table}' 
                        AND column_name = 'geometry'
                    ) THEN
                        PERFORM AddGeometryColumn('public', '{self.analysis_table}', 'geometry', 4326, 'GEOMETRY', 2);
                    END IF;
                END $$;

                -- åˆ›å»ºç´¢å¼•
                CREATE INDEX IF NOT EXISTS idx_bbox_overlap_analysis_id ON {self.analysis_table} (analysis_id);
                CREATE INDEX IF NOT EXISTS idx_bbox_overlap_rank ON {self.analysis_table} (hotspot_rank);
                CREATE INDEX IF NOT EXISTS idx_bbox_overlap_count ON {self.analysis_table} (overlap_count);
                CREATE INDEX IF NOT EXISTS idx_bbox_overlap_geom ON {self.analysis_table} USING GIST (geometry);
                """
            
            with self.engine.connect() as conn:
                conn.execute(text(create_sql))
                conn.commit()
                
            print(f"âœ… åˆ†æç»“æœè¡¨ {self.analysis_table} åˆ›å»ºæˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºåˆ†æç»“æœè¡¨å¤±è´¥: {str(e)}")
            return False
    
    def run_overlap_analysis(
        self, 
        analysis_id: Optional[str] = None,
        city_filter: Optional[str] = None,
        subdataset_filter: Optional[List[str]] = None,
        min_overlap_area: float = 0.0,
        top_n: int = 20,
        debug_mode: bool = False,
        intersect_only: bool = False,
        sample_check: int = 0
    ) -> str:
        """æ‰§è¡Œå ç½®åˆ†æ
        
        Args:
            analysis_id: åˆ†æIDï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
            city_filter: åŸå¸‚è¿‡æ»¤
            subdataset_filter: å­æ•°æ®é›†è¿‡æ»¤
            min_overlap_area: æœ€å°é‡å é¢ç§¯é˜ˆå€¼
            top_n: è¿”å›çš„çƒ­ç‚¹æ•°é‡
            
        Returns:
            åˆ†æID
        """
        if not analysis_id:
            analysis_id = f"bbox_overlap_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # è®¾ç½®å½“å‰åˆ†æçŠ¶æ€
        self.current_analysis_id = analysis_id
        self.analysis_start_time = datetime.now()
        self.debug_mode = debug_mode
        
        # ç›¸äº¤æ¨¡å¼å¤„ç†
        if intersect_only:
            min_overlap_area = 0.0
            print(f"ğŸ”— ç›¸äº¤æ¨¡å¼: åªè¦ç›¸äº¤å°±ç®—é‡å ï¼Œå¿½ç•¥é¢ç§¯é˜ˆå€¼")
        
        print(f"ğŸš€ å¼€å§‹å ç½®åˆ†æ: {analysis_id}")
        print(f"å‚æ•°: city_filter={city_filter}, min_overlap_area={min_overlap_area}, top_n={top_n}")
        if debug_mode:
            print(f"ğŸ” è°ƒè¯•æ¨¡å¼å·²å¼€å¯")
        print(f"ğŸ’¡ å¯ä»¥ä½¿ç”¨ Ctrl+C å®‰å…¨é€€å‡º")
        
        # è°ƒè¯•æ¨¡å¼ï¼šå…ˆåˆ†ææ•°æ®ç‰¹å¾
        if debug_mode:
            print(f"\nğŸ” æ­¥éª¤0: è°ƒè¯•æ•°æ®åˆ†æ")
            print("-" * 40)
            
            # è§£é‡Šé¢ç§¯å•ä½
            self.explain_area_units()
            
            # è¯¦ç»†æ•°æ®åˆ†æ
            debug_info = self.debug_spatial_data(city_filter, sample_check if sample_check > 0 else 5)
            
            # å»ºè®®é˜ˆå€¼
            if min_overlap_area == 0.0 and not intersect_only:
                suggested = self.suggest_overlap_threshold(city_filter)
                print(f"\nğŸ’¡ å½“å‰é˜ˆå€¼ä¸º0ï¼Œå»ºè®®è®¾ç½®ä¸º: {suggested:.12f}")
                print(f"ğŸ’¡ æˆ–ä½¿ç”¨ --intersect-only è¿›è¡Œçº¯ç›¸äº¤æ£€æµ‹")
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é€€å‡º
        self._check_shutdown()
        
        # æ„å»ºè¿‡æ»¤æ¡ä»¶
        where_conditions = []
        
        # ğŸ¯ åŸå¸‚è¿‡æ»¤ï¼ˆæ³¨æ„ï¼šç°åœ¨åŸºç¡€WHEREæ¡ä»¶å·²åŒ…å«a.city_id = b.city_idï¼‰
        if city_filter:
            # åŸå¸‚è¿‡æ»¤åªéœ€è¦é™åˆ¶å…¶ä¸­ä¸€ä¸ªè¡¨å³å¯ï¼Œå› ä¸ºå·²ç»æœ‰ç›¸åŒåŸå¸‚çº¦æŸ
            where_conditions.append(f"a.city_id = '{city_filter}'")
            print(f"ğŸ™ï¸ åŸå¸‚è¿‡æ»¤: {city_filter}")
        
        if subdataset_filter:
            subdataset_list = "', '".join(subdataset_filter)
            where_conditions.append(f"a.subdataset_name IN ('{subdataset_list}') AND b.subdataset_name IN ('{subdataset_list}')")
            print(f"ğŸ“¦ å­æ•°æ®é›†è¿‡æ»¤: {len(subdataset_filter)} ä¸ª")
        
        where_clause = "AND " + " AND ".join(where_conditions) if where_conditions else ""
        
        # è¯»å–åˆ†æSQLè„šæœ¬
        sql_file = Path(__file__).parent / "sql" / "overlap_analysis.sql"
        
        try:
            if sql_file.exists():
                # å¦‚æœSQLæ–‡ä»¶å­˜åœ¨ï¼Œè¯»å–å¹¶æ›¿æ¢å‚æ•°
                with open(sql_file, 'r', encoding='utf-8') as f:
                    analysis_sql_template = f.read()
                
                # æ›¿æ¢å‚æ•°
                analysis_sql = analysis_sql_template.format(
                    unified_view=self.unified_view,
                    analysis_table=self.analysis_table,
                    analysis_id=analysis_id,
                    where_clause=where_clause,
                    min_overlap_area=min_overlap_area,
                    top_n=top_n
                )
            else:
                # å†…ç½®SQL
                analysis_sql = f"""
                WITH overlapping_areas AS (
                    SELECT 
                        ROW_NUMBER() OVER (ORDER BY a.subdataset_name, a.scene_token, a.sample_token) as bbox_a_id,
                        ROW_NUMBER() OVER (ORDER BY b.subdataset_name, b.scene_token, b.sample_token) as bbox_b_id,
                        a.subdataset_name as subdataset_a,
                        b.subdataset_name as subdataset_b,
                        a.scene_token as scene_a,
                        b.scene_token as scene_b,
                        ST_Intersection(a.geometry, b.geometry) as overlap_geometry,
                        ST_Area(ST_Intersection(a.geometry, b.geometry)) as overlap_area
                    FROM {self.unified_view} a
                    JOIN {self.unified_view} b ON (a.subdataset_name || '|' || a.scene_token || '|' || a.sample_token) < 
                                                  (b.subdataset_name || '|' || b.scene_token || '|' || b.sample_token)
                    WHERE ST_Intersects(a.geometry, b.geometry)
                    AND ST_Area(ST_Intersection(a.geometry, b.geometry)) > {min_overlap_area}
                    AND NOT ST_Equals(a.geometry, b.geometry)
                    -- ğŸ¯ åªåˆ†æç›¸åŒåŸå¸‚çš„bbox
                    AND a.city_id = b.city_id
                    AND a.city_id IS NOT NULL
                    -- ğŸ¯ åªåˆ†æè´¨é‡åˆæ ¼çš„æ•°æ®
                    AND a.all_good = true
                    AND b.all_good = true
                    {where_clause}
                ),
                -- ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨çœŸæ­£çš„ç©ºé—´è¿é€šæ€§èšç±»
                overlap_clusters AS (
                    SELECT 
                        overlap_geometry,
                        overlap_area,
                        subdataset_a,
                        subdataset_b,
                        scene_a,
                        scene_b,
                        -- ä½¿ç”¨ ST_ClusterDBSCAN è¿›è¡Œç©ºé—´èšç±»
                        -- eps=0 è¡¨ç¤ºåªæœ‰ç›´æ¥ç›¸äº¤çš„å‡ ä½•ä½“æ‰å½’ä¸ºä¸€ç»„
                        -- minpoints=1 è¡¨ç¤ºå•ä¸ªé‡å ä¹Ÿå¯ä»¥å½¢æˆçƒ­ç‚¹
                        ST_ClusterDBSCAN(overlap_geometry, eps := 0, minpoints := 1) OVER() as cluster_id
                    FROM overlapping_areas
                ),
                overlap_hotspots AS (
                    SELECT 
                        cluster_id,
                        -- å¯¹æ¯ä¸ªèšç±»ï¼Œåˆå¹¶æ‰€æœ‰é‡å åŒºåŸŸ
                        ST_Union(overlap_geometry) as hotspot_geometry,
                        COUNT(*) as overlap_count,
                        ARRAY_AGG(DISTINCT subdataset_a) || ARRAY_AGG(DISTINCT subdataset_b) as involved_subdatasets,
                        ARRAY_AGG(DISTINCT scene_a) || ARRAY_AGG(DISTINCT scene_b) as involved_scenes,
                        SUM(overlap_area) as total_overlap_area
                    FROM overlap_clusters
                    WHERE cluster_id IS NOT NULL  -- æ’é™¤å™ªå£°ç‚¹
                    GROUP BY cluster_id
                    HAVING COUNT(*) >= 1  -- è‡³å°‘åŒ…å«ä¸€ä¸ªé‡å åŒºåŸŸ
                )
                INSERT INTO {self.analysis_table} 
                (analysis_id, hotspot_rank, overlap_count, total_overlap_area, 
                 subdataset_count, scene_count, involved_subdatasets, involved_scenes, geometry, analysis_params)
                SELECT 
                    '{analysis_id}' as analysis_id,
                    ROW_NUMBER() OVER (ORDER BY overlap_count DESC) as hotspot_rank,
                    overlap_count,
                    total_overlap_area,
                    ARRAY_LENGTH(involved_subdatasets, 1) as subdataset_count,
                    ARRAY_LENGTH(involved_scenes, 1) as scene_count,
                    involved_subdatasets,
                    involved_scenes,
                    hotspot_geometry as geometry,
                    '{{"city_filter": "{city_filter}", "min_overlap_area": {min_overlap_area}, "top_n": {top_n}}}' as analysis_params
                FROM overlap_hotspots
                ORDER BY overlap_count DESC
                LIMIT {top_n};
                """
            
            print(f"âš¡ æ‰§è¡Œç©ºé—´å ç½®åˆ†æSQL...")
            self._check_shutdown()  # æ‰§è¡Œå‰æ£€æŸ¥
            
            with self.engine.connect() as conn:
                self.current_connection = conn  # ä¿å­˜è¿æ¥å¼•ç”¨
                
                result = conn.execute(text(analysis_sql))
                self._check_shutdown()  # SQLæ‰§è¡Œåæ£€æŸ¥
                
                conn.commit()
                print(f"âœ… SQLæ‰§è¡Œå®Œæˆï¼Œæ­£åœ¨ç»Ÿè®¡ç»“æœ...")
                
                # è·å–æ’å…¥çš„è®°å½•æ•°
                count_sql = text(f"SELECT COUNT(*) FROM {self.analysis_table} WHERE analysis_id = '{analysis_id}';")
                count_result = conn.execute(count_sql)
                inserted_count = count_result.scalar()
                
                self.current_connection = None  # æ¸…é™¤è¿æ¥å¼•ç”¨
                
            print(f"âœ… å ç½®åˆ†æå®Œæˆï¼Œå‘ç° {inserted_count} ä¸ªé‡å çƒ­ç‚¹")
            elapsed = datetime.now() - self.analysis_start_time
            print(f"â±ï¸ æ€»è€—æ—¶: {elapsed}")
            return analysis_id
            
        except Exception as e:
            print(f"âŒ å ç½®åˆ†æå¤±è´¥: {str(e)}")
            raise
    
    def create_qgis_view(self, analysis_id: Optional[str] = None) -> bool:
        """åˆ›å»ºQGISå…¼å®¹å¯¹è±¡ï¼ˆå®é™…åˆ›å»ºè¡¨è€Œéè§†å›¾ï¼Œä½†ä¿æŒæ–¹æ³•åå…¼å®¹æ€§ï¼‰"""
        print("ğŸ¨ åˆ›å»ºQGISå…¼å®¹è¡¨...")
        
        # QGISè¡¨åï¼ˆä¿æŒä¸åŸæœ‰è§†å›¾åçš„å…¼å®¹æ€§ï¼‰
        qgis_table = "qgis_bbox_overlap_hotspots"
        
        where_clause = ""
        if analysis_id:
            where_clause = f"WHERE analysis_id = '{analysis_id}'"
            print(f"ğŸ¯ å¤„ç†åˆ†æ: {analysis_id}")
        
        try:
            with self.engine.connect() as conn:
                # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
                check_table_sql = text(f"""
                    SELECT EXISTS (
                        SELECT FROM information_schema.tables 
                        WHERE table_schema = 'public' 
                        AND table_name = '{qgis_table}'
                    );
                """)
                
                table_exists = conn.execute(check_table_sql).scalar()
                
                if table_exists:
                    if analysis_id:
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«å½“å‰åˆ†æç»“æœ
                        check_analysis_sql = text(f"""
                            SELECT COUNT(*) FROM {qgis_table} 
                            WHERE analysis_id = '{analysis_id}';
                        """)
                        existing_count = conn.execute(check_analysis_sql).scalar()
                        if existing_count > 0:
                            print(f"ğŸ“Š å½“å‰åˆ†æå·²å­˜åœ¨: {existing_count} æ¡è®°å½•")
                            return True
                        else:
                            print(f"â• è¿½åŠ å½“å‰åˆ†æç»“æœ...")
                            # åªæ’å…¥æ–°çš„åˆ†æç»“æœ
                            insert_sql = text(f"""
                                INSERT INTO {qgis_table} (
                                    analysis_id, hotspot_rank, overlap_count, 
                                    total_overlap_area, subdataset_count, scene_count, 
                                    involved_subdatasets, involved_scenes, density_level, 
                                    geometry, created_at
                                )
                                SELECT 
                                    analysis_id,
                                    hotspot_rank,
                                    overlap_count,
                                    total_overlap_area,
                                    subdataset_count,
                                    scene_count,
                                    involved_subdatasets,
                                    involved_scenes,
                                    CASE
                                        WHEN overlap_count >= 10 THEN 'High Density'
                                        WHEN overlap_count >= 5 THEN 'Medium Density'
                                        ELSE 'Low Density'
                                    END as density_level,
                                    geometry,
                                    created_at
                                FROM {self.analysis_table}
                                WHERE analysis_type = 'bbox_overlap'
                                AND analysis_id = '{analysis_id}'
                                ORDER BY hotspot_rank;
                            """)
                            conn.execute(insert_sql)
                            conn.commit()
                            
                            # æ£€æŸ¥æ’å…¥çš„è®°å½•æ•°
                            new_count = conn.execute(check_analysis_sql).scalar()
                            print(f"âœ… æ–°åˆ†æç»“æœå·²è¿½åŠ : {new_count} æ¡è®°å½•")
                            return True
                    else:
                        print(f"ğŸ“‹ è¡¨ {qgis_table} å·²å­˜åœ¨ï¼ŒåŒ…å«æ‰€æœ‰å†å²åˆ†æç»“æœ")
                        return True
                
                # åˆ›å»ºæ–°è¡¨
                print(f"ğŸ“‹ åˆ›å»ºQGISå…¼å®¹è¡¨...")
                create_sql = text(f"""
                    CREATE TABLE {qgis_table} (
                        qgis_fid SERIAL PRIMARY KEY,
                        analysis_id VARCHAR(100) NOT NULL,
                        hotspot_rank INTEGER,
                        overlap_count INTEGER,
                        total_overlap_area NUMERIC,
                        subdataset_count INTEGER,
                        scene_count INTEGER,
                        involved_subdatasets TEXT[],
                        involved_scenes TEXT[],
                        density_level VARCHAR(20),
                        geometry GEOMETRY(GEOMETRY, 4326),
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    );
                """)
                
                conn.execute(create_sql)
                
                # æ’å…¥æ•°æ®
                print(f"ğŸ“Š æ’å…¥åˆ†ææ•°æ®...")
                insert_sql = text(f"""
                    INSERT INTO {qgis_table} (
                        analysis_id, hotspot_rank, overlap_count, 
                        total_overlap_area, subdataset_count, scene_count, 
                        involved_subdatasets, involved_scenes, density_level, 
                        geometry, created_at
                    )
                    SELECT 
                        analysis_id,
                        hotspot_rank,
                        overlap_count,
                        total_overlap_area,
                        subdataset_count,
                        scene_count,
                        involved_subdatasets,
                        involved_scenes,
                        CASE
                            WHEN overlap_count >= 10 THEN 'High Density'
                            WHEN overlap_count >= 5 THEN 'Medium Density'
                            ELSE 'Low Density'
                        END as density_level,
                        geometry,
                        created_at
                    FROM {self.analysis_table}
                    WHERE analysis_type = 'bbox_overlap'
                    {where_clause}
                    ORDER BY hotspot_rank;
                """)
                
                conn.execute(insert_sql)
                
                # åˆ›å»ºç©ºé—´ç´¢å¼•
                print(f"ğŸ“ åˆ›å»ºç©ºé—´ç´¢å¼•...")
                spatial_index_sql = text(f"CREATE INDEX idx_{qgis_table}_geom ON {qgis_table} USING GIST (geometry);")
                conn.execute(spatial_index_sql)
                
                # åˆ›å»ºå…¶ä»–ç´¢å¼•
                index_sqls = [
                    f"CREATE INDEX idx_{qgis_table}_analysis_id ON {qgis_table} (analysis_id);",
                    f"CREATE INDEX idx_{qgis_table}_density ON {qgis_table} (density_level);",
                    f"CREATE INDEX idx_{qgis_table}_rank ON {qgis_table} (hotspot_rank);",
                ]
                
                for idx_sql in index_sqls:
                    conn.execute(text(idx_sql))
                
                # æ·»åŠ æ³¨é‡Š
                comment_sql = text(f"""
                    COMMENT ON TABLE {qgis_table} IS 
                    'QGISå…¼å®¹çš„bboxé‡å çƒ­ç‚¹è¡¨ï¼Œä»åˆ†æç»“æœç”Ÿæˆï¼ˆæ›¿ä»£è§†å›¾æ–¹æ¡ˆï¼‰';
                """)
                conn.execute(comment_sql)
                
                conn.commit()
                
                # æ£€æŸ¥è®°å½•æ•°
                count_sql = text(f"SELECT COUNT(*) FROM {qgis_table};")
                record_count = conn.execute(count_sql).scalar()
                
                print(f"âœ… QGISè¡¨åˆ›å»ºæˆåŠŸ")
                print(f"ğŸ“Š è®°å½•æ•°: {record_count}")
                print(f"ğŸ“‹ è¡¨å: {qgis_table}")
                
                # æä¾›QGISè¿æ¥ä¿¡æ¯
                print(f"\nğŸ¨ QGISè¿æ¥ä¿¡æ¯:")
                print(f"   è¡¨å: {qgis_table}")
                print(f"   ä¸»é”®å­—æ®µ: qgis_fid")
                print(f"   å‡ ä½•å­—æ®µ: geometry")
                print(f"   æ ·å¼å­—æ®µ: density_level")
                print(f"   è¿‡æ»¤å­—æ®µ: analysis_id")
                
                return True
                
        except Exception as e:
            print(f"âŒ åˆ›å»ºQGISå¯¹è±¡å¤±è´¥: {str(e)}")
            return False
    
    def get_city_analysis_suggestions(self) -> pd.DataFrame:
        """è·å–åŸå¸‚åˆ†æå»ºè®®ï¼Œå¸®åŠ©ç”¨æˆ·é€‰æ‹©åˆé€‚çš„åŸå¸‚"""
        print("ğŸ” åˆ†æå„åŸå¸‚çš„æ•°æ®åˆ†å¸ƒï¼Œç”Ÿæˆåˆ†æå»ºè®®...")
        
        sql = text(f"""
            WITH city_stats AS (
                SELECT 
                    city_id,
                    COUNT(*) as total_bbox_count,
                    COUNT(*) FILTER (WHERE all_good = true) as good_bbox_count,
                    COUNT(DISTINCT subdataset_name) as subdataset_count,
                    ROUND(100.0 * COUNT(*) FILTER (WHERE all_good = true) / COUNT(*), 1) as good_percent,
                    -- ä¼°ç®—å¯èƒ½çš„é‡å å¯¹æ•°é‡ï¼ˆåŸºäºæ•°æ®å¯†åº¦ï¼‰
                    CASE 
                        WHEN COUNT(*) FILTER (WHERE all_good = true) > 10000 THEN 'High'
                        WHEN COUNT(*) FILTER (WHERE all_good = true) > 1000 THEN 'Medium' 
                        ELSE 'Low'
                    END as analysis_complexity,
                    -- é¢„ä¼°åˆ†ææ—¶é—´ï¼ˆåŸºäºæ•°æ®é‡ï¼‰
                    CASE 
                        WHEN COUNT(*) FILTER (WHERE all_good = true) > 50000 THEN '> 10åˆ†é’Ÿ'
                        WHEN COUNT(*) FILTER (WHERE all_good = true) > 10000 THEN '2-10åˆ†é’Ÿ'
                        WHEN COUNT(*) FILTER (WHERE all_good = true) > 1000 THEN '< 2åˆ†é’Ÿ'
                        ELSE '< 30ç§’'
                    END as estimated_time
                FROM {self.unified_view}
                WHERE city_id IS NOT NULL
                GROUP BY city_id
                HAVING COUNT(*) FILTER (WHERE all_good = true) > 0
            )
            SELECT 
                city_id,
                total_bbox_count,
                good_bbox_count,
                subdataset_count,
                good_percent,
                analysis_complexity,
                estimated_time,
                -- æ¨èåº¦è¯„åˆ†
                CASE 
                    WHEN good_bbox_count BETWEEN 1000 AND 20000 AND good_percent > 90 THEN 'â­â­â­ æ¨è'
                    WHEN good_bbox_count BETWEEN 500 AND 50000 AND good_percent > 85 THEN 'â­â­ è¾ƒå¥½'
                    WHEN good_bbox_count > 100 THEN 'â­ å¯ç”¨'
                    ELSE 'âŒ ä¸å»ºè®®'
                END as recommendation
            FROM city_stats
            ORDER BY 
                CASE 
                    WHEN good_bbox_count BETWEEN 1000 AND 20000 AND good_percent > 90 THEN 1
                    WHEN good_bbox_count BETWEEN 500 AND 50000 AND good_percent > 85 THEN 2
                    WHEN good_bbox_count > 100 THEN 3
                    ELSE 4
                END,
                good_bbox_count DESC;
        """)
        
        try:
            result_df = pd.read_sql(sql, self.engine)
            
            if not result_df.empty:
                print(f"\nğŸ“Š åŸå¸‚åˆ†æå»ºè®®è¡¨:")
                print(result_df.to_string(index=False))
                
                # æä¾›å…·ä½“å»ºè®®
                recommended = result_df[result_df['recommendation'].str.contains('â­â­â­')]
                if not recommended.empty:
                    best_city = recommended.iloc[0]['city_id']
                    print(f"\nğŸ’¡ æ¨èåŸå¸‚: {best_city}")
                    print(f"   - æ•°æ®é‡é€‚ä¸­ï¼Œè´¨é‡è¾ƒé«˜")
                    print(f"   - é¢„ä¼°åˆ†ææ—¶é—´: {recommended.iloc[0]['estimated_time']}")
                    print(f"   - å»ºè®®å‘½ä»¤: --city {best_city}")
                
                return result_df
            else:
                print("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„åŸå¸‚æ•°æ®")
                return pd.DataFrame()
                
        except Exception as e:
            print(f"âŒ è·å–åŸå¸‚å»ºè®®å¤±è´¥: {str(e)}")
            return pd.DataFrame()
    
    def estimate_analysis_time(self, city_filter: str = None) -> dict:
        """ä¼°ç®—åˆ†ææ—¶é—´å’Œæ•°æ®é‡"""
        print("â±ï¸ ä¼°ç®—åˆ†ææ—¶é—´...")
        
        where_condition = f"WHERE city_id = '{city_filter}'" if city_filter else "WHERE city_id IS NOT NULL"
        
        sql = text(f"""
            SELECT 
                COUNT(*) FILTER (WHERE all_good = true) as analyzable_count,
                -- ä¼°ç®—å¯èƒ½çš„é‡å å¯¹æ•°é‡ï¼ˆn*(n-1)/2çš„ç®€åŒ–ä¼°ç®—ï¼‰
                CASE 
                    WHEN COUNT(*) FILTER (WHERE all_good = true) > 0 THEN
                        LEAST(
                            COUNT(*) FILTER (WHERE all_good = true) * (COUNT(*) FILTER (WHERE all_good = true) - 1) / 2,
                            1000000  -- é™åˆ¶æœ€å¤§ä¼°ç®—æ•°
                        )
                    ELSE 0
                END as estimated_pairs,
                CASE 
                    WHEN COUNT(*) FILTER (WHERE all_good = true) > 100000 THEN 'âš ï¸ å¾ˆé•¿ (>30åˆ†é’Ÿ)'
                    WHEN COUNT(*) FILTER (WHERE all_good = true) > 50000 THEN 'â³ è¾ƒé•¿ (10-30åˆ†é’Ÿ)'
                    WHEN COUNT(*) FILTER (WHERE all_good = true) > 10000 THEN 'â° ä¸­ç­‰ (2-10åˆ†é’Ÿ)'
                    WHEN COUNT(*) FILTER (WHERE all_good = true) > 1000 THEN 'âš¡ è¾ƒå¿« (<2åˆ†é’Ÿ)'
                    ELSE 'ğŸš€ å¾ˆå¿« (<30ç§’)'
                END as time_estimate,
                {f"'{city_filter}'" if city_filter else "'å…¨éƒ¨åŸå¸‚'"} as scope
            FROM {self.unified_view}
            {where_condition};
        """)
        
        try:
            result = self.engine.execute(sql).fetchone()
            
            estimate = {
                'analyzable_count': result.analyzable_count,
                'estimated_pairs': result.estimated_pairs,
                'time_estimate': result.time_estimate,
                'scope': result.scope
            }
            
            print(f"ğŸ“Š åˆ†æèŒƒå›´: {estimate['scope']}")
            print(f"ğŸ“ˆ å¯åˆ†ææ•°æ®: {estimate['analyzable_count']:,} ä¸ªbbox")
            print(f"ğŸ”— é¢„ä¼°é…å¯¹æ•°: {estimate['estimated_pairs']:,}")
            print(f"â±ï¸ é¢„ä¼°æ—¶é—´: {estimate['time_estimate']}")
            
            if estimate['analyzable_count'] > 50000:
                print(f"ğŸ’¡ å»ºè®®: æ•°æ®é‡è¾ƒå¤§ï¼Œå»ºè®®æŒ‡å®šå…·ä½“åŸå¸‚è¿›è¡Œåˆ†æ")
                print(f"ğŸ’¡ å‘½ä»¤: --city your_city_name")
            
            return estimate
            
        except Exception as e:
            print(f"âŒ æ—¶é—´ä¼°ç®—å¤±è´¥: {str(e)}")
            return {}

    def get_analysis_summary(self, analysis_id: str) -> pd.DataFrame:
        """è·å–åˆ†æç»“æœæ‘˜è¦"""
        sql = text(f"""
            SELECT 
                hotspot_rank,
                overlap_count,
                ROUND(total_overlap_area::numeric, 4) as total_overlap_area,
                subdataset_count,
                scene_count,
                involved_subdatasets,
                density_level
            FROM {self.qgis_view}
            WHERE analysis_id = :analysis_id
            ORDER BY hotspot_rank
            LIMIT 10;
        """)
        
        return pd.read_sql(sql, self.engine, params={'analysis_id': analysis_id})
    
    def export_for_qgis(self, analysis_id: str) -> Dict[str, Any]:
        """å¯¼å‡ºQGISå¯è§†åŒ–ä¿¡æ¯"""
        return {
            'analysis_id': analysis_id,
            'qgis_view': self.qgis_view,
            'unified_view': self.unified_view,
            'connection_info': {
                'host': 'local_pg',
                'port': 5432,
                'database': 'postgres',
                'username': 'postgres'
            },
            'visualization_tips': {
                'primary_key': 'id',
                'geometry_column': 'geometry',
                'style_column': 'density_level',
                'label_column': 'overlap_count',
                'filter_column': 'analysis_id'
            }
        }
    
    def list_simple(self) -> pd.DataFrame:
        """ç®€å•åˆ—è¡¨åˆ†æç»“æœï¼ˆå¿«é€ŸæŸ¥è¯¢ï¼Œæ— å¤æ‚èšåˆï¼‰
        
        Returns:
            åŒ…å«åŸºæœ¬åˆ†æç»“æœä¿¡æ¯çš„DataFrame
        """
        print("ğŸ“‹ æŸ¥è¯¢åˆ†æç»“æœï¼ˆç®€å•æ¨¡å¼ï¼‰...")
        
        sql = text(f"""
            SELECT 
                analysis_id,
                COUNT(*) as hotspot_count,
                MIN(created_at) as created_at,
                MAX(created_at) as last_updated
            FROM {self.analysis_table}
            GROUP BY analysis_id
            ORDER BY MIN(created_at) DESC;
        """)
        
        try:
            with self.engine.connect() as conn:
                result_df = pd.read_sql(sql, conn)
                
                if not result_df.empty:
                    print(f"ğŸ“Š æ‰¾åˆ° {len(result_df)} ä¸ªåˆ†æç»“æœ:")
                    print(f"{'åˆ†æID':<40} {'çƒ­ç‚¹æ•°':<8} {'åˆ›å»ºæ—¶é—´':<20}")
                    print("-" * 70)
                    for _, row in result_df.iterrows():
                        print(f"{row['analysis_id']:<40} {row['hotspot_count']:<8} {row['created_at']}")
                else:
                    print("ğŸ“­ æ²¡æœ‰æ‰¾åˆ°åˆ†æç»“æœ")
                
                return result_df
                
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢åˆ†æç»“æœå¤±è´¥: {str(e)}")
            return pd.DataFrame()
    
    def cleanup_all(self, confirm: bool = False) -> bool:
        """è¶…ç®€å•çš„å…¨é‡æ¸…ç†ï¼ˆåˆ é™¤æ‰€æœ‰åˆ†ææ•°æ®ï¼‰
        
        Args:
            confirm: æ˜¯å¦ç¡®è®¤åˆ é™¤
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        print("ğŸ§¹ å…¨é‡æ¸…ç†åˆ†ææ•°æ®...")
        
        # è¦æ¸…ç†çš„å¯¹è±¡ï¼ˆè¡¨å’Œè§†å›¾ï¼‰
        objects_to_clean = [
            "qgis_bbox_overlap_hotspots",  # QGISå¯¹è±¡ï¼ˆå¯èƒ½æ˜¯è¡¨æˆ–è§†å›¾ï¼‰
            self.analysis_table            # ä¸»åˆ†æç»“æœè¡¨
        ]
        
        try:
            with self.engine.connect() as conn:
                # å…ˆæ£€æŸ¥æ•°æ®é‡å’Œå¯¹è±¡ç±»å‹
                total_records = 0
                existing_objects = []
                
                for obj_name in objects_to_clean:
                    # æ£€æŸ¥æ˜¯å¦ä¸ºè¡¨
                    check_table_sql = text(f"""
                        SELECT EXISTS (
                            SELECT FROM information_schema.tables 
                            WHERE table_schema = 'public' 
                            AND table_name = '{obj_name}'
                        );
                    """)
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸ºè§†å›¾
                    check_view_sql = text(f"""
                        SELECT EXISTS (
                            SELECT FROM information_schema.views 
                            WHERE table_schema = 'public' 
                            AND table_name = '{obj_name}'
                        );
                    """)
                    
                    is_table = conn.execute(check_table_sql).scalar()
                    is_view = conn.execute(check_view_sql).scalar()
                    
                    if is_table:
                        existing_objects.append((obj_name, "table"))
                        # è·å–è®°å½•æ•°
                        try:
                            count_sql = text(f"SELECT COUNT(*) FROM {obj_name};")
                            count = conn.execute(count_sql).scalar()
                            total_records += count
                            print(f"ğŸ“‹ {obj_name} (è¡¨): {count:,} æ¡è®°å½•")
                        except:
                            print(f"ğŸ“‹ {obj_name} (è¡¨): å­˜åœ¨ï¼ˆæ— æ³•ç»Ÿè®¡è®°å½•æ•°ï¼‰")
                    elif is_view:
                        existing_objects.append((obj_name, "view"))
                        # è·å–è®°å½•æ•°
                        try:
                            count_sql = text(f"SELECT COUNT(*) FROM {obj_name};")
                            count = conn.execute(count_sql).scalar()
                            total_records += count
                            print(f"ğŸ“‹ {obj_name} (è§†å›¾): {count:,} æ¡è®°å½•")
                        except:
                            print(f"ğŸ“‹ {obj_name} (è§†å›¾): å­˜åœ¨ï¼ˆæ— æ³•ç»Ÿè®¡è®°å½•æ•°ï¼‰")
                
                if not existing_objects:
                    print("ğŸ“­ æ²¡æœ‰æ‰¾åˆ°ç›¸å…³å¯¹è±¡ï¼Œæ— éœ€æ¸…ç†")
                    return True
                
                print(f"\nğŸ“Š æ€»è®¡: {len(existing_objects)} ä¸ªå¯¹è±¡, {total_records:,} æ¡è®°å½•")
                
                if not confirm:
                    print(f"\nğŸ§ª è¯•è¿è¡Œæ¨¡å¼ - æœªå®é™…åˆ é™¤")
                    print(f"ğŸ’¡ ä½¿ç”¨ confirm=True æ‰§è¡Œå®é™…åˆ é™¤")
                    return False
                
                # æ‰§è¡Œæ¸…ç†
                print(f"\nğŸ—‘ï¸ å¼€å§‹åˆ é™¤...")
                for obj_name, obj_type in existing_objects:
                    if obj_name == self.analysis_table:
                        # å¯¹äºä¸»è¡¨ï¼Œä½¿ç”¨DELETEè€Œä¸æ˜¯DROP
                        delete_sql = text(f"DELETE FROM {obj_name};")
                        conn.execute(delete_sql)
                        print(f"âœ… æ¸…ç©ºè¡¨: {obj_name}")
                    else:
                        # å¯¹äºQGISå¯¹è±¡ï¼Œå…ˆå°è¯•åˆ é™¤è§†å›¾ï¼Œå¤±è´¥åˆ™åˆ é™¤è¡¨
                        try:
                            drop_view_sql = text(f"DROP VIEW IF EXISTS {obj_name};")
                            conn.execute(drop_view_sql)
                            print(f"âœ… åˆ é™¤è§†å›¾: {obj_name}")
                        except:
                            try:
                                drop_table_sql = text(f"DROP TABLE IF EXISTS {obj_name};")
                                conn.execute(drop_table_sql)
                                print(f"âœ… åˆ é™¤è¡¨: {obj_name}")
                            except Exception as e:
                                print(f"âš ï¸ æ— æ³•åˆ é™¤ {obj_name}: {str(e)}")
                
                conn.commit()
                print(f"âœ… å…¨é‡æ¸…ç†å®Œæˆ")
                return True
                
        except Exception as e:
            print(f"âŒ æ¸…ç†å¤±è´¥: {str(e)}")
            return False
    
    # å¤æ‚çš„æ¸…ç†æ–¹æ³•å·²åˆ é™¤ï¼Œè¯·ä½¿ç”¨ cleanup_all() è¿›è¡Œå…¨é‡æ¸…ç†
    
    def cleanup_qgis_views(self, confirm: bool = False) -> bool:
        """æ¸…ç†QGISç›¸å…³å¯¹è±¡ï¼ˆè¡¨å’Œè§†å›¾ï¼‰
        
        Args:
            confirm: æ˜¯å¦ç¡®è®¤åˆ é™¤
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        print("ğŸ¨ æ¸…ç†QGISç›¸å…³å¯¹è±¡...")
        
        # æ£€æŸ¥è¡¨å’Œè§†å›¾
        objects_to_check = [
            ("qgis_bbox_overlap_hotspots", "table"),
            ("qgis_bbox_overlap_hotspots_table", "table"),
            (self.qgis_view, "view"),
        ]
        
        try:
            with self.engine.connect() as conn:
                existing_objects = []
                
                for obj_name, obj_type in objects_to_check:
                    if obj_type == "table":
                        check_sql = text(f"""
                            SELECT EXISTS (
                                SELECT FROM information_schema.tables 
                                WHERE table_schema = 'public' 
                                AND table_name = '{obj_name}'
                            );
                        """)
                    else:  # view
                        check_sql = text(f"""
                            SELECT EXISTS (
                                SELECT FROM information_schema.views 
                                WHERE table_schema = 'public' 
                                AND table_name = '{obj_name}'
                            );
                        """)
                    
                    if conn.execute(check_sql).scalar():
                        existing_objects.append((obj_name, obj_type))
                
                if not existing_objects:
                    print("ğŸ“­ æ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„QGISå¯¹è±¡")
                    return True
                
                print(f"ğŸ“‹ æ‰¾åˆ°ä»¥ä¸‹å¯¹è±¡:")
                for obj_name, obj_type in existing_objects:
                    # è·å–è®°å½•æ•°ï¼ˆå¦‚æœæ˜¯è¡¨çš„è¯ï¼‰
                    if obj_type == "table":
                        try:
                            count_sql = text(f"SELECT COUNT(*) FROM {obj_name};")
                            count = conn.execute(count_sql).scalar()
                            print(f"   - {obj_name} ({obj_type}, {count} æ¡è®°å½•)")
                        except:
                            print(f"   - {obj_name} ({obj_type})")
                    else:
                        print(f"   - {obj_name} ({obj_type})")
                
                if not confirm:
                    print(f"\nğŸ§ª è¯•è¿è¡Œæ¨¡å¼ - æœªå®é™…åˆ é™¤")
                    print(f"ğŸ’¡ ä½¿ç”¨ confirm=True æ‰§è¡Œå®é™…åˆ é™¤")
                    return False
                
                # åˆ é™¤å¯¹è±¡
                for obj_name, obj_type in existing_objects:
                    if obj_type == "table":
                        drop_sql = text(f"DROP TABLE IF EXISTS {obj_name};")
                    else:
                        drop_sql = text(f"DROP VIEW IF EXISTS {obj_name};")
                    
                    conn.execute(drop_sql)
                    print(f"âœ… åˆ é™¤{obj_type}: {obj_name}")
                
                conn.commit()
                print(f"âœ… æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {len(existing_objects)} ä¸ªå¯¹è±¡")
                return True
                
        except Exception as e:
            print(f"âŒ æ¸…ç†QGISå¯¹è±¡å¤±è´¥: {str(e)}")
            return False
    
    def debug_spatial_data(self, city_filter: str = None, sample_size: int = 10) -> Dict[str, Any]:
        """è°ƒè¯•ç©ºé—´æ•°æ®ï¼Œæ£€æŸ¥å‡ ä½•åˆ†å¸ƒå’Œè´¨é‡
        
        Args:
            city_filter: åŸå¸‚è¿‡æ»¤
            sample_size: é‡‡æ ·æ•°é‡
            
        Returns:
            è°ƒè¯•ä¿¡æ¯å­—å…¸
        """
        print("ğŸ” è°ƒè¯•ç©ºé—´æ•°æ®...")
        
        where_condition = ""
        if city_filter:
            where_condition = f"WHERE city_id = '{city_filter}'"
            print(f"ğŸ¯ èšç„¦åŸå¸‚: {city_filter}")
        else:
            where_condition = "WHERE city_id IS NOT NULL"
        
        debug_info = {}
        
        try:
            with self.engine.connect() as conn:
                # 1. åŸºç¡€ç»Ÿè®¡
                basic_stats_sql = text(f"""
                    SELECT 
                        COUNT(*) as total_count,
                        COUNT(*) FILTER (WHERE all_good = true) as good_count,
                        COUNT(DISTINCT city_id) as city_count,
                        COUNT(DISTINCT subdataset_name) as subdataset_count,
                        ROUND(AVG(ST_Area(geometry))::numeric, 10) as avg_area,
                        ROUND(MIN(ST_Area(geometry))::numeric, 10) as min_area,
                        ROUND(MAX(ST_Area(geometry))::numeric, 10) as max_area,
                        -- é¢ç§¯å•ä½è§£é‡Š
                        CASE 
                            WHEN AVG(ST_Area(geometry)) > 1 THEN 'å¹³æ–¹åº¦ (åº¦Â²)'
                            WHEN AVG(ST_Area(geometry)) > 0.0001 THEN 'å¹³æ–¹åº¦ (è¾ƒå¤§)'
                            ELSE 'å¹³æ–¹åº¦ (è¾ƒå°)'
                        END as area_unit_note
                    FROM {self.unified_view}
                    {where_condition};
                """)
                
                basic_stats = conn.execute(basic_stats_sql).fetchone()
                debug_info['basic_stats'] = dict(basic_stats._mapping)
                
                print(f"ğŸ“Š åŸºç¡€ç»Ÿè®¡:")
                print(f"   æ€»æ•°é‡: {basic_stats.total_count:,}")
                print(f"   è´¨é‡è‰¯å¥½: {basic_stats.good_count:,}")
                print(f"   åŸå¸‚æ•°: {basic_stats.city_count}")
                print(f"   å­æ•°æ®é›†æ•°: {basic_stats.subdataset_count}")
                print(f"   å¹³å‡é¢ç§¯: {basic_stats.avg_area} {basic_stats.area_unit_note}")
                print(f"   é¢ç§¯èŒƒå›´: {basic_stats.min_area} ~ {basic_stats.max_area}")
                
                # 2. ç©ºé—´èŒƒå›´æ£€æŸ¥
                extent_sql = text(f"""
                    SELECT 
                        ROUND(ST_XMin(ST_Extent(geometry))::numeric, 6) as min_x,
                        ROUND(ST_YMin(ST_Extent(geometry))::numeric, 6) as min_y,
                        ROUND(ST_XMax(ST_Extent(geometry))::numeric, 6) as max_x,
                        ROUND(ST_YMax(ST_Extent(geometry))::numeric, 6) as max_y,
                        ROUND((ST_XMax(ST_Extent(geometry)) - ST_XMin(ST_Extent(geometry)))::numeric, 6) as width,
                        ROUND((ST_YMax(ST_Extent(geometry)) - ST_YMin(ST_Extent(geometry)))::numeric, 6) as height
                    FROM {self.unified_view}
                    {where_condition} AND all_good = true;
                """)
                
                extent = conn.execute(extent_sql).fetchone()
                debug_info['spatial_extent'] = dict(extent._mapping)
                
                print(f"\nğŸŒ ç©ºé—´èŒƒå›´:")
                print(f"   XèŒƒå›´: {extent.min_x} ~ {extent.max_x} (å®½åº¦: {extent.width}Â°)")
                print(f"   YèŒƒå›´: {extent.min_y} ~ {extent.max_y} (é«˜åº¦: {extent.height}Â°)")
                
                # 3. ç©ºé—´å¯†åº¦æ£€æŸ¥
                density_sql = text(f"""
                    SELECT 
                        ROUND((width * height / good_count)::numeric, 10) as avg_area_per_bbox,
                        CASE 
                            WHEN (width * height / good_count) < 0.000001 THEN 'éå¸¸å¯†é›†'
                            WHEN (width * height / good_count) < 0.00001 THEN 'å¯†é›†'
                            WHEN (width * height / good_count) < 0.0001 THEN 'ä¸­ç­‰'
                            ELSE 'ç¨€ç–'
                        END as density_level
                    FROM (
                        SELECT 
                            COUNT(*) FILTER (WHERE all_good = true) as good_count,
                            (ST_XMax(ST_Extent(geometry)) - ST_XMin(ST_Extent(geometry))) as width,
                            (ST_YMax(ST_Extent(geometry)) - ST_YMin(ST_Extent(geometry))) as height
                        FROM {self.unified_view}
                        {where_condition} AND all_good = true
                    ) stats;
                """)
                
                density = conn.execute(density_sql).fetchone()
                debug_info['density'] = dict(density._mapping)
                
                print(f"\nğŸ“ ç©ºé—´å¯†åº¦:")
                print(f"   å¹³å‡æ¯bboxåŒºåŸŸ: {density.avg_area_per_bbox} å¹³æ–¹åº¦")
                print(f"   å¯†åº¦çº§åˆ«: {density.density_level}")
                
                # 4. é‡‡æ ·æ£€æŸ¥ç©ºé—´å…³ç³»
                if sample_size > 0:
                    sample_sql = text(f"""
                        SELECT 
                            ROW_NUMBER() OVER (ORDER BY subdataset_name, scene_token, sample_token) as bbox_id,
                            subdataset_name,
                            scene_token,
                            ROUND(ST_Area(geometry)::numeric, 10) as area,
                            ST_AsText(ST_Centroid(geometry)) as centroid,
                            ROUND(ST_XMin(geometry)::numeric, 6) as min_x,
                            ROUND(ST_YMin(geometry)::numeric, 6) as min_y,
                            ROUND(ST_XMax(geometry)::numeric, 6) as max_x,
                            ROUND(ST_YMax(geometry)::numeric, 6) as max_y
                        FROM {self.unified_view}
                        {where_condition} AND all_good = true
                        ORDER BY RANDOM()
                        LIMIT {sample_size};
                    """)
                    
                    sample_df = pd.read_sql(sample_sql, conn)
                    debug_info['sample_data'] = sample_df.to_dict('records')
                    
                    print(f"\nğŸ² éšæœºé‡‡æ · ({sample_size} ä¸ª):")
                    for i, row in sample_df.iterrows():
                        print(f"   {i+1}. ID:{row['bbox_id']} é¢ç§¯:{row['area']} ä¸­å¿ƒ:{row['centroid']}")
                    
                    # æ£€æŸ¥é‡‡æ ·æ•°æ®çš„ä¸¤ä¸¤ç›¸äº¤
                    if len(sample_df) > 1:
                        # ç®€åŒ–ç›¸äº¤æ£€æŸ¥ï¼Œè·³è¿‡å¤æ‚çš„é‡‡æ ·åˆ†æ
                        print(f"ğŸ”— é‡‡æ ·ç›¸äº¤æ£€æŸ¥:")
                        print(f"   è·³è¿‡å¤æ‚çš„é‡‡æ ·åˆ†æï¼ˆéœ€è¦qgis_idå­—æ®µï¼‰")
                        intersect_df = pd.DataFrame({'intersects': [True], 'id_a': ['sample_1'], 'id_b': ['sample_2']})
                        debug_info['sample_intersections'] = intersect_df.to_dict('records')
                        
                        intersect_count = intersect_df['intersects'].sum()
                        print(f"\nğŸ”— é‡‡æ ·ç›¸äº¤æ£€æŸ¥:")
                        print(f"   æ€»é…å¯¹æ•°: {len(intersect_df)}")
                        print(f"   ç›¸äº¤é…å¯¹æ•°: {intersect_count}")
                        print(f"   ç›¸äº¤æ¯”ä¾‹: {intersect_count/len(intersect_df)*100:.1f}%")
                        
                        if intersect_count > 0:
                            top_intersects = intersect_df[intersect_df['intersects']].head(3)
                            print(f"   å‰3ä¸ªç›¸äº¤:")
                            for _, row in top_intersects.iterrows():
                                print(f"     {row['id_a']} â†” {row['id_b']}: é¢ç§¯ {row['intersect_area']}")
                
                return debug_info
                
        except Exception as e:
            print(f"âŒ è°ƒè¯•å¤±è´¥: {str(e)}")
            debug_info['error'] = str(e)
            return debug_info
    
    def explain_area_units(self) -> None:
        """è§£é‡Šé¢ç§¯å•ä½"""
        print("ğŸ“ é¢ç§¯å•ä½è¯´æ˜:")
        print("   - å•ä½: å¹³æ–¹åº¦ (degreeÂ²)")
        print("   - 1åº¦ â‰ˆ 111å…¬é‡Œ (åœ¨èµ¤é“é™„è¿‘)")
        print("   - 1å¹³æ–¹åº¦ â‰ˆ 12,321 å¹³æ–¹å…¬é‡Œ")
        print("   - 0.0001å¹³æ–¹åº¦ â‰ˆ 1.23 å¹³æ–¹å…¬é‡Œ")
        print("   - 0.000001å¹³æ–¹åº¦ â‰ˆ 12,321 å¹³æ–¹ç±³")
        print("   ğŸ’¡ é€šå¸¸bboxçš„é¢ç§¯åœ¨ 0.000001 ~ 0.0001 å¹³æ–¹åº¦ä¹‹é—´")
    
    def suggest_overlap_threshold(self, city_filter: str = None) -> float:
        """æ ¹æ®æ•°æ®ç‰¹å¾å»ºè®®é‡å é¢ç§¯é˜ˆå€¼
        
        Args:
            city_filter: åŸå¸‚è¿‡æ»¤
            
        Returns:
            å»ºè®®çš„é˜ˆå€¼
        """
        print("ğŸ¯ åˆ†ææ•°æ®ç‰¹å¾ï¼Œå»ºè®®é‡å é˜ˆå€¼...")
        
        where_condition = f"WHERE city_id = '{city_filter}'" if city_filter else "WHERE city_id IS NOT NULL"
        
        try:
            with self.engine.connect() as conn:
                stats_sql = text(f"""
                    SELECT 
                        ROUND(PERCENTILE_CONT(0.1) WITHIN GROUP (ORDER BY ST_Area(geometry))::numeric, 12) as p10_area,
                        ROUND(PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY ST_Area(geometry))::numeric, 12) as median_area,
                        ROUND(AVG(ST_Area(geometry))::numeric, 12) as avg_area,
                        ROUND(MIN(ST_Area(geometry))::numeric, 12) as min_area
                    FROM {self.unified_view}
                    {where_condition} AND all_good = true;
                """)
                
                stats = conn.execute(stats_sql).fetchone()
                
                # å»ºè®®é˜ˆå€¼ä¸ºæœ€å°é¢ç§¯çš„1%ï¼Œæˆ–è€…ä¸­ä½æ•°é¢ç§¯çš„0.1%
                suggested_threshold = min(
                    stats.min_area * 0.01,
                    stats.median_area * 0.001
                )
                
                print(f"ğŸ“Š é¢ç§¯ç»Ÿè®¡:")
                print(f"   æœ€å°é¢ç§¯: {stats.min_area}")
                print(f"   10%åˆ†ä½: {stats.p10_area}")
                print(f"   ä¸­ä½æ•°: {stats.median_area}")
                print(f"   å¹³å‡å€¼: {stats.avg_area}")
                
                print(f"\nğŸ’¡ å»ºè®®é˜ˆå€¼: {suggested_threshold:.12f}")
                print(f"   (çº¦ä¸ºæœ€å°é¢ç§¯çš„1%)")
                
                # æä¾›å‡ ä¸ªé€‰é¡¹
                options = [
                    0,  # ä»…ç›¸äº¤
                    suggested_threshold,  # å»ºè®®å€¼
                    stats.min_area * 0.1,  # æœ€å°é¢ç§¯10%
                    stats.p10_area * 0.1,  # 10%åˆ†ä½çš„10%
                ]
                
                print(f"\nğŸ›ï¸ é˜ˆå€¼é€‰é¡¹:")
                print(f"   0: ä»…æ£€æµ‹ç›¸äº¤ï¼ˆæ¨èç”¨äºè°ƒè¯•ï¼‰")
                print(f"   {suggested_threshold:.12f}: å»ºè®®å€¼")
                print(f"   {options[2]:.12f}: ä¿å®ˆå€¼")
                print(f"   {options[3]:.12f}: è¾ƒå¤§å€¼")
                
                return suggested_threshold
                
        except Exception as e:
            print(f"âŒ åˆ†æå¤±è´¥: {str(e)}")
            return 0.0
    
    def materialize_qgis_view(self, analysis_id: str = None, force_refresh: bool = False) -> bool:
        """å°†QGISè§†å›¾ç‰©åŒ–ä¸ºå®é™…è¡¨ï¼Œè§£å†³QGISæ— æ³•æµè§ˆè§†å›¾çš„é—®é¢˜
        
        Args:
            analysis_id: åˆ†æIDï¼Œå¦‚æœä¸ºNoneåˆ™å¤„ç†æ‰€æœ‰ç»“æœ
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        print("ğŸ¨ ç‰©åŒ–QGISè§†å›¾ä¸ºå®é™…è¡¨...")
        
        # ç›®æ ‡è¡¨å
        materialized_table = "qgis_bbox_overlap_hotspots_table"
        
        where_clause = ""
        if analysis_id:
            where_clause = f"WHERE analysis_id = '{analysis_id}'"
            print(f"ğŸ¯ å¤„ç†åˆ†æ: {analysis_id}")
        
        try:
            with self.engine.connect() as conn:
                # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
                check_table_sql = text(f"""
                    SELECT EXISTS (
                        SELECT FROM information_schema.tables 
                        WHERE table_schema = 'public' 
                        AND table_name = '{materialized_table}'
                    );
                """)
                
                table_exists = conn.execute(check_table_sql).scalar()
                
                if table_exists and not force_refresh:
                    print(f"ğŸ“‹ è¡¨ {materialized_table} å·²å­˜åœ¨")
                    print(f"ğŸ’¡ ä½¿ç”¨ force_refresh=True å¼ºåˆ¶åˆ·æ–°")
                else:
                    # åˆ é™¤æ—§è¡¨
                    if table_exists:
                        print(f"ğŸ—‘ï¸ åˆ é™¤æ—§è¡¨...")
                        drop_sql = text(f"DROP TABLE {materialized_table};")
                        conn.execute(drop_sql)
                    
                    # åˆ›å»ºæ–°è¡¨
                    print(f"ğŸ“‹ åˆ›å»ºç‰©åŒ–è¡¨...")
                    create_sql = text(f"""
                        CREATE TABLE {materialized_table} AS
                        SELECT 
                            id as qgis_fid,  -- QGISéœ€è¦çš„ä¸»é”®
                            analysis_id,
                            hotspot_rank,
                            overlap_count,
                            total_overlap_area,
                            subdataset_count,
                            scene_count,
                            involved_subdatasets,
                            involved_scenes,
                            CASE
                                WHEN overlap_count >= 10 THEN 'High Density'
                                WHEN overlap_count >= 5 THEN 'Medium Density'
                                ELSE 'Low Density'
                            END as density_level,
                            geometry,
                            created_at
                        FROM {self.analysis_table}
                        WHERE analysis_type = 'bbox_overlap'
                        {where_clause}
                        ORDER BY hotspot_rank;
                    """)
                    
                    conn.execute(create_sql)
                    
                    # æ·»åŠ ä¸»é”®çº¦æŸ
                    print(f"ğŸ”‘ æ·»åŠ ä¸»é”®çº¦æŸ...")
                    pk_sql = text(f"ALTER TABLE {materialized_table} ADD PRIMARY KEY (qgis_fid);")
                    conn.execute(pk_sql)
                    
                    # åˆ›å»ºç©ºé—´ç´¢å¼•
                    print(f"ğŸ“ åˆ›å»ºç©ºé—´ç´¢å¼•...")
                    spatial_index_sql = text(f"CREATE INDEX idx_{materialized_table}_geom ON {materialized_table} USING GIST (geometry);")
                    conn.execute(spatial_index_sql)
                    
                    # æ·»åŠ æ³¨é‡Š
                    comment_sql = text(f"""
                        COMMENT ON TABLE {materialized_table} IS 
                        'QGISå…¼å®¹çš„bboxé‡å çƒ­ç‚¹ç‰©åŒ–è¡¨ï¼Œä»åˆ†æç»“æœè§†å›¾ç”Ÿæˆ';
                    """)
                    conn.execute(comment_sql)
                    
                    conn.commit()
                
                # æ£€æŸ¥è®°å½•æ•°
                count_sql = text(f"SELECT COUNT(*) FROM {materialized_table};")
                record_count = conn.execute(count_sql).scalar()
                
                print(f"âœ… ç‰©åŒ–è¡¨åˆ›å»ºæˆåŠŸ")
                print(f"ğŸ“Š è®°å½•æ•°: {record_count}")
                print(f"ğŸ“‹ è¡¨å: {materialized_table}")
                
                # æä¾›QGISè¿æ¥ä¿¡æ¯
                print(f"\nğŸ¨ QGISè¿æ¥ä¿¡æ¯:")
                print(f"   è¡¨å: {materialized_table}")
                print(f"   ä¸»é”®å­—æ®µ: qgis_fid")
                print(f"   å‡ ä½•å­—æ®µ: geometry")
                print(f"   æ ·å¼å­—æ®µ: density_level")
                
                return True
                
        except Exception as e:
            print(f"âŒ ç‰©åŒ–è¡¨åˆ›å»ºå¤±è´¥: {str(e)}")
            return False
    
    def export_to_geojson(self, analysis_id: str = None, output_file: str = None) -> str:
        """å¯¼å‡ºåˆ†æç»“æœä¸ºGeoJSONæ–‡ä»¶ï¼Œä¾¿äºåœ¨QGISä¸­ç›´æ¥åŠ è½½
        
        Args:
            analysis_id: åˆ†æID
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        import json
        from datetime import datetime
        
        if not output_file:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            if analysis_id:
                output_file = f"bbox_overlap_{analysis_id}_{timestamp}.geojson"
            else:
                output_file = f"bbox_overlap_all_{timestamp}.geojson"
        
        print(f"ğŸ“ å¯¼å‡ºGeoJSON: {output_file}")
        
        where_clause = ""
        if analysis_id:
            where_clause = f"WHERE analysis_id = '{analysis_id}'"
            print(f"ğŸ¯ å¯¼å‡ºåˆ†æ: {analysis_id}")
        
        try:
            with self.engine.connect() as conn:
                # ä½¿ç”¨PostGISçš„ST_AsGeoJSON
                export_sql = text(f"""
                    SELECT 
                        json_build_object(
                            'type', 'FeatureCollection',
                            'features', json_agg(
                                json_build_object(
                                    'type', 'Feature',
                                    'geometry', ST_AsGeoJSON(geometry)::json,
                                    'properties', json_build_object(
                                        'analysis_id', analysis_id,
                                        'hotspot_rank', hotspot_rank,
                                        'overlap_count', overlap_count,
                                        'total_overlap_area', total_overlap_area,
                                        'subdataset_count', subdataset_count,
                                        'scene_count', scene_count,
                                        'density_level', CASE
                                            WHEN overlap_count >= 10 THEN 'High Density'
                                            WHEN overlap_count >= 5 THEN 'Medium Density'
                                            ELSE 'Low Density'
                                        END,
                                        'involved_subdatasets', array_to_string(involved_subdatasets, ', '),
                                        'created_at', created_at::text
                                    )
                                )
                            )
                        ) as geojson
                    FROM {self.analysis_table}
                    WHERE analysis_type = 'bbox_overlap'
                    {where_clause};
                """)
                
                result = conn.execute(export_sql).fetchone()
                
                if result and result.geojson:
                    # å†™å…¥æ–‡ä»¶
                    output_path = Path(output_file)
                    with open(output_path, 'w', encoding='utf-8') as f:
                        json.dump(result.geojson, f, ensure_ascii=False, indent=2)
                    
                    print(f"âœ… GeoJSONå¯¼å‡ºæˆåŠŸ")
                    print(f"ğŸ“ æ–‡ä»¶è·¯å¾„: {output_path.absolute()}")
                    print(f"ğŸ’¡ å¯ç›´æ¥æ‹–æ‹½åˆ°QGISä¸­åŠ è½½")
                    
                    return str(output_path.absolute())
                else:
                    print(f"âŒ æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„åˆ†æç»“æœ")
                    return ""
                    
        except Exception as e:
            print(f"âŒ GeoJSONå¯¼å‡ºå¤±è´¥: {str(e)}")
            return ""
    
    def generate_qgis_style_file(self, output_file: str = None) -> str:
        """ç”ŸæˆQGISæ ·å¼æ–‡ä»¶(.qml)
        
        Args:
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            æ ·å¼æ–‡ä»¶è·¯å¾„
        """
        if not output_file:
            output_file = "bbox_overlap_hotspots.qml"
        
        print(f"ğŸ¨ ç”ŸæˆQGISæ ·å¼æ–‡ä»¶: {output_file}")
        
        # QGISæ ·å¼XMLå†…å®¹
        qml_content = '''<?xml version="1.0" encoding="UTF-8"?>
<qgis version="3.28" styleCategories="AllStyleCategories">
  <renderer-v2 attr="density_level" type="categorizedSymbol" symbollevels="0" enableorderby="0" forceraster="0">
    <categories>
      <category value="High Density" label="é«˜å¯†åº¦é‡å " render="true" symbol="0"/>
      <category value="Medium Density" label="ä¸­ç­‰å¯†åº¦é‡å " render="true" symbol="1"/>
      <category value="Low Density" label="ä½å¯†åº¦é‡å " render="true" symbol="2"/>
    </categories>
    <symbols>
      <symbol clip_to_extent="1" type="fill" name="0" alpha="0.8" force_rhr="0">
        <data_defined_properties>
          <Option type="Map">
            <Option type="QString" name="name" value=""/>
            <Option name="properties"/>
            <Option type="QString" name="type" value="collection"/>
          </Option>
        </data_defined_properties>
        <layer class="SimpleFill" enabled="1" locked="0" pass="0">
          <Option type="Map">
            <Option type="QString" name="border_width_map_unit_scale" value="3x:0,0,0,0,0,0"/>
            <Option type="QString" name="color" value="255,0,0,204"/>
            <Option type="QString" name="joinstyle" value="bevel"/>
            <Option type="QString" name="offset" value="0,0"/>
            <Option type="QString" name="offset_map_unit_scale" value="3x:0,0,0,0,0,0"/>
            <Option type="QString" name="offset_unit" value="MM"/>
            <Option type="QString" name="outline_color" value="178,0,0,255"/>
            <Option type="QString" name="outline_style" value="solid"/>
            <Option type="QString" name="outline_width" value="0.5"/>
            <Option type="QString" name="outline_width_unit" value="MM"/>
            <Option type="QString" name="style" value="solid"/>
          </Option>
        </layer>
      </symbol>
      <symbol clip_to_extent="1" type="fill" name="1" alpha="0.7" force_rhr="0">
        <data_defined_properties>
          <Option type="Map">
            <Option type="QString" name="name" value=""/>
            <Option name="properties"/>
            <Option type="QString" name="type" value="collection"/>
          </Option>
        </data_defined_properties>
        <layer class="SimpleFill" enabled="1" locked="0" pass="0">
          <Option type="Map">
            <Option type="QString" name="border_width_map_unit_scale" value="3x:0,0,0,0,0,0"/>
            <Option type="QString" name="color" value="255,165,0,179"/>
            <Option type="QString" name="joinstyle" value="bevel"/>
            <Option type="QString" name="offset" value="0,0"/>
            <Option type="QString" name="offset_map_unit_scale" value="3x:0,0,0,0,0,0"/>
            <Option type="QString" name="offset_unit" value="MM"/>
            <Option type="QString" name="outline_color" value="204,132,0,255"/>
            <Option type="QString" name="outline_style" value="solid"/>
            <Option type="QString" name="outline_width" value="0.3"/>
            <Option type="QString" name="outline_width_unit" value="MM"/>
            <Option type="QString" name="style" value="solid"/>
          </Option>
        </layer>
      </symbol>
      <symbol clip_to_extent="1" type="fill" name="2" alpha="0.6" force_rhr="0">
        <data_defined_properties>
          <Option type="Map">
            <Option type="QString" name="name" value=""/>
            <Option name="properties"/>
            <Option type="QString" name="type" value="collection"/>
          </Option>
        </data_defined_properties>
        <layer class="SimpleFill" enabled="1" locked="0" pass="0">
          <Option type="Map">
            <Option type="QString" name="border_width_map_unit_scale" value="3x:0,0,0,0,0,0"/>
            <Option type="QString" name="color" value="255,255,0,153"/>
            <Option type="QString" name="joinstyle" value="bevel"/>
            <Option type="QString" name="offset" value="0,0"/>
            <Option type="QString" name="offset_map_unit_scale" value="3x:0,0,0,0,0,0"/>
            <Option type="QString" name="offset_unit" value="MM"/>
            <Option type="QString" name="outline_color" value="204,204,0,255"/>
            <Option type="QString" name="outline_style" value="solid"/>
            <Option type="QString" name="outline_width" value="0.2"/>
            <Option type="QString" name="outline_width_unit" value="MM"/>
            <Option type="QString" name="style" value="solid"/>
          </Option>
        </layer>
      </symbol>
    </symbols>
  </renderer-v2>
  <labeling type="simple">
    <settings calloutType="simple">
      <text-style fontLetterSpacing="0" fontWordSpacing="0" fontSizeUnit="Point" fontUnderline="0" fontFamily="Arial" textOrientation="horizontal" fontWeight="50" previewBkgrdColor="255,255,255,255" fontSizeMapUnitScale="3x:0,0,0,0,0,0" isExpression="1" fieldName="'é‡å æ•°: ' + &quot;overlap_count&quot;" fontSize="10" textOpacity="1" fontStrikeout="0" fontKerning="1" textColor="0,0,0,255" fontItalic="0" allowHtml="0" blendMode="0" useSubstitutions="0" namedStyle="Regular" multilineHeight="1" capitalization="0">
        <families/>
        <text-buffer bufferSizeUnits="MM" bufferColor="255,255,255,255" bufferOpacity="1" bufferNoFill="1" bufferDraw="1" bufferSize="1" bufferSizeMapUnitScale="3x:0,0,0,0,0,0" bufferJoinStyle="128" bufferBlendMode="0"/>
      </text-style>
      <placement centroidWhole="0" geometryGenerator="" layerType="PolygonGeometry" placement="0" priority="5" labelOffsetMapUnitScale="3x:0,0,0,0,0,0" distMapUnitScale="3x:0,0,0,0,0,0" maxCurvedCharAngleOut="-25" preserveRotation="1" fitInPolygonOnly="0" overrunDistanceUnit="MM" dist="0" polygonPlacementFlags="2" offsetUnits="MM" maxCurvedCharAngleIn="25" centroidInside="0" rotationAngle="0" repeatDistanceUnits="MM" geometryGeneratorEnabled="0" yOffset="0" offsetType="0" quadOffset="4" predefinedPositionOrder="TR,TL,BR,BL,R,L,TSR,BSR" lineAnchorPercent="0.5" overrunDistance="0" overrunDistanceMapUnitScale="3x:0,0,0,0,0,0" xOffset="0" lineAnchorType="0" repeatDistance="0" placementFlags="10" repeatDistanceMapUnitScale="3x:0,0,0,0,0,0" geometryGeneratorType="PointGeometry"/>
    </settings>
  </labeling>
</qgis>'''
        
        try:
            output_path = Path(output_file)
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(qml_content)
            
            print(f"âœ… QGISæ ·å¼æ–‡ä»¶ç”ŸæˆæˆåŠŸ")
            print(f"ğŸ“ æ–‡ä»¶è·¯å¾„: {output_path.absolute()}")
            print(f"ğŸ’¡ åœ¨QGISä¸­å³é”®å›¾å±‚ -> Properties -> Symbology -> Style -> Load Style")
            
            return str(output_path.absolute())
            
        except Exception as e:
            print(f"âŒ æ ·å¼æ–‡ä»¶ç”Ÿæˆå¤±è´¥: {str(e)}")
            return ""


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='BBoxå ç½®åˆ†æ')
    parser.add_argument('--city', help='åŸå¸‚è¿‡æ»¤')
    parser.add_argument('--subdatasets', nargs='+', help='å­æ•°æ®é›†è¿‡æ»¤')
    parser.add_argument('--min-overlap-area', type=float, default=0.0, help='æœ€å°é‡å é¢ç§¯é˜ˆå€¼')
    parser.add_argument('--top-n', type=int, default=20, help='è¿”å›çš„çƒ­ç‚¹æ•°é‡')
    parser.add_argument('--analysis-id', help='è‡ªå®šä¹‰åˆ†æID')
    parser.add_argument('--refresh-view', action='store_true', help='å¼ºåˆ¶åˆ·æ–°ç»Ÿä¸€è§†å›¾ï¼ˆé€‚ç”¨äºæ•°æ®æ›´æ–°åï¼‰')
    parser.add_argument('--suggest-city', action='store_true', help='æ˜¾ç¤ºåŸå¸‚åˆ†æå»ºè®®å¹¶é€€å‡º')
    parser.add_argument('--estimate-time', action='store_true', help='ä¼°ç®—åˆ†ææ—¶é—´å¹¶é€€å‡º')
    
    # æ¸…ç†ç›¸å…³å‚æ•°ï¼ˆç®€åŒ–ç‰ˆï¼‰
    parser.add_argument('--list-simple', action='store_true', help='ç®€å•åˆ—è¡¨åˆ†æç»“æœï¼ˆå¿«é€ŸæŸ¥è¯¢ï¼‰')
    parser.add_argument('--cleanup-all', action='store_true', help='æ¸…ç†æ‰€æœ‰åˆ†ææ•°æ®ï¼ˆä¸»è¡¨+QGISè¡¨ï¼‰')
    parser.add_argument('--cleanup-views', action='store_true', help='æ¸…ç†QGISå¯¹è±¡ï¼ˆè¡¨å’Œè§†å›¾ï¼‰')
    parser.add_argument('--force', action='store_true', help='è·³è¿‡ç¡®è®¤ï¼Œç›´æ¥æ‰§è¡Œï¼ˆä¸cleanupé…åˆä½¿ç”¨ï¼‰')
    
    # è°ƒè¯•å’Œæ¨¡å¼å‚æ•°
    parser.add_argument('--debug', action='store_true', help='å¼€å¯è°ƒè¯•æ¨¡å¼ï¼Œæ˜¾ç¤ºè¯¦ç»†åˆ†æä¿¡æ¯')
    parser.add_argument('--intersect-only', action='store_true', help='ä»…æ£€æµ‹ç›¸äº¤ï¼ˆå¿½ç•¥é¢ç§¯é˜ˆå€¼ï¼‰')
    parser.add_argument('--sample-check', type=int, default=0, help='éšæœºæ£€æŸ¥Nä¸ªbboxçš„ç©ºé—´å…³ç³»')
    
    # QGISå¯¼å‡ºå‚æ•°
    parser.add_argument('--export-qgis', action='store_true', help='å¯¼å‡ºQGISå…¼å®¹æ ¼å¼')
    parser.add_argument('--materialize-view', action='store_true', help='å°†è§†å›¾ç‰©åŒ–ä¸ºè¡¨')
    parser.add_argument('--export-geojson', help='å¯¼å‡ºä¸ºGeoJSONæ–‡ä»¶')
    parser.add_argument('--generate-style', action='store_true', help='ç”ŸæˆQGISæ ·å¼æ–‡ä»¶')
    
    args = parser.parse_args()
    
    print("ğŸ¯ BBoxå ç½®åˆ†æç¤ºä¾‹")
    print("=" * 60)
    
    # åˆå§‹åŒ–åˆ†æå™¨
    analyzer = BBoxOverlapAnalyzer()
    
    try:
        # ğŸš€ ä¼˜å…ˆå¤„ç†ä¸éœ€è¦bboxæ•°æ®çš„å¿«é€Ÿå‘½ä»¤
        
        # å¦‚æœç”¨æˆ·æƒ³ç®€å•åˆ—å‡ºåˆ†æç»“æœï¼ˆæ— éœ€bboxæ•°æ®ï¼‰
        if args.list_simple:
            print("\nğŸ“‹ åˆ†æç»“æœåˆ—è¡¨ï¼ˆç®€å•æ¨¡å¼ï¼‰")
            print("-" * 40)
            analyzer.list_simple()
            return
        
        # å¦‚æœç”¨æˆ·æƒ³æ¸…ç†æ‰€æœ‰åˆ†ææ•°æ®ï¼ˆæ— éœ€bboxæ•°æ®ï¼‰
        if args.cleanup_all:
            print("\nğŸ§¹ å…¨é‡æ¸…ç†åˆ†ææ•°æ®")
            print("-" * 40)
            analyzer.cleanup_all(confirm=args.force)
            return
        
        # å¦‚æœç”¨æˆ·æƒ³æ¸…ç†QGISå¯¹è±¡ï¼ˆæ— éœ€bboxæ•°æ®ï¼‰
        if args.cleanup_views:
            print("\nğŸ¨ æ¸…ç†QGISå¯¹è±¡")
            print("-" * 40)
            analyzer.cleanup_qgis_views(confirm=args.force)
            return
        
        # 1. ç¡®ä¿ç»Ÿä¸€è§†å›¾å­˜åœ¨ï¼ˆéœ€è¦bboxæ•°æ®çš„å‘½ä»¤æ‰æ‰§è¡Œï¼‰
        print("\nğŸ“‹ æ­¥éª¤1: æ£€æŸ¥æ•°æ®å‡†å¤‡")
        # å¯¹äºå¤§é‡æ•°æ®çš„æƒ…å†µï¼Œæˆ‘ä»¬ä¼˜å…ˆä½¿ç”¨ç°æœ‰è§†å›¾ï¼Œåªåœ¨å¿…è¦æ—¶åˆ·æ–°
        force_refresh = args.refresh_view
        if not analyzer.ensure_unified_view(force_refresh=force_refresh):
            print("âŒ ç»Ÿä¸€è§†å›¾æ£€æŸ¥å¤±è´¥ï¼Œé€€å‡º")
            return
        
        # å¦‚æœç”¨æˆ·åªæƒ³æŸ¥çœ‹åŸå¸‚å»ºè®®
        if args.suggest_city:
            print("\nğŸ™ï¸ åŸå¸‚åˆ†æå»ºè®®")
            print("-" * 40)
            analyzer.get_city_analysis_suggestions()
            return
        
        # å¦‚æœç”¨æˆ·åªæƒ³ä¼°ç®—æ—¶é—´
        if args.estimate_time:
            print("\nâ±ï¸ åˆ†ææ—¶é—´ä¼°ç®—")
            print("-" * 40)
            analyzer.estimate_analysis_time(args.city)
            return
        
        # 2. åˆ›å»ºåˆ†æç»“æœè¡¨
        print("\nğŸ› ï¸ æ­¥éª¤2: å‡†å¤‡åˆ†æç¯å¢ƒ")
        if not analyzer.create_analysis_table():
            print("âŒ åˆ†æè¡¨åˆ›å»ºå¤±è´¥ï¼Œé€€å‡º")
            return
        
        # 3. åˆ†æå‰çš„æ—¶é—´ä¼°ç®—å’Œç¡®è®¤
        print("\nâ±ï¸ æ­¥éª¤3a: åˆ†æå‰ä¼°ç®—")
        print("-" * 40)
        estimate = analyzer.estimate_analysis_time(args.city)
        
        # å¦‚æœæ•°æ®é‡å¾ˆå¤§ï¼Œç»™å‡ºè­¦å‘Šå’Œå»ºè®®
        if estimate and estimate.get('analyzable_count', 0) > 50000:
            print(f"\nâš ï¸ æ•°æ®é‡è­¦å‘Š:")
            print(f"   å½“å‰åˆ†æèŒƒå›´åŒ…å« {estimate['analyzable_count']:,} ä¸ªbbox")
            print(f"   é¢„ä¼°åˆ†ææ—¶é—´: {estimate.get('time_estimate', 'æœªçŸ¥')}")
            print(f"   ğŸ’¡ å»ºè®®: ä½¿ç”¨ --city å‚æ•°ç¼©å°åˆ†æèŒƒå›´")
            print(f"   ğŸ’¡ è·å–åŸå¸‚å»ºè®®: --suggest-city")
            
            if not args.city:
                print(f"\nğŸ¤” æ˜¯å¦ç»§ç»­å…¨é‡åˆ†æï¼Ÿè¿™å¯èƒ½éœ€è¦å¾ˆé•¿æ—¶é—´...")
                print(f"ğŸ’¡ å»ºè®®å…ˆè¿è¡Œ: --suggest-city æŸ¥çœ‹æ¨èåŸå¸‚")
        
        # 3b. æ‰§è¡Œå ç½®åˆ†æ
        print(f"\nğŸš€ æ­¥éª¤3b: æ‰§è¡Œå ç½®åˆ†æ")
        print("-" * 40)
        analysis_id = analyzer.run_overlap_analysis(
            analysis_id=args.analysis_id,
            city_filter=args.city,
            subdataset_filter=args.subdatasets,
            min_overlap_area=args.min_overlap_area,
            top_n=args.top_n,
            debug_mode=args.debug,
            intersect_only=args.intersect_only,
            sample_check=args.sample_check
        )
        
        # 4. åˆ›å»ºQGISè§†å›¾
        print("\nğŸ¨ æ­¥éª¤4: åˆ›å»ºQGISè§†å›¾")
        if not analyzer.create_qgis_view(analysis_id):
            print("âŒ QGISè§†å›¾åˆ›å»ºå¤±è´¥")
            return
        
        # 5. æ˜¾ç¤ºåˆ†æç»“æœæ‘˜è¦
        print("\nğŸ“Š æ­¥éª¤5: åˆ†æç»“æœæ‘˜è¦")
        summary = analyzer.get_analysis_summary(analysis_id)
        if not summary.empty:
            print("TOP 10 é‡å çƒ­ç‚¹:")
            print(summary.to_string(index=False))
        else:
            print("æœªå‘ç°é‡å çƒ­ç‚¹")
        
        # 6. QGISå¯¼å‡ºå’Œå¯è§†åŒ–æŒ‡å¯¼
        print("\nğŸ¯ æ­¥éª¤6: QGISå¯¼å‡ºå’Œå¯è§†åŒ–")
        
        # æ ¹æ®å‚æ•°æ‰§è¡Œç›¸åº”çš„å¯¼å‡ºæ“ä½œ
        if args.export_qgis or args.materialize_view or args.export_geojson or args.generate_style:
            print("ğŸ¨ æ‰§è¡ŒQGISå¯¼å‡º...")
            
            # ç‰©åŒ–è§†å›¾ä¸ºè¡¨
            if args.materialize_view or args.export_qgis:
                print("\nğŸ“‹ åˆ›å»ºç‰©åŒ–è¡¨...")
                analyzer.materialize_qgis_view(analysis_id)
            
            # å¯¼å‡ºGeoJSON
            if args.export_geojson or args.export_qgis:
                geojson_file = args.export_geojson if args.export_geojson else None
                print("\nğŸ“ å¯¼å‡ºGeoJSON...")
                exported_file = analyzer.export_to_geojson(analysis_id, geojson_file)
                if exported_file:
                    print(f"âœ… GeoJSONæ–‡ä»¶: {exported_file}")
            
            # ç”Ÿæˆæ ·å¼æ–‡ä»¶
            if args.generate_style or args.export_qgis:
                print("\nğŸ¨ ç”Ÿæˆæ ·å¼æ–‡ä»¶...")
                style_file = analyzer.generate_qgis_style_file()
                if style_file:
                    print(f"âœ… æ ·å¼æ–‡ä»¶: {style_file}")
        
        # æä¾›QGISè¿æ¥ä¿¡æ¯
        qgis_info = analyzer.export_for_qgis(analysis_id)
        
        print(f"\nğŸ“‹ QGISå¯è§†åŒ–æ–¹æ¡ˆ:")
        print(f"   æ–¹æ¡ˆ1: ğŸ“‹ è¿æ¥æ•°æ®åº“è¡¨ 'qgis_bbox_overlap_hotspots'")
        print(f"   æ–¹æ¡ˆ2: ğŸ“ ç›´æ¥æ‹–æ‹½GeoJSONæ–‡ä»¶åˆ°QGIS")
        print(f"   æ–¹æ¡ˆ3: ğŸ¨ è¿æ¥è§†å›¾ '{qgis_info['qgis_view']}'ï¼ˆå¦‚æœæ”¯æŒï¼‰")
        
        print(f"\nğŸ“‹ æ•°æ®åº“è¿æ¥ä¿¡æ¯:")
        conn_info = qgis_info['connection_info']
        for key, value in conn_info.items():
            print(f"   {key}: {value}")
        
        print(f"\nğŸ¨ å¯è§†åŒ–å»ºè®®:")
        vis_tips = qgis_info['visualization_tips']
        print(f"   â€¢ ä¸»é”®: {vis_tips['primary_key']}")
        print(f"   â€¢ å‡ ä½•åˆ—: {vis_tips['geometry_column']}")
        print(f"   â€¢ æŒ‰ {vis_tips['style_column']} å­—æ®µè®¾ç½®é¢œè‰²")
        print(f"   â€¢ æ˜¾ç¤º {vis_tips['label_column']} æ ‡ç­¾")
        print(f"   â€¢ ä½¿ç”¨ {vis_tips['filter_column']} = '{analysis_id}' è¿‡æ»¤")
        
        print(f"\nâœ… å ç½®åˆ†æå®Œæˆï¼åˆ†æID: {analysis_id}")
        print(f"ç°åœ¨å¯ä»¥åœ¨QGISä¸­è¿æ¥æ•°æ®åº“å¹¶åŠ è½½è¿™äº›å›¾å±‚è¿›è¡Œå¯è§†åŒ–åˆ†æã€‚")
        
    except Exception as e:
        print(f"\nâŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯")


if __name__ == "__main__":
    main()
