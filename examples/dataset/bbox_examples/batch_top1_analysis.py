#!/usr/bin/env python3
"""
æ‰¹é‡åŸå¸‚çƒ­ç‚¹åˆ†æè„šæœ¬
===============================

éå†æ‰€æœ‰åŸå¸‚ï¼Œæå–æ¯ä¸ªåŸå¸‚çš„topçƒ­ç‚¹åŒºåŸŸï¼ˆæ”¯æŒå›ºå®šæ•°é‡æˆ–ç™¾åˆ†æ¯”ï¼‰

ä½¿ç”¨æ–¹æ³•ï¼š
    # ä½¿ç”¨ç™¾åˆ†æ¯”ï¼ˆé»˜è®¤å‰1%ï¼‰
    python examples/dataset/bbox_examples/batch_top1_analysis.py --top-percent 1
    
    # ä½¿ç”¨å›ºå®šæ•°é‡
    python examples/dataset/bbox_examples/batch_top1_analysis.py --top-n 1
    
    # è‡ªå®šä¹‰è¾“å‡ºè¡¨
    python examples/dataset/bbox_examples/batch_top1_analysis.py --top-percent 5 --output-table city_top5pct_hotspots
"""

import sys
from pathlib import Path
import argparse
from datetime import datetime
import subprocess
import time

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

try:
    from spdatalab.dataset.bbox import LOCAL_DSN
except ImportError:
    sys.path.insert(0, str(project_root / "src"))
    from spdatalab.dataset.bbox import LOCAL_DSN

from sqlalchemy import create_engine, text
import pandas as pd

def get_all_cities(conn):
    """è·å–æ‰€æœ‰åŸå¸‚"""
    
    print(f"ğŸ” æŸ¥æ‰¾æ‰€æœ‰åŸå¸‚...")
    
    cities_sql = text("""
        SELECT 
            city_id,
            COUNT(*) as bbox_count,
            COUNT(*) FILTER (WHERE all_good = true) as good_bbox_count
        FROM clips_bbox_unified
        WHERE city_id IS NOT NULL 
        GROUP BY city_id
        ORDER BY COUNT(*) DESC;
    """)
    
    cities_df = pd.read_sql(cities_sql, conn)
    
    print(f"ğŸ“Š æ‰¾åˆ° {len(cities_df)} ä¸ªåŸå¸‚:")
    print(cities_df.head(10).to_string(index=False))
    if len(cities_df) > 10:
        print(f"... è¿˜æœ‰ {len(cities_df) - 10} ä¸ªåŸå¸‚")
    
    return cities_df['city_id'].tolist()

def analyze_city_with_existing_script(city_id, top_n=None, top_percent=None):
    """ä½¿ç”¨ç°æœ‰è„šæœ¬åˆ†æå•ä¸ªåŸå¸‚çš„çƒ­ç‚¹
    
    Args:
        city_id: åŸå¸‚ID
        top_n: å›ºå®šæ•°é‡ï¼ˆä¸top_percentäº’æ–¥ï¼‰
        top_percent: ç™¾åˆ†æ¯”ï¼ˆä¸top_näº’æ–¥ï¼‰
    """
    
    print(f"\nğŸ¯ åˆ†æåŸå¸‚: {city_id}")
    
    try:
        # è°ƒç”¨ç°æœ‰çš„run_overlap_analysis.pyè„šæœ¬
        cmd = [
            'python', 
            'run_overlap_analysis.py',
            '--city', city_id,
            '--grid-size', '0.002',
            '--density-threshold', '5'
        ]
        
        # æ·»åŠ top-næˆ–top-percentå‚æ•°
        if top_n is not None:
            cmd.extend(['--top-n', str(top_n)])
        elif top_percent is not None:
            cmd.extend(['--top-percent', str(top_percent)])
        else:
            # é»˜è®¤ä½¿ç”¨1%
            cmd.extend(['--top-percent', '1'])
        
        print(f"   æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
        
        # åœ¨bbox_examplesç›®å½•ä¸‹æ‰§è¡Œ
        result = subprocess.run(
            cmd,
            cwd=Path(__file__).parent,
            capture_output=True,
            text=True,
            timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
        )
        
        if result.returncode == 0:
            print(f"   âœ… åŸå¸‚ {city_id} åˆ†ææˆåŠŸ")
            return True
        else:
            print(f"   âŒ åŸå¸‚ {city_id} åˆ†æå¤±è´¥:")
            print(f"   é”™è¯¯è¾“å‡º: {result.stderr}")
            return False
            
    except subprocess.TimeoutExpired:
        print(f"   â° åŸå¸‚ {city_id} åˆ†æè¶…æ—¶ï¼ˆ>5åˆ†é’Ÿï¼‰")
        return False
    except Exception as e:
        print(f"   âŒ åŸå¸‚ {city_id} åˆ†æå¼‚å¸¸: {str(e)}")
        return False

def create_top1_summary_table(conn, table_name):
    """åˆ›å»ºtop1æ±‡æ€»è¡¨"""
    
    print(f"ğŸ“‹ åˆ›å»ºæ±‡æ€»è¡¨: {table_name}")
    
    create_sql = text(f"""
        CREATE TABLE IF NOT EXISTS {table_name} (
            id SERIAL PRIMARY KEY,
            city_id VARCHAR(50) NOT NULL,
            analysis_id VARCHAR(100),
            bbox_count INTEGER,
            subdataset_count INTEGER,
            scene_count INTEGER,
            total_overlap_area NUMERIC,
            grid_coords TEXT,
            analysis_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
        
        -- æ·»åŠ å‡ ä½•åˆ—
        DO $$
        BEGIN
            IF NOT EXISTS (
                SELECT 1 FROM information_schema.columns 
                WHERE table_name = '{table_name}' 
                AND column_name = 'geometry'
            ) THEN
                PERFORM AddGeometryColumn('public', '{table_name}', 'geometry', 4326, 'GEOMETRY', 2);
            END IF;
        END $$;
        
        -- åˆ›å»ºç´¢å¼•
        CREATE INDEX IF NOT EXISTS idx_{table_name}_city_id ON {table_name} (city_id);
        CREATE INDEX IF NOT EXISTS idx_{table_name}_bbox_count ON {table_name} (bbox_count);
        CREATE INDEX IF NOT EXISTS idx_{table_name}_geom ON {table_name} USING GIST (geometry);
    """)
    
    conn.execute(create_sql)
    conn.commit()
    print(f"âœ… è¡¨ {table_name} åˆ›å»ºæˆåŠŸ")

def extract_single_city_top1(conn, table_name, city_id):
    """ä»bbox_overlap_analysis_resultsä¸­æå–å•ä¸ªåŸå¸‚çš„top1ç»“æœ"""
    
    # å…ˆåˆ é™¤è¯¥åŸå¸‚ä»Šå¤©çš„æ—§æ•°æ®
    cleanup_sql = text(f"""
        DELETE FROM {table_name} 
        WHERE city_id = :city_id 
        AND analysis_time::date = CURRENT_DATE;
    """)
    conn.execute(cleanup_sql, {'city_id': city_id})
    
    # æå–è¯¥åŸå¸‚çš„top1çƒ­ç‚¹
    extract_sql = text(f"""
        INSERT INTO {table_name} 
        (city_id, analysis_id, bbox_count, subdataset_count, scene_count, 
         total_overlap_area, geometry, grid_coords)
        SELECT 
            (analysis_params::json->>'city_filter') as city_id,
            analysis_id,
            overlap_count as bbox_count,
            subdataset_count,
            scene_count,
            total_overlap_area,
            geometry,
            (analysis_params::json->>'grid_coords') as grid_coords
        FROM bbox_overlap_analysis_results 
        WHERE analysis_id = (
            SELECT analysis_id
            FROM bbox_overlap_analysis_results
            WHERE analysis_params::json->>'city_filter' = :city_id
            AND analysis_time::date = CURRENT_DATE
            ORDER BY analysis_time DESC
            LIMIT 1
        );
    """)
    
    result = conn.execute(extract_sql, {'city_id': city_id})
    conn.commit()
    
    return result.rowcount

def extract_top1_results(conn, table_name):
    """ä»bbox_overlap_analysis_resultsä¸­æå–æ‰€æœ‰åŸå¸‚çš„top1ç»“æœ"""
    
    print(f"ğŸ“Š æå–top1ç»“æœåˆ° {table_name}...")
    
    # å…ˆæ¸…ç©ºä»Šå¤©çš„æ•°æ®
    cleanup_sql = text(f"""
        DELETE FROM {table_name} 
        WHERE analysis_time::date = CURRENT_DATE;
    """)
    conn.execute(cleanup_sql)
    
    # æå–æ¯ä¸ªåŸå¸‚çš„top1çƒ­ç‚¹ï¼ˆhotspot_rank = 1ï¼‰
    extract_sql = text(f"""
        INSERT INTO {table_name} 
        (city_id, analysis_id, bbox_count, subdataset_count, scene_count, 
         total_overlap_area, geometry, grid_coords)
        SELECT 
            -- ä»analysis_params JSONä¸­æå–city_id
            (analysis_params::json->>'city_filter') as city_id,
            analysis_id,
            overlap_count as bbox_count,
            subdataset_count,
            scene_count,
            total_overlap_area,
            geometry,
            (analysis_params::json->>'grid_coords') as grid_coords
        FROM bbox_overlap_analysis_results 
        WHERE hotspot_rank = 1  -- åªè¦æ¯ä¸ªåˆ†æçš„top1
        AND analysis_time::date = CURRENT_DATE  -- åªè¦ä»Šå¤©çš„åˆ†æ
        AND analysis_params::json->>'city_filter' IS NOT NULL;
    """)
    
    result = conn.execute(extract_sql)
    conn.commit()
    
    extracted_count = result.rowcount
    print(f"âœ… æå–äº† {extracted_count} ä¸ªåŸå¸‚çš„top1çƒ­ç‚¹")
    
    return extracted_count

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ‰¹é‡åŸå¸‚çƒ­ç‚¹åˆ†æ')
    parser.add_argument('--output-table', default='city_hotspots',
                       help='è¾“å‡ºæ±‡æ€»è¡¨å (é»˜è®¤: city_hotspots)')
    parser.add_argument('--cities', nargs='+', 
                       help='æŒ‡å®šåˆ†æçš„åŸå¸‚åˆ—è¡¨ï¼Œå¦‚: --cities A263 B001')
    parser.add_argument('--max-cities', type=int, default=None,
                       help='æœ€å¤šåˆ†æåŸå¸‚æ•°é‡ (é»˜è®¤: æ— é™åˆ¶)')
    
    # ğŸ¯ æ”¯æŒå›ºå®šæ•°é‡æˆ–ç™¾åˆ†æ¯”ä¸¤ç§æ–¹å¼
    result_group = parser.add_mutually_exclusive_group()
    result_group.add_argument('--top-n', type=int, help='è¿”å›çš„çƒ­ç‚¹æ•°é‡ï¼ˆä¸--top-percentäº’æ–¥ï¼‰')
    result_group.add_argument('--top-percent', type=float, default=1.0, 
                            help='è¿”å›æœ€å¯†é›†çš„å‰X%%ç½‘æ ¼ï¼ˆé»˜è®¤1%%ï¼‰')
    
    args = parser.parse_args()
    
    print("ğŸš€ æ‰¹é‡åŸå¸‚çƒ­ç‚¹åˆ†æ")
    print("=" * 50)
    print(f"è¾“å‡ºè¡¨: {args.output_table}")
    if args.top_n is not None:
        print(f"åˆ†æå‚æ•°: è¿”å›å‰ {args.top_n} ä¸ªæœ€å¯†é›†ç½‘æ ¼")
    else:
        print(f"åˆ†æå‚æ•°: è¿”å›å‰ {args.top_percent}% æœ€å¯†é›†ç½‘æ ¼")
    if args.max_cities:
        print(f"æœ€å¤šåˆ†æ: {args.max_cities} ä¸ªåŸå¸‚")
    else:
        print(f"åˆ†ææ‰€æœ‰åŸå¸‚ï¼ˆæ— é™åˆ¶ï¼‰")
    
    engine = create_engine(LOCAL_DSN, future=True)
    
    try:
        with engine.connect() as conn:
            
            # åˆ›å»ºæ±‡æ€»è¡¨
            create_top1_summary_table(conn, args.output_table)
            
            # è·å–åŸå¸‚åˆ—è¡¨
            if args.cities:
                print(f"\nğŸ¯ æŒ‡å®šåˆ†æåŸå¸‚: {args.cities}")
                cities_to_analyze = args.cities
            else:
                all_cities = get_all_cities(conn)
                if args.max_cities:
                    cities_to_analyze = all_cities[:args.max_cities]
                else:
                    cities_to_analyze = all_cities  # åˆ†ææ‰€æœ‰åŸå¸‚
            
            if not cities_to_analyze:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°åŸå¸‚")
                return 1
            
            # æ‰¹é‡åˆ†æ
            print(f"\nğŸ”„ å¼€å§‹æ‰¹é‡åˆ†æ {len(cities_to_analyze)} ä¸ªåŸå¸‚...")
            if args.top_n is not None:
                print(f"æ¯ä¸ªåŸå¸‚ä½¿ç”¨ run_overlap_analysis.py --top-n {args.top_n} è¿›è¡Œåˆ†æ")
            else:
                print(f"æ¯ä¸ªåŸå¸‚ä½¿ç”¨ run_overlap_analysis.py --top-percent {args.top_percent} è¿›è¡Œåˆ†æ")
            
            successful_cities = []
            failed_cities = []
            
            start_time = time.time()
            
            for i, city_id in enumerate(cities_to_analyze, 1):
                print(f"\n[{i}/{len(cities_to_analyze)}] å¤„ç†åŸå¸‚: {city_id}")
                
                success = analyze_city_with_existing_script(city_id, top_n=args.top_n, top_percent=args.top_percent)
                
                if success:
                    successful_cities.append(city_id)
                    # ç«‹å³æå–è¯¥åŸå¸‚çš„çƒ­ç‚¹ç»“æœ
                    try:
                        extract_single_city_top1(conn, args.output_table, city_id)
                        print(f"   ğŸ“Š å·²æå– {city_id} çš„çƒ­ç‚¹ç»“æœåˆ°æ±‡æ€»è¡¨")
                    except Exception as e:
                        print(f"   âš ï¸ æå– {city_id} ç»“æœå¤±è´¥: {str(e)}")
                else:
                    failed_cities.append(city_id)
                
                # æ¯10ä¸ªåŸå¸‚ä¼‘æ¯ä¸€ä¸‹
                if i % 10 == 0:
                    print(f"   ğŸ’¤ å·²å¤„ç† {i} ä¸ªåŸå¸‚ï¼Œä¼‘æ¯2ç§’...")
                    time.sleep(2)
            
            # æ£€æŸ¥æ±‡æ€»è¡¨ä¸­çš„ç»“æœæ•°é‡
            count_sql = text(f"""
                SELECT COUNT(*) as count 
                FROM {args.output_table} 
                WHERE analysis_time::date = CURRENT_DATE;
            """)
            result = conn.execute(count_sql).fetchone()
            extracted_count = result.count if result else 0
            
            print(f"\nğŸ“Š æ±‡æ€»è¡¨ä¸­å…±æœ‰ {extracted_count} ä¸ªåŸå¸‚çš„top1çƒ­ç‚¹")
            
            # ç»Ÿè®¡ç»“æœ
            total_time = time.time() - start_time
            
            print(f"\n" + "=" * 60)
            print(f"ğŸ“Š æ‰¹é‡åˆ†æå®Œæˆï¼")
            print(f"=" * 60)
            print(f"æ€»è€—æ—¶: {total_time:.2f}ç§’")
            print(f"æˆåŠŸåˆ†æ: {len(successful_cities)} ä¸ªåŸå¸‚")
            print(f"å¤±è´¥: {len(failed_cities)} ä¸ªåŸå¸‚")
            print(f"æå–top1: {extracted_count} ä¸ªçƒ­ç‚¹")
            
            if successful_cities:
                print(f"\nâœ… æˆåŠŸçš„åŸå¸‚: {', '.join(successful_cities[:10])}")
                if len(successful_cities) > 10:
                    print(f"   ... è¿˜æœ‰ {len(successful_cities) - 10} ä¸ª")
            
            if failed_cities:
                print(f"\nâš ï¸ å¤±è´¥çš„åŸå¸‚: {', '.join(failed_cities[:10])}")
                if len(failed_cities) > 10:
                    print(f"   ... è¿˜æœ‰ {len(failed_cities) - 10} ä¸ª")
            
            # æ˜¾ç¤ºç»“æœæ¦‚è§ˆ
            if extracted_count > 0:
                summary_sql = text(f"""
                    SELECT 
                        city_id,
                        bbox_count,
                        subdataset_count,
                        scene_count,
                        grid_coords,
                        ROUND(total_overlap_area::numeric, 6) as total_overlap_area
                    FROM {args.output_table}
                    WHERE analysis_time::date = CURRENT_DATE
                    ORDER BY bbox_count DESC
                    LIMIT 10;
                """)
                
                results_df = pd.read_sql(summary_sql, conn)
                
                print(f"\nğŸ“‹ Top10çƒ­ç‚¹åŸå¸‚:")
                print(results_df.to_string(index=False))
                
                print(f"\nğŸ¯ QGISå¯è§†åŒ–:")
                print(f"   è¡¨å: {args.output_table}")
                print(f"   ä¸»é”®: id")
                print(f"   å‡ ä½•åˆ—: geometry")
                print(f"   æŒ‰ bbox_count è®¾ç½®é¢œè‰²ï¼ˆå¯†åº¦è¶Šé«˜è¶Šçƒ­ï¼‰")
                print(f"   æ˜¾ç¤º city_id å’Œ bbox_count æ ‡ç­¾")
            
    except Exception as e:
        print(f"\nâŒ æ‰¹é‡åˆ†æå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main())