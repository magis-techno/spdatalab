#!/usr/bin/env python3
"""
åœºæ™¯å›¾ç‰‡æŸ¥çœ‹å™¨ç¤ºä¾‹è„šæœ¬
======================

ä»æ•°æ®åº“æŸ¥è¯¢åœºæ™¯IDï¼ŒåŠ è½½å›¾ç‰‡å¹¶ç”ŸæˆHTMLæŠ¥å‘Šç”¨äºå¿«é€Ÿæµè§ˆã€‚

ä½¿ç”¨åœºæ™¯ï¼š
1. æŸ¥çœ‹ç½‘æ ¼èšç±»åˆ†æç»“æœçš„ä»£è¡¨æ€§åœºæ™¯å›¾ç‰‡
2. æŸ¥çœ‹æŒ‡å®šåœºæ™¯çš„å›¾ç‰‡æ ·æœ¬
3. ä»èšç±»ç»“æœé€‰æ‹©TOP Nä¸ªclusterçš„åœºæ™¯

ä½¿ç”¨æ–¹æ³•ï¼š
    # 1. ä»èšç±»ç»“æœé€‰æ‹©åœºæ™¯ï¼ˆæŒ‡å®šgrid_idå’Œclusterï¼‰
    python view_cluster_images.py \\
        --grid-id 123 \\
        --cluster-label 0 \\
        --max-scenes 5 \\
        --frames-per-scene 3
    
    # 2. æŒ‡å®šå…·ä½“çš„scene_ids
    python view_cluster_images.py \\
        --scene-ids scene_001 scene_002 scene_003 \\
        --frames-per-scene 5 \\
        --output my_report.html
    
    # 3. ä»åˆ†æIDåŠ è½½åœºæ™¯ï¼ˆé€‰æ‹©TOP Nä¸ªclusterï¼‰
    python view_cluster_images.py \\
        --analysis-id cluster_20231021 \\
        --top-clusters 3 \\
        --max-scenes-per-cluster 3 \\
        --frames-per-scene 3

è¾“å‡ºç»“æœï¼š
    - HTMLæŠ¥å‘Šæ–‡ä»¶ï¼ˆåŒ…å«base64ç¼–ç çš„å›¾ç‰‡ï¼‰
    - ç»ˆç«¯ç»Ÿè®¡ä¿¡æ¯

ä½œè€…ï¼šspdatalab
"""

import sys
from pathlib import Path
import argparse
import logging
from datetime import datetime
from typing import List, Optional

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

try:
    from spdatalab.dataset.scene_image_retriever import SceneImageRetriever
    from spdatalab.dataset.scene_image_viewer import SceneImageHTMLViewer
except ImportError:
    sys.path.insert(0, str(project_root / "src"))
    from spdatalab.dataset.scene_image_retriever import SceneImageRetriever
    from spdatalab.dataset.scene_image_viewer import SceneImageHTMLViewer

from sqlalchemy import create_engine, text
import pandas as pd

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# æ•°æ®åº“è¿æ¥
LOCAL_DSN = "postgresql+psycopg://postgres:postgres@local_pg:5432/postgres"


def get_cluster_scenes(
    grid_id: int,
    cluster_label: Optional[int] = None,
    max_scenes: int = 10
) -> List[str]:
    """ä»èšç±»ç»“æœè·å–åœºæ™¯ID
    
    Args:
        grid_id: Grid ID
        cluster_label: èšç±»æ ‡ç­¾ï¼ˆNoneè¡¨ç¤ºæ‰€æœ‰clusterï¼‰
        max_scenes: æœ€å¤§åœºæ™¯æ•°
        
    Returns:
        åœºæ™¯IDåˆ—è¡¨ï¼ˆå®é™…æ˜¯dataset_nameï¼‰
    """
    logger.info(f"æŸ¥è¯¢Grid {grid_id} çš„èšç±»åœºæ™¯...")
    
    engine = create_engine(LOCAL_DSN)
    
    # æ„å»ºæŸ¥è¯¢
    if cluster_label is not None:
        sql = text("""
            SELECT DISTINCT dataset_name
            FROM public.grid_trajectory_segments
            WHERE grid_id = :grid_id
              AND cluster_label = :cluster_label
              AND quality_flag = true
            LIMIT :max_scenes
        """)
        params = {
            "grid_id": grid_id,
            "cluster_label": cluster_label,
            "max_scenes": max_scenes
        }
        logger.info(f"  Clusteræ ‡ç­¾: {cluster_label}")
    else:
        sql = text("""
            SELECT DISTINCT dataset_name
            FROM public.grid_trajectory_segments
            WHERE grid_id = :grid_id
              AND quality_flag = true
            LIMIT :max_scenes
        """)
        params = {"grid_id": grid_id, "max_scenes": max_scenes}
        logger.info(f"  æ‰€æœ‰Cluster")
    
    with engine.connect() as conn:
        result = conn.execute(sql, params)
        dataset_names = [row[0] for row in result]
    
    logger.info(f"âœ… æ‰¾åˆ° {len(dataset_names)} ä¸ªdataset_name")
    
    # dataset_nameé€šå¸¸å°±æ˜¯scene_idï¼Œæˆ–è€…éœ€è¦è¿›ä¸€æ­¥è½¬æ¢
    # è¿™é‡Œå‡è®¾dataset_nameå¯ä»¥ç›´æ¥ç”¨ä½œscene_id
    return dataset_names


def get_top_clusters_scenes(
    analysis_id: str,
    top_n: int = 3,
    max_scenes_per_cluster: int = 5
) -> List[str]:
    """è·å–TOP Nä¸ªclusterçš„åœºæ™¯
    
    Args:
        analysis_id: åˆ†æID
        top_n: é€‰æ‹©TOP Nä¸ªcluster
        max_scenes_per_cluster: æ¯ä¸ªclusterçš„æœ€å¤§åœºæ™¯æ•°
        
    Returns:
        åœºæ™¯IDåˆ—è¡¨
    """
    logger.info(f"æŸ¥è¯¢åˆ†æ {analysis_id} çš„TOP {top_n} clusters...")
    
    engine = create_engine(LOCAL_DSN)
    
    # 1. è·å–TOP Nä¸ªcluster
    sql_clusters = text("""
        SELECT cluster_label, segment_count
        FROM public.grid_clustering_summary
        WHERE analysis_id = :analysis_id
          AND cluster_label >= 0
        ORDER BY segment_count DESC
        LIMIT :top_n
    """)
    
    with engine.connect() as conn:
        result = conn.execute(sql_clusters, {
            "analysis_id": analysis_id,
            "top_n": top_n
        })
        top_clusters = [row[0] for row in result]
    
    logger.info(f"  TOP {top_n} clusters: {top_clusters}")
    
    # 2. è·å–æ¯ä¸ªclusterçš„åœºæ™¯
    all_scenes = []
    for cluster_label in top_clusters:
        sql_scenes = text("""
            SELECT DISTINCT dataset_name
            FROM public.grid_trajectory_segments
            WHERE analysis_id = :analysis_id
              AND cluster_label = :cluster_label
              AND quality_flag = true
            LIMIT :max_scenes
        """)
        
        with engine.connect() as conn:
            result = conn.execute(sql_scenes, {
                "analysis_id": analysis_id,
                "cluster_label": cluster_label,
                "max_scenes": max_scenes_per_cluster
            })
            scenes = [row[0] for row in result]
            all_scenes.extend(scenes)
        
        logger.info(f"  Cluster {cluster_label}: {len(scenes)} ä¸ªåœºæ™¯")
    
    logger.info(f"âœ… æ€»å…±æ‰¾åˆ° {len(all_scenes)} ä¸ªåœºæ™¯")
    return all_scenes


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="ä»æ•°æ®åº“åŠ è½½åœºæ™¯å›¾ç‰‡å¹¶ç”ŸæˆHTMLæŠ¥å‘Š",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•ï¼š
  # æŸ¥çœ‹æŸä¸ªgridçš„clusterå›¾ç‰‡
  python %(prog)s --grid-id 123 --cluster-label 0 --max-scenes 5

  # æŸ¥çœ‹æŒ‡å®šåœºæ™¯
  python %(prog)s --scene-ids scene_001 scene_002 --frames-per-scene 5

  # æŸ¥çœ‹TOP 3 clusters
  python %(prog)s --analysis-id cluster_20231021 --top-clusters 3
        """
    )
    
    # åœºæ™¯æ¥æºå‚æ•°ï¼ˆäº’æ–¥ï¼‰
    source_group = parser.add_mutually_exclusive_group(required=True)
    source_group.add_argument(
        '--scene-ids', 
        nargs='+',
        help='ç›´æ¥æŒ‡å®šåœºæ™¯IDåˆ—è¡¨'
    )
    source_group.add_argument(
        '--grid-id',
        type=int,
        help='ä»Gridèšç±»ç»“æœæŸ¥è¯¢åœºæ™¯'
    )
    source_group.add_argument(
        '--analysis-id',
        type=str,
        help='ä»åˆ†æIDæŸ¥è¯¢åœºæ™¯'
    )
    
    # GridæŸ¥è¯¢å‚æ•°
    parser.add_argument(
        '--cluster-label',
        type=int,
        help='èšç±»æ ‡ç­¾ï¼ˆä¸--grid-idé…åˆä½¿ç”¨ï¼‰'
    )
    parser.add_argument(
        '--max-scenes',
        type=int,
        default=10,
        help='æœ€å¤§åœºæ™¯æ•°ï¼ˆä¸--grid-idé…åˆä½¿ç”¨ï¼Œé»˜è®¤: 10ï¼‰'
    )
    
    # AnalysisæŸ¥è¯¢å‚æ•°
    parser.add_argument(
        '--top-clusters',
        type=int,
        default=3,
        help='é€‰æ‹©TOP Nä¸ªclusterï¼ˆä¸--analysis-idé…åˆä½¿ç”¨ï¼Œé»˜è®¤: 3ï¼‰'
    )
    parser.add_argument(
        '--max-scenes-per-cluster',
        type=int,
        default=5,
        help='æ¯ä¸ªclusterçš„æœ€å¤§åœºæ™¯æ•°ï¼ˆä¸--analysis-idé…åˆä½¿ç”¨ï¼Œé»˜è®¤: 5ï¼‰'
    )
    
    # å›¾ç‰‡åŠ è½½å‚æ•°
    parser.add_argument(
        '--frames-per-scene',
        type=int,
        default=3,
        help='æ¯ä¸ªåœºæ™¯åŠ è½½çš„å¸§æ•°ï¼ˆé»˜è®¤: 3ï¼‰'
    )
    parser.add_argument(
        '--camera-type',
        type=str,
        default='CAM_FRONT_WIDE_ANGLE',
        help='ç›¸æœºç±»å‹ï¼ˆé»˜è®¤: CAM_FRONT_WIDE_ANGLEï¼‰'
    )
    
    # è¾“å‡ºå‚æ•°
    parser.add_argument(
        '--output',
        type=str,
        help='è¾“å‡ºHTMLæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤è‡ªåŠ¨ç”Ÿæˆï¼‰'
    )
    parser.add_argument(
        '--title',
        type=str,
        help='HTMLæŠ¥å‘Šæ ‡é¢˜ï¼ˆé»˜è®¤è‡ªåŠ¨ç”Ÿæˆï¼‰'
    )
    parser.add_argument(
        '--thumbnail-size',
        type=int,
        default=200,
        help='ç¼©ç•¥å›¾å¤§å°ï¼ˆé»˜è®¤: 200ï¼‰'
    )
    
    args = parser.parse_args()
    
    print("=" * 70)
    print("åœºæ™¯å›¾ç‰‡æŸ¥çœ‹å™¨")
    print("=" * 70)
    
    # 1. è·å–åœºæ™¯IDåˆ—è¡¨
    scene_ids = []
    
    if args.scene_ids:
        scene_ids = args.scene_ids
        logger.info(f"ä½¿ç”¨æŒ‡å®šçš„åœºæ™¯ID: {len(scene_ids)} ä¸ª")
        
    elif args.grid_id:
        scene_ids = get_cluster_scenes(
            args.grid_id,
            args.cluster_label,
            args.max_scenes
        )
        
    elif args.analysis_id:
        scene_ids = get_top_clusters_scenes(
            args.analysis_id,
            args.top_clusters,
            args.max_scenes_per_cluster
        )
    
    if not scene_ids:
        logger.error("âŒ æœªæ‰¾åˆ°ä»»ä½•åœºæ™¯ID")
        return 1
    
    print(f"\nğŸ“‹ å¾…å¤„ç†åœºæ™¯æ•°: {len(scene_ids)}")
    print(f"ğŸ¬ æ¯åœºæ™¯å¸§æ•°: {args.frames_per_scene}")
    print(f"ğŸ“· ç›¸æœºç±»å‹: {args.camera_type}")
    
    # 2. åŠ è½½å›¾ç‰‡
    print(f"\n{'=' * 70}")
    print("å¼€å§‹åŠ è½½å›¾ç‰‡...")
    print(f"{'=' * 70}\n")
    
    retriever = SceneImageRetriever(camera_type=args.camera_type)
    
    try:
        images_dict = retriever.batch_load_images(
            scene_ids,
            frames_per_scene=args.frames_per_scene
        )
    except Exception as e:
        logger.error(f"âŒ åŠ è½½å›¾ç‰‡å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    if not images_dict:
        logger.error("âŒ æœªæˆåŠŸåŠ è½½ä»»ä½•å›¾ç‰‡")
        return 1
    
    # 3. ç”ŸæˆHTMLæŠ¥å‘Š
    print(f"\n{'=' * 70}")
    print("ç”ŸæˆHTMLæŠ¥å‘Š...")
    print(f"{'=' * 70}\n")
    
    # ç¡®å®šè¾“å‡ºè·¯å¾„
    if args.output:
        output_path = args.output
    else:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        if args.grid_id:
            suffix = f"grid{args.grid_id}"
            if args.cluster_label is not None:
                suffix += f"_cluster{args.cluster_label}"
        elif args.analysis_id:
            suffix = f"analysis_{args.analysis_id}"
        else:
            suffix = "scenes"
        output_path = f"scene_images_{suffix}_{timestamp}.html"
    
    # ç¡®å®šæ ‡é¢˜
    if args.title:
        title = args.title
    else:
        if args.grid_id:
            title = f"Grid {args.grid_id}"
            if args.cluster_label is not None:
                title += f" - Cluster {args.cluster_label}"
            title += " å›¾ç‰‡æŸ¥çœ‹å™¨"
        elif args.analysis_id:
            title = f"åˆ†æ {args.analysis_id} - TOP {args.top_clusters} Clusters"
        else:
            title = "åœºæ™¯å›¾ç‰‡æŸ¥çœ‹å™¨"
    
    viewer = SceneImageHTMLViewer()
    
    try:
        report_path = viewer.generate_html_report(
            images_dict,
            output_path,
            title=title,
            thumbnail_size=args.thumbnail_size
        )
    except Exception as e:
        logger.error(f"âŒ ç”ŸæˆHTMLæŠ¥å‘Šå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    # 4. è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    total_frames = sum(len(frames) for frames in images_dict.values())
    
    print(f"\n{'=' * 70}")
    print("âœ… å¤„ç†å®Œæˆï¼")
    print(f"{'=' * 70}")
    print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"  æˆåŠŸåŠ è½½åœºæ™¯æ•°: {len(images_dict)}")
    print(f"  æ€»å¸§æ•°: {total_frames}")
    print(f"  å¹³å‡æ¯åœºæ™¯å¸§æ•°: {total_frames / len(images_dict):.1f}")
    print(f"\nğŸ“„ HTMLæŠ¥å‘Šè·¯å¾„:")
    print(f"  {report_path}")
    print(f"\nğŸ’¡ æç¤º: åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€HTMLæ–‡ä»¶æŸ¥çœ‹å›¾ç‰‡")
    print(f"{'=' * 70}\n")
    
    return 0


if __name__ == "__main__":
    sys.exit(main())

