#!/usr/bin/env python3
"""
Dockerå…¼å®¹çš„bboxå ç½®åˆ†æå¯åŠ¨è„šæœ¬

è¿™ä¸ªè„šæœ¬ä¸“é—¨ä¸ºDockerç¯å¢ƒè®¾è®¡ï¼Œè‡ªåŠ¨å¤„ç†è·¯å¾„å’Œä¾èµ–å¯¼å…¥é—®é¢˜ã€‚

ä½¿ç”¨æ–¹æ³•ï¼š
    # åœ¨Dockerå®¹å™¨ä¸­è¿è¡Œ
    python examples/dataset/bbox_examples/run_overlap_analysis.py

    # å¸¦å‚æ•°è¿è¡Œ
    python examples/dataset/bbox_examples/run_overlap_analysis.py \
        --city beijing --refresh-view --top-n 15
"""

import sys
import os
import signal
import atexit
from pathlib import Path

def setup_environment():
    """è®¾ç½®è¿è¡Œç¯å¢ƒï¼Œå¤„ç†è·¯å¾„å’Œå¯¼å…¥é—®é¢˜"""
    
    # è·å–é¡¹ç›®æ ¹ç›®å½•
    script_path = Path(__file__).resolve()
    project_root = script_path.parent.parent.parent
    
    print(f"ğŸ”§ è„šæœ¬ä½ç½®: {script_path}")
    print(f"ğŸ”§ é¡¹ç›®æ ¹ç›®å½•: {project_root}")
    
    # æ·»åŠ å¯èƒ½çš„è·¯å¾„
    paths_to_add = [
        str(project_root),
        str(project_root / "src"),
        "/workspace",
        "/workspace/src"
    ]
    
    for path in paths_to_add:
        if path not in sys.path:
            sys.path.insert(0, path)
    
    print(f"ğŸ”§ Pythonè·¯å¾„:")
    for i, path in enumerate(sys.path[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
        print(f"   {i}: {path}")
    
    # å°è¯•å¯¼å…¥æµ‹è¯•
    try:
        # å°è¯•æ–¹å¼1ï¼šç›´æ¥å¯¼å…¥
        from spdatalab.dataset.bbox import LOCAL_DSN
        print("âœ… å¯¼å…¥æ–¹å¼: ç›´æ¥å¯¼å…¥ spdatalab")
        return True
    except ImportError as e1:
        try:
            # å°è¯•æ–¹å¼2ï¼šä»srcå¯¼å…¥
            from src.spdatalab.dataset.bbox import LOCAL_DSN
            print("âœ… å¯¼å…¥æ–¹å¼: ä»srcå¯¼å…¥ spdatalab")
            return True
        except ImportError as e2:
            print(f"âŒ å¯¼å…¥å¤±è´¥:")
            print(f"   æ–¹å¼1é”™è¯¯: {e1}")
            print(f"   æ–¹å¼2é”™è¯¯: {e2}")
            
            # æ˜¾ç¤ºå½“å‰ç›®å½•ç»“æ„ä»¥ä¾›è°ƒè¯•
            print(f"\nğŸ” å½“å‰ç›®å½•ç»“æ„:")
            cwd = Path.cwd()
            print(f"   å½“å‰å·¥ä½œç›®å½•: {cwd}")
            
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨spdatalabæ¨¡å—
            possible_paths = [
                cwd / "spdatalab",
                cwd / "src" / "spdatalab", 
                project_root / "spdatalab",
                project_root / "src" / "spdatalab"
            ]
            
            for path in possible_paths:
                exists = path.exists()
                print(f"   {path}: {'å­˜åœ¨' if exists else 'ä¸å­˜åœ¨'}")
                
            return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ Dockerå…¼å®¹çš„BBoxå ç½®åˆ†æ")
    print("=" * 50)
    
    # è®¾ç½®ä¼˜é›…é€€å‡ºå¤„ç†
    shutdown_requested = False
    current_connection = None
    analysis_start_time = None
    
    def signal_handler(signum, frame):
        nonlocal shutdown_requested, current_connection, analysis_start_time
        print(f"\n\nğŸ›‘ æ”¶åˆ°é€€å‡ºä¿¡å· ({signal.Signals(signum).name})")
        shutdown_requested = True
        print(f"ğŸ”„ æ­£åœ¨å®‰å…¨é€€å‡º...")
        
        if analysis_start_time:
            elapsed = datetime.now() - analysis_start_time
            print(f"â±ï¸ å·²è¿è¡Œæ—¶é—´: {elapsed}")
        
        if current_connection:
            try:
                current_connection.close()
                print(f"âœ… æ•°æ®åº“è¿æ¥å·²å…³é—­")
            except Exception as e:
                print(f"âš ï¸ å…³é—­è¿æ¥æ—¶å‡ºé”™: {e}")
        
        print(f"âœ… ä¼˜é›…é€€å‡ºå®Œæˆ")
        sys.exit(0)
    
    def check_shutdown():
        if shutdown_requested:
            print(f"ğŸ›‘ æ£€æµ‹åˆ°é€€å‡ºè¯·æ±‚ï¼Œåœæ­¢æ‰§è¡Œ")
            sys.exit(0)
    
    # æ³¨å†Œä¿¡å·å¤„ç†å™¨
    try:
        signal.signal(signal.SIGINT, signal_handler)   # Ctrl+C
        signal.signal(signal.SIGTERM, signal_handler)  # ç»ˆæ­¢ä¿¡å·
        if hasattr(signal, 'SIGBREAK'):  # Windows
            signal.signal(signal.SIGBREAK, signal_handler)
    except ValueError:
        print("âš ï¸ æ— æ³•æ³¨å†Œä¿¡å·å¤„ç†å™¨")
    
    # è®¾ç½®ç¯å¢ƒ
    if not setup_environment():
        print("\nâŒ ç¯å¢ƒè®¾ç½®å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
        sys.exit(1)
    
    print("\nğŸš€ ç¯å¢ƒè®¾ç½®æˆåŠŸï¼Œå¼€å§‹å¯¼å…¥æ¨¡å—...")
    
    try:
        # å¯¼å…¥å¿…è¦çš„æ¨¡å—
        import argparse
        from datetime import datetime
        
        # å°è¯•å¯¼å…¥åˆ†æå™¨
        try:
            from spdatalab.dataset.bbox import (
                create_unified_view,
                list_bbox_tables,
                LOCAL_DSN
            )
        except ImportError:
            from src.spdatalab.dataset.bbox import (
                create_unified_view,
                list_bbox_tables,
                LOCAL_DSN
            )
        
        from sqlalchemy import create_engine, text
        import pandas as pd
        
        print("âœ… æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # è§£æå‘½ä»¤è¡Œå‚æ•°
        parser = argparse.ArgumentParser(description='Dockerå…¼å®¹çš„BBoxå ç½®åˆ†æ')
        parser.add_argument('--city', help='åŸå¸‚è¿‡æ»¤')
        parser.add_argument('--subdatasets', nargs='+', help='å­æ•°æ®é›†è¿‡æ»¤')
        parser.add_argument('--min-overlap-area', type=float, default=0.0001, help='æœ€å°é‡å é¢ç§¯é˜ˆå€¼')
        parser.add_argument('--top-n', type=int, default=15, help='è¿”å›çš„çƒ­ç‚¹æ•°é‡')
        parser.add_argument('--analysis-id', help='è‡ªå®šä¹‰åˆ†æID')
        parser.add_argument('--refresh-view', action='store_true', help='å¼ºåˆ¶åˆ·æ–°ç»Ÿä¸€è§†å›¾')
        parser.add_argument('--test-only', action='store_true', help='åªè¿è¡Œæµ‹è¯•ï¼Œä¸æ‰§è¡Œåˆ†æ')
        parser.add_argument('--suggest-city', action='store_true', help='æ˜¾ç¤ºåŸå¸‚åˆ†æå»ºè®®å¹¶é€€å‡º')
        parser.add_argument('--estimate-time', action='store_true', help='ä¼°ç®—åˆ†ææ—¶é—´å¹¶é€€å‡º')
        parser.add_argument('--debug', action='store_true', help='å¼€å¯è°ƒè¯•æ¨¡å¼ï¼Œæ˜¾ç¤ºè¯¦ç»†åˆ†æä¿¡æ¯')
        parser.add_argument('--intersect-only', action='store_true', help='ä»…æ£€æµ‹ç›¸äº¤ï¼ˆå¿½ç•¥é¢ç§¯é˜ˆå€¼ï¼‰')
        parser.add_argument('--sample-check', type=int, default=0, help='è°ƒè¯•é‡‡æ ·æ•°é‡ï¼ˆé…åˆ--debugä½¿ç”¨ï¼‰')
        
        args = parser.parse_args()
        
        print(f"\nğŸ“‹ åˆ†æå‚æ•°:")
        print(f"   åŸå¸‚è¿‡æ»¤: {args.city}")
        print(f"   æœ€å°é‡å é¢ç§¯: {args.min_overlap_area}")
        print(f"   è¿”å›æ•°é‡: {args.top_n}")
        print(f"   å¼ºåˆ¶åˆ·æ–°è§†å›¾: {args.refresh_view}")
        if args.debug:
            print(f"   è°ƒè¯•æ¨¡å¼: å¼€å¯")
            if args.sample_check > 0:
                print(f"   è°ƒè¯•é‡‡æ ·: {args.sample_check}")
        if args.intersect_only:
            print(f"   ç›¸äº¤æ¨¡å¼: å¿½ç•¥é¢ç§¯é˜ˆå€¼ï¼Œåªè¦ç›¸äº¤å°±ç®—é‡å ")
        
        # åˆ›å»ºæ•°æ®åº“è¿æ¥
        print(f"\nğŸ”Œ è¿æ¥æ•°æ®åº“...")
        engine = create_engine(LOCAL_DSN, future=True)
        
        with engine.connect() as conn:
            result = conn.execute(text("SELECT 1 as test;"))
            print(f"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
        
        # æ£€æŸ¥bboxè¡¨
        print(f"\nğŸ“Š æ£€æŸ¥bboxåˆ†è¡¨...")
        tables = list_bbox_tables(engine)
        bbox_tables = [t for t in tables if t.startswith('clips_bbox_') and t != 'clips_bbox']
        print(f"âœ… å‘ç° {len(bbox_tables)} ä¸ªbboxåˆ†è¡¨")
        
        if len(bbox_tables) == 0:
            print("âŒ æ²¡æœ‰å‘ç°bboxåˆ†è¡¨ï¼Œæ— æ³•æ‰§è¡Œåˆ†æ")
            return
        
        # æ£€æŸ¥ç»Ÿä¸€è§†å›¾
        print(f"\nğŸ” æ£€æŸ¥ç»Ÿä¸€è§†å›¾...")
        view_name = "clips_bbox_unified"
        
        check_view_sql = text(f"""
            SELECT EXISTS (
                SELECT FROM information_schema.views 
                WHERE table_schema = 'public' 
                AND table_name = '{view_name}'
            );
        """)
        
        # åˆ›å»ºæŒä¹…è¿æ¥ç”¨äºæ•´ä¸ªåˆ†æè¿‡ç¨‹
        conn = engine.connect()
        
        try:
            result = conn.execute(check_view_sql)
            view_exists = result.scalar()
            
            if not view_exists or args.refresh_view:
                if args.refresh_view:
                    print(f"ğŸ”„ å¼ºåˆ¶åˆ·æ–°æ¨¡å¼ï¼Œé‡æ–°åˆ›å»ºè§†å›¾...")
                else:
                    print(f"ğŸ“Œ è§†å›¾ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°è§†å›¾...")
                
                success = create_unified_view(engine, view_name)
                if not success:
                    print("âŒ ç»Ÿä¸€è§†å›¾åˆ›å»ºå¤±è´¥")
                    return
                print(f"âœ… ç»Ÿä¸€è§†å›¾åˆ›å»ºæˆåŠŸ")
            else:
                print(f"âœ… ç»Ÿä¸€è§†å›¾å·²å­˜åœ¨")
            
            # è·³è¿‡è€—æ—¶çš„COUNTæŸ¥è¯¢ï¼Œç›´æ¥å¼€å§‹åˆ†æ
            print(f"ğŸ“Š ç»Ÿä¸€è§†å›¾å·²å°±ç»ªï¼Œå¼€å§‹åˆ†æ...")
            
            # å¦‚æœåªæ˜¯æµ‹è¯•æ¨¡å¼ï¼Œåˆ°è¿™é‡Œå°±ç»“æŸ
            if args.test_only:
                print(f"\nâœ… æµ‹è¯•æ¨¡å¼å®Œæˆï¼Œæ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼")
                print(f"ğŸ’¡ ç§»é™¤ --test-only å‚æ•°å¯ä»¥æ‰§è¡Œå®Œæ•´åˆ†æ")
                return
            
            # å¦‚æœç”¨æˆ·æƒ³æŸ¥çœ‹åŸå¸‚å»ºè®®
            if args.suggest_city:
                print(f"\nğŸ™ï¸ åŸå¸‚åˆ†æå»ºè®®")
                print("-" * 40)
                
                city_stats_sql = f"""
                SELECT 
                    city_id,
                    COUNT(*) as total_count,
                    COUNT(*) FILTER (WHERE all_good = true) as good_count,
                    ROUND(100.0 * COUNT(*) FILTER (WHERE all_good = true) / COUNT(*), 1) as good_percent,
                    CASE 
                        WHEN COUNT(*) FILTER (WHERE all_good = true) > 50000 THEN '> 10åˆ†é’Ÿ'
                        WHEN COUNT(*) FILTER (WHERE all_good = true) > 10000 THEN '2-10åˆ†é’Ÿ'
                        WHEN COUNT(*) FILTER (WHERE all_good = true) > 1000 THEN '< 2åˆ†é’Ÿ'
                        ELSE '< 30ç§’'
                    END as estimated_time,
                    CASE 
                        WHEN COUNT(*) FILTER (WHERE all_good = true) BETWEEN 1000 AND 20000 AND 
                             100.0 * COUNT(*) FILTER (WHERE all_good = true) / COUNT(*) > 90 THEN 'â­â­â­ æ¨è'
                        WHEN COUNT(*) FILTER (WHERE all_good = true) BETWEEN 500 AND 50000 AND 
                             100.0 * COUNT(*) FILTER (WHERE all_good = true) / COUNT(*) > 85 THEN 'â­â­ è¾ƒå¥½'
                        WHEN COUNT(*) FILTER (WHERE all_good = true) > 100 THEN 'â­ å¯ç”¨'
                        ELSE 'âŒ ä¸å»ºè®®'
                    END as recommendation
                FROM {view_name}
                WHERE city_id IS NOT NULL
                GROUP BY city_id
                HAVING COUNT(*) FILTER (WHERE all_good = true) > 0
                ORDER BY 
                    CASE 
                        WHEN COUNT(*) FILTER (WHERE all_good = true) BETWEEN 1000 AND 20000 AND 
                             100.0 * COUNT(*) FILTER (WHERE all_good = true) / COUNT(*) > 90 THEN 1
                        WHEN COUNT(*) FILTER (WHERE all_good = true) BETWEEN 500 AND 50000 AND 
                             100.0 * COUNT(*) FILTER (WHERE all_good = true) / COUNT(*) > 85 THEN 2
                        WHEN COUNT(*) FILTER (WHERE all_good = true) > 100 THEN 3
                        ELSE 4
                    END,
                    COUNT(*) FILTER (WHERE all_good = true) DESC;
                """
                
                city_df = pd.read_sql(city_stats_sql, engine)
                if not city_df.empty:
                    print("ğŸ“Š åŸå¸‚åˆ†æå»ºè®®è¡¨:")
                    print(city_df.to_string(index=False))
                    
                    recommended = city_df[city_df['recommendation'].str.contains('â­â­â­')]
                    if not recommended.empty:
                        best_city = recommended.iloc[0]['city_id']
                        print(f"\nğŸ’¡ æ¨èåŸå¸‚: {best_city}")
                        print(f"   - å»ºè®®å‘½ä»¤: --city {best_city}")
                else:
                    print("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„åŸå¸‚æ•°æ®")
                return
            
            # å¦‚æœç”¨æˆ·æƒ³ä¼°ç®—æ—¶é—´
            if args.estimate_time:
                print(f"\nâ±ï¸ åˆ†ææ—¶é—´ä¼°ç®—")
                print("-" * 40)
                
                where_condition = f"WHERE city_id = '{args.city}'" if args.city else "WHERE city_id IS NOT NULL"
                time_estimate_sql = f"""
                SELECT 
                    COUNT(*) FILTER (WHERE all_good = true) as analyzable_count,
                    CASE 
                        WHEN COUNT(*) FILTER (WHERE all_good = true) > 100000 THEN 'âš ï¸ å¾ˆé•¿ (>30åˆ†é’Ÿ)'
                        WHEN COUNT(*) FILTER (WHERE all_good = true) > 50000 THEN 'â³ è¾ƒé•¿ (10-30åˆ†é’Ÿ)'
                        WHEN COUNT(*) FILTER (WHERE all_good = true) > 10000 THEN 'â° ä¸­ç­‰ (2-10åˆ†é’Ÿ)'
                        WHEN COUNT(*) FILTER (WHERE all_good = true) > 1000 THEN 'âš¡ è¾ƒå¿« (<2åˆ†é’Ÿ)'
                        ELSE 'ğŸš€ å¾ˆå¿« (<30ç§’)'
                    END as time_estimate,
                    '{args.city if args.city else "å…¨éƒ¨åŸå¸‚"}' as scope
                FROM {view_name}
                {where_condition};
                """
                
                estimate_result = conn.execute(text(time_estimate_sql)).fetchone()
                print(f"ğŸ“Š åˆ†æèŒƒå›´: {estimate_result.scope}")
                print(f"ğŸ“ˆ å¯åˆ†ææ•°æ®: {estimate_result.analyzable_count:,} ä¸ªbbox")
                print(f"â±ï¸ é¢„ä¼°æ—¶é—´: {estimate_result.time_estimate}")
                
                if estimate_result.analyzable_count > 50000:
                    print(f"ğŸ’¡ å»ºè®®: æ•°æ®é‡è¾ƒå¤§ï¼Œå»ºè®®æŒ‡å®šå…·ä½“åŸå¸‚è¿›è¡Œåˆ†æ")
                return
        
        finally:
            # ç¡®ä¿è¿æ¥æ€»æ˜¯ä¼šè¢«å…³é—­
            if conn:
                conn.close()
        
        # åˆ›å»ºåˆ†æç»“æœè¡¨
        print(f"\nğŸ› ï¸ å‡†å¤‡åˆ†æè¡¨...")
        
        analysis_table = "bbox_overlap_analysis_results"
        
        # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
        check_table_sql = text(f"""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_schema = 'public' 
                AND table_name = '{analysis_table}'
            );
        """)
        
        with engine.connect() as conn:
            result = conn.execute(check_table_sql)
            table_exists = result.scalar()
            
            if not table_exists:
                print(f"ğŸ“Œ åˆ†æè¡¨ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°è¡¨...")
                
                # ç›´æ¥ä½¿ç”¨å†…ç½®SQLåˆ›å»ºè¡¨
                create_sql = f"""
                CREATE TABLE {analysis_table} (
                    id SERIAL PRIMARY KEY,
                    analysis_id VARCHAR(100) NOT NULL,
                    analysis_type VARCHAR(50) DEFAULT 'bbox_overlap',
                    analysis_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    hotspot_rank INTEGER,
                    overlap_count INTEGER,
                    total_overlap_area NUMERIC,
                    subdataset_count INTEGER,
                    scene_count INTEGER,
                    involved_subdatasets TEXT[],
                    involved_scenes TEXT[],
                    analysis_params TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
                
                -- æ·»åŠ å‡ ä½•åˆ—
                SELECT AddGeometryColumn('public', '{analysis_table}', 'geometry', 4326, 'GEOMETRY', 2);
                
                -- åˆ›å»ºç´¢å¼•
                CREATE INDEX idx_{analysis_table}_analysis_id ON {analysis_table} (analysis_id);
                CREATE INDEX idx_{analysis_table}_rank ON {analysis_table} (hotspot_rank);
                CREATE INDEX idx_{analysis_table}_geom ON {analysis_table} USING GIST (geometry);
                """
                
                conn.execute(text(create_sql))
                conn.commit()
                print(f"âœ… åˆ†æè¡¨åˆ›å»ºæˆåŠŸ")
            else:
                print(f"âœ… åˆ†æè¡¨å·²å­˜åœ¨")
        
        # ç”Ÿæˆåˆ†æID
        if not args.analysis_id:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            analysis_id = f"overlap_docker_{timestamp}"
        else:
            analysis_id = args.analysis_id
        
        print(f"\nğŸš€ å¼€å§‹å ç½®åˆ†æ: {analysis_id}")
        
        # æ„å»ºè¿‡æ»¤æ¡ä»¶
        where_conditions = []
        if args.city:
            where_conditions.append(f"a.city_id = '{args.city}' AND b.city_id = '{args.city}'")
        
        if args.subdatasets:
            subdataset_list = "', '".join(args.subdatasets)
            where_conditions.append(f"a.subdataset_name IN ('{subdataset_list}') AND b.subdataset_name IN ('{subdataset_list}')")
        
        where_clause = "AND " + " AND ".join(where_conditions) if where_conditions else ""
        
        # è°ƒè¯•æ¨¡å¼ï¼šæ˜¾ç¤ºæ•°æ®ç»Ÿè®¡ä¿¡æ¯
        if args.debug:
            print(f"\nğŸ” è°ƒè¯•æ¨¡å¼ï¼šåˆ†ææ•°æ®åˆ†å¸ƒ")
            print("-" * 40)
            
            debug_sql = f"""
            SELECT 
                COUNT(*) as total_count,
                COUNT(*) FILTER (WHERE all_good = true) as good_count,
                COUNT(DISTINCT city_id) as city_count,
                COUNT(DISTINCT subdataset_name) as subdataset_count,
                ROUND(AVG(ST_Area(geometry))::numeric, 10) as avg_area,
                ROUND(MIN(ST_Area(geometry))::numeric, 10) as min_area,
                ROUND(MAX(ST_Area(geometry))::numeric, 10) as max_area
            FROM {view_name}
            WHERE city_id IS NOT NULL
            {f"AND city_id = '{args.city}'" if args.city else ""};
            """
            
            debug_result = conn.execute(text(debug_sql)).fetchone()
            print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
            print(f"   æ€»æ•°é‡: {debug_result.total_count:,}")
            print(f"   è´¨é‡è‰¯å¥½: {debug_result.good_count:,}")
            print(f"   åŸå¸‚æ•°: {debug_result.city_count}")
            print(f"   å­æ•°æ®é›†æ•°: {debug_result.subdataset_count}")
            print(f"   å¹³å‡é¢ç§¯: {debug_result.avg_area}")
            print(f"   é¢ç§¯èŒƒå›´: {debug_result.min_area} ~ {debug_result.max_area}")
            
            # é‡‡æ ·æ£€æŸ¥
            if args.sample_check > 0:
                print(f"\nğŸ² éšæœºé‡‡æ · ({args.sample_check} ä¸ª):")
                sample_sql = f"""
                SELECT 
                    qgis_id,
                    subdataset_name,
                    scene_token,
                    ROUND(ST_Area(geometry)::numeric, 10) as area,
                    ST_AsText(ST_Centroid(geometry)) as centroid
                FROM {view_name}
                WHERE all_good = true
                {f"AND city_id = '{args.city}'" if args.city else ""}
                ORDER BY RANDOM()
                LIMIT {args.sample_check};
                """
                
                sample_results = conn.execute(text(sample_sql)).fetchall()
                for i, row in enumerate(sample_results, 1):
                    print(f"   {i}. ID:{row.qgis_id} é¢ç§¯:{row.area} ä¸­å¿ƒ:{row.centroid}")
        
        # æ ¹æ®æ¨¡å¼å†³å®šé¢ç§¯æ¡ä»¶
        if args.intersect_only:
            area_condition = "-- ç›¸äº¤æ¨¡å¼ï¼šå¿½ç•¥é¢ç§¯é˜ˆå€¼ï¼Œåªè¦ç›¸äº¤å°±ç®—é‡å "
            print(f"ğŸ” ä½¿ç”¨ç›¸äº¤æ¨¡å¼ï¼šåªè¦å‡ ä½•ä½“ç›¸äº¤å°±ç®—é‡å ï¼ˆå¿½ç•¥é¢ç§¯é˜ˆå€¼ï¼‰")
        else:
            area_condition = f"AND ST_Area(ST_Intersection(a.geometry, b.geometry)) > {args.min_overlap_area}"
            print(f"ğŸ“ ä½¿ç”¨é¢ç§¯æ¨¡å¼ï¼šé‡å é¢ç§¯å¿…é¡»å¤§äº {args.min_overlap_area}")
        
        # æ‰§è¡Œåˆ†æ
        analysis_sql = f"""
        WITH overlapping_pairs AS (
            SELECT 
                a.qgis_id as bbox_a_id,
                b.qgis_id as bbox_b_id,
                a.subdataset_name as subdataset_a,
                b.subdataset_name as subdataset_b,
                a.scene_token as scene_a,
                b.scene_token as scene_b,
                ST_Intersection(a.geometry, b.geometry) as overlap_geometry,
                ST_Area(ST_Intersection(a.geometry, b.geometry)) as overlap_area
            FROM {view_name} a
            JOIN {view_name} b ON a.qgis_id < b.qgis_id
            WHERE ST_Intersects(a.geometry, b.geometry)
            {area_condition}
            AND NOT ST_Equals(a.geometry, b.geometry)
            -- ğŸ¯ åªåˆ†æç›¸åŒåŸå¸‚çš„bboxï¼ˆæ€§èƒ½å’Œé€»è¾‘ä¼˜åŒ–ï¼‰
            AND a.city_id = b.city_id
            AND a.city_id IS NOT NULL
            -- ğŸ¯ åªåˆ†æè´¨é‡åˆæ ¼çš„æ•°æ®ï¼ˆall_good=trueï¼‰
            AND a.all_good = true
            AND b.all_good = true
            {where_clause}
        ),
        -- ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨çœŸæ­£çš„ç©ºé—´è¿é€šæ€§èšç±»
        overlap_clusters AS (
            SELECT 
                overlap_geometry,
                overlap_area,
                subdataset_a,
                subdataset_b,
                scene_a,
                scene_b,
                -- ä½¿ç”¨ ST_ClusterDBSCAN è¿›è¡Œç©ºé—´èšç±»
                -- eps=0 è¡¨ç¤ºåªæœ‰ç›´æ¥ç›¸äº¤çš„å‡ ä½•ä½“æ‰å½’ä¸ºä¸€ç»„
                -- minpoints=1 è¡¨ç¤ºå•ä¸ªé‡å ä¹Ÿå¯ä»¥å½¢æˆçƒ­ç‚¹
                ST_ClusterDBSCAN(overlap_geometry, eps := 0, minpoints := 1) OVER() as cluster_id
            FROM overlapping_pairs
        ),
        overlap_hotspots AS (
            SELECT 
                cluster_id,
                -- å¯¹æ¯ä¸ªèšç±»ï¼Œåˆå¹¶æ‰€æœ‰é‡å åŒºåŸŸ
                ST_Union(overlap_geometry) as hotspot_geometry,
                COUNT(*) as overlap_count,
                ARRAY_AGG(DISTINCT subdataset_a) || ARRAY_AGG(DISTINCT subdataset_b) as involved_subdatasets,
                ARRAY_AGG(DISTINCT scene_a) || ARRAY_AGG(DISTINCT scene_b) as involved_scenes,
                SUM(overlap_area) as total_overlap_area
            FROM overlap_clusters
            WHERE cluster_id IS NOT NULL  -- æ’é™¤å™ªå£°ç‚¹
            GROUP BY cluster_id
            HAVING COUNT(*) >= 1  -- è‡³å°‘åŒ…å«ä¸€ä¸ªé‡å åŒºåŸŸ
        )
        INSERT INTO {analysis_table} 
        (analysis_id, hotspot_rank, overlap_count, total_overlap_area, 
         subdataset_count, scene_count, involved_subdatasets, involved_scenes, geometry, analysis_params)
        SELECT 
            '{analysis_id}' as analysis_id,
            ROW_NUMBER() OVER (ORDER BY overlap_count DESC) as hotspot_rank,
            overlap_count,
            total_overlap_area,
            ARRAY_LENGTH(involved_subdatasets, 1) as subdataset_count,
            ARRAY_LENGTH(involved_scenes, 1) as scene_count,
            involved_subdatasets,
            involved_scenes,
            hotspot_geometry as geometry,
            '{{"city_filter": "{args.city}", "min_overlap_area": {args.min_overlap_area}, "top_n": {args.top_n}}}' as analysis_params
        FROM overlap_hotspots
        ORDER BY overlap_count DESC
        LIMIT {args.top_n};
        """
        
        print(f"âš¡ æ‰§è¡Œç©ºé—´å ç½®åˆ†æSQL...")
        print(f"ğŸ’¡ å¯ä»¥ä½¿ç”¨ Ctrl+C å®‰å…¨é€€å‡º")
        analysis_start_time = datetime.now()
        check_shutdown()  # æ‰§è¡Œå‰æ£€æŸ¥
        
        with engine.connect() as conn:
            current_connection = conn  # ä¿å­˜è¿æ¥å¼•ç”¨
            
            conn.execute(text(analysis_sql))
            check_shutdown()  # SQLæ‰§è¡Œåæ£€æŸ¥
            
            conn.commit()
            print(f"âœ… SQLæ‰§è¡Œå®Œæˆï¼Œæ­£åœ¨ç»Ÿè®¡ç»“æœ...")
            current_connection = None  # æ¸…é™¤è¿æ¥å¼•ç”¨
            
            # è·å–ç»“æœç»Ÿè®¡
            count_sql = text(f"SELECT COUNT(*) FROM {analysis_table} WHERE analysis_id = '{analysis_id}';")
            count_result = conn.execute(count_sql)
            inserted_count = count_result.scalar()
            
            print(f"âœ… å ç½®åˆ†æå®Œæˆï¼Œå‘ç° {inserted_count} ä¸ªé‡å çƒ­ç‚¹")
            
            if inserted_count > 0:
                # æ˜¾ç¤ºTOPç»“æœ
                summary_sql = text(f"""
                    SELECT 
                        hotspot_rank,
                        overlap_count,
                        ROUND(total_overlap_area::numeric, 4) as total_overlap_area,
                        subdataset_count,
                        scene_count
                    FROM {analysis_table}
                    WHERE analysis_id = '{analysis_id}'
                    ORDER BY hotspot_rank
                    LIMIT 5;
                """)
                
                result_df = pd.read_sql(summary_sql, engine)
                print(f"\nğŸ“Š TOP 5 é‡å çƒ­ç‚¹:")
                print(result_df.to_string(index=False))
                
                # åˆ›å»ºQGISè§†å›¾
                print(f"\nğŸ¨ åˆ›å»ºQGISè§†å›¾...")
                qgis_view = "qgis_bbox_overlap_hotspots"
                
                view_sql = f"""
                CREATE OR REPLACE VIEW {qgis_view} AS
                SELECT 
                    id as qgis_id,
                    analysis_id,
                    hotspot_rank,
                    overlap_count,
                    total_overlap_area,
                    subdataset_count,
                    scene_count,
                    involved_subdatasets,
                    involved_scenes,
                    CASE 
                        WHEN overlap_count >= 10 THEN 'High Density'
                        WHEN overlap_count >= 5 THEN 'Medium Density'
                        ELSE 'Low Density'
                    END as density_level,
                    geometry,
                    created_at
                FROM {analysis_table}
                WHERE analysis_type = 'bbox_overlap'
                ORDER BY hotspot_rank;
                """
                
                conn.execute(text(view_sql))
                conn.commit()
                print(f"âœ… QGISè§†å›¾ {qgis_view} åˆ›å»ºæˆåŠŸ")
                
                # è¾“å‡ºQGISè¿æ¥ä¿¡æ¯
                print(f"\nğŸ¯ QGISå¯è§†åŒ–æŒ‡å¯¼")
                print(f"=" * 40)
                print(f"ğŸ“‹ æ•°æ®åº“è¿æ¥ä¿¡æ¯:")
                print(f"   host: local_pg")
                print(f"   port: 5432") 
                print(f"   database: postgres")
                print(f"   username: postgres")
                print(f"")
                print(f"ğŸ“Š æ¨èåŠ è½½çš„å›¾å±‚:")
                print(f"   1. {view_name} - æ‰€æœ‰bboxæ•°æ®ï¼ˆåº•å›¾ï¼‰")
                print(f"   2. {qgis_view} - é‡å çƒ­ç‚¹åŒºåŸŸ")
                print(f"")
                print(f"ğŸ¨ å¯è§†åŒ–å»ºè®®:")
                print(f"   â€¢ ä¸»é”®: qgis_id")
                print(f"   â€¢ å‡ ä½•åˆ—: geometry")
                print(f"   â€¢ æŒ‰ density_level å­—æ®µè®¾ç½®é¢œè‰²")
                print(f"   â€¢ æ˜¾ç¤º overlap_count æ ‡ç­¾")
                print(f"   â€¢ ä½¿ç”¨ analysis_id = '{analysis_id}' è¿‡æ»¤")
                
            else:
                print(f"âš ï¸ æœªå‘ç°é‡å çƒ­ç‚¹ï¼Œå»ºè®®:")
                print(f"   â€¢ é™ä½ --min-overlap-area é˜ˆå€¼")
                print(f"   â€¢ æ£€æŸ¥æ•°æ®æ˜¯å¦åœ¨åŒä¸€åŒºåŸŸ")
                print(f"   â€¢ å°è¯•ä¸åŒçš„åŸå¸‚è¿‡æ»¤æ¡ä»¶")
        
        print(f"\nâœ… åˆ†æå®Œæˆï¼åˆ†æID: {analysis_id}")
        
    except Exception as e:
        print(f"\nâŒ åˆ†æå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
