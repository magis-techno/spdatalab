#!/usr/bin/env python3
"""
Dockerå…¼å®¹çš„bboxå ç½®åˆ†æå¯åŠ¨è„šæœ¬

è¿™ä¸ªè„šæœ¬ä¸“é—¨ä¸ºDockerç¯å¢ƒè®¾è®¡ï¼Œè‡ªåŠ¨å¤„ç†è·¯å¾„å’Œä¾èµ–å¯¼å…¥é—®é¢˜ã€‚

ä½¿ç”¨æ–¹æ³•ï¼š
    # åœ¨Dockerå®¹å™¨ä¸­è¿è¡Œ
    python examples/dataset/bbox_examples/run_overlap_analysis.py

    # å¸¦å‚æ•°è¿è¡Œ
    python examples/dataset/bbox_examples/run_overlap_analysis.py \
        --city beijing --refresh-view --top-n 15
"""

import sys
import os
from pathlib import Path

def setup_environment():
    """è®¾ç½®è¿è¡Œç¯å¢ƒï¼Œå¤„ç†è·¯å¾„å’Œå¯¼å…¥é—®é¢˜"""
    
    # è·å–é¡¹ç›®æ ¹ç›®å½•
    script_path = Path(__file__).resolve()
    project_root = script_path.parent.parent.parent
    
    print(f"ğŸ”§ è„šæœ¬ä½ç½®: {script_path}")
    print(f"ğŸ”§ é¡¹ç›®æ ¹ç›®å½•: {project_root}")
    
    # æ·»åŠ å¯èƒ½çš„è·¯å¾„
    paths_to_add = [
        str(project_root),
        str(project_root / "src"),
        "/workspace",
        "/workspace/src"
    ]
    
    for path in paths_to_add:
        if path not in sys.path:
            sys.path.insert(0, path)
    
    print(f"ğŸ”§ Pythonè·¯å¾„:")
    for i, path in enumerate(sys.path[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
        print(f"   {i}: {path}")
    
    # å°è¯•å¯¼å…¥æµ‹è¯•
    try:
        # å°è¯•æ–¹å¼1ï¼šç›´æ¥å¯¼å…¥
        from spdatalab.dataset.bbox import LOCAL_DSN
        print("âœ… å¯¼å…¥æ–¹å¼: ç›´æ¥å¯¼å…¥ spdatalab")
        return True
    except ImportError as e1:
        try:
            # å°è¯•æ–¹å¼2ï¼šä»srcå¯¼å…¥
            from src.spdatalab.dataset.bbox import LOCAL_DSN
            print("âœ… å¯¼å…¥æ–¹å¼: ä»srcå¯¼å…¥ spdatalab")
            return True
        except ImportError as e2:
            print(f"âŒ å¯¼å…¥å¤±è´¥:")
            print(f"   æ–¹å¼1é”™è¯¯: {e1}")
            print(f"   æ–¹å¼2é”™è¯¯: {e2}")
            
            # æ˜¾ç¤ºå½“å‰ç›®å½•ç»“æ„ä»¥ä¾›è°ƒè¯•
            print(f"\nğŸ” å½“å‰ç›®å½•ç»“æ„:")
            cwd = Path.cwd()
            print(f"   å½“å‰å·¥ä½œç›®å½•: {cwd}")
            
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨spdatalabæ¨¡å—
            possible_paths = [
                cwd / "spdatalab",
                cwd / "src" / "spdatalab", 
                project_root / "spdatalab",
                project_root / "src" / "spdatalab"
            ]
            
            for path in possible_paths:
                exists = path.exists()
                print(f"   {path}: {'å­˜åœ¨' if exists else 'ä¸å­˜åœ¨'}")
                
            return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ Dockerå…¼å®¹çš„BBoxå ç½®åˆ†æ")
    print("=" * 50)
    
    # è®¾ç½®ç¯å¢ƒ
    if not setup_environment():
        print("\nâŒ ç¯å¢ƒè®¾ç½®å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
        sys.exit(1)
    
    print("\nğŸš€ ç¯å¢ƒè®¾ç½®æˆåŠŸï¼Œå¼€å§‹å¯¼å…¥æ¨¡å—...")
    
    try:
        # å¯¼å…¥å¿…è¦çš„æ¨¡å—
        import argparse
        from datetime import datetime
        
        # å°è¯•å¯¼å…¥åˆ†æå™¨
        try:
            from spdatalab.dataset.bbox import (
                create_qgis_compatible_unified_view,
                list_bbox_tables,
                LOCAL_DSN
            )
        except ImportError:
            from src.spdatalab.dataset.bbox import (
                create_qgis_compatible_unified_view,
                list_bbox_tables,
                LOCAL_DSN
            )
        
        from sqlalchemy import create_engine, text
        import pandas as pd
        
        print("âœ… æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # è§£æå‘½ä»¤è¡Œå‚æ•°
        parser = argparse.ArgumentParser(description='Dockerå…¼å®¹çš„BBoxå ç½®åˆ†æ')
        parser.add_argument('--city', help='åŸå¸‚è¿‡æ»¤')
        parser.add_argument('--subdatasets', nargs='+', help='å­æ•°æ®é›†è¿‡æ»¤')
        parser.add_argument('--min-overlap-area', type=float, default=0.0001, help='æœ€å°é‡å é¢ç§¯é˜ˆå€¼')
        parser.add_argument('--top-n', type=int, default=15, help='è¿”å›çš„çƒ­ç‚¹æ•°é‡')
        parser.add_argument('--analysis-id', help='è‡ªå®šä¹‰åˆ†æID')
        parser.add_argument('--refresh-view', action='store_true', help='å¼ºåˆ¶åˆ·æ–°ç»Ÿä¸€è§†å›¾')
        parser.add_argument('--test-only', action='store_true', help='åªè¿è¡Œæµ‹è¯•ï¼Œä¸æ‰§è¡Œåˆ†æ')
        
        args = parser.parse_args()
        
        print(f"\nğŸ“‹ åˆ†æå‚æ•°:")
        print(f"   åŸå¸‚è¿‡æ»¤: {args.city}")
        print(f"   æœ€å°é‡å é¢ç§¯: {args.min_overlap_area}")
        print(f"   è¿”å›æ•°é‡: {args.top_n}")
        print(f"   å¼ºåˆ¶åˆ·æ–°è§†å›¾: {args.refresh_view}")
        
        # åˆ›å»ºæ•°æ®åº“è¿æ¥
        print(f"\nğŸ”Œ è¿æ¥æ•°æ®åº“...")
        engine = create_engine(LOCAL_DSN, future=True)
        
        with engine.connect() as conn:
            result = conn.execute(text("SELECT 1 as test;"))
            print(f"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
        
        # æ£€æŸ¥bboxè¡¨
        print(f"\nğŸ“Š æ£€æŸ¥bboxåˆ†è¡¨...")
        tables = list_bbox_tables(engine)
        bbox_tables = [t for t in tables if t.startswith('clips_bbox_') and t != 'clips_bbox']
        print(f"âœ… å‘ç° {len(bbox_tables)} ä¸ªbboxåˆ†è¡¨")
        
        if len(bbox_tables) == 0:
            print("âŒ æ²¡æœ‰å‘ç°bboxåˆ†è¡¨ï¼Œæ— æ³•æ‰§è¡Œåˆ†æ")
            return
        
        # æ£€æŸ¥ç»Ÿä¸€è§†å›¾
        print(f"\nğŸ” æ£€æŸ¥ç»Ÿä¸€è§†å›¾...")
        view_name = "clips_bbox_unified_qgis"
        
        check_view_sql = text(f"""
            SELECT EXISTS (
                SELECT FROM information_schema.views 
                WHERE table_schema = 'public' 
                AND table_name = '{view_name}'
            );
        """)
        
        with engine.connect() as conn:
            result = conn.execute(check_view_sql)
            view_exists = result.scalar()
            
            if not view_exists or args.refresh_view:
                if args.refresh_view:
                    print(f"ğŸ”„ å¼ºåˆ¶åˆ·æ–°æ¨¡å¼ï¼Œé‡æ–°åˆ›å»ºè§†å›¾...")
                else:
                    print(f"ğŸ“Œ è§†å›¾ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°è§†å›¾...")
                
                success = create_qgis_compatible_unified_view(engine, view_name)
                if not success:
                    print("âŒ ç»Ÿä¸€è§†å›¾åˆ›å»ºå¤±è´¥")
                    return
                print(f"âœ… ç»Ÿä¸€è§†å›¾åˆ›å»ºæˆåŠŸ")
            else:
                print(f"âœ… ç»Ÿä¸€è§†å›¾å·²å­˜åœ¨")
            
            # æ£€æŸ¥æ•°æ®é‡
            count_sql = text(f"SELECT COUNT(*) FROM {view_name};")
            count_result = conn.execute(count_sql)
            row_count = count_result.scalar()
            print(f"ğŸ“Š ç»Ÿä¸€è§†å›¾åŒ…å« {row_count:,} æ¡bboxè®°å½•")
            
            if row_count == 0:
                print("âš ï¸ ç»Ÿä¸€è§†å›¾ä¸ºç©ºï¼Œå¯èƒ½åˆ†è¡¨ä¸­æ²¡æœ‰æ•°æ®")
                return
        
        # å¦‚æœåªæ˜¯æµ‹è¯•æ¨¡å¼ï¼Œåˆ°è¿™é‡Œå°±ç»“æŸ
        if args.test_only:
            print(f"\nâœ… æµ‹è¯•æ¨¡å¼å®Œæˆï¼Œæ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼")
            print(f"ğŸ’¡ ç§»é™¤ --test-only å‚æ•°å¯ä»¥æ‰§è¡Œå®Œæ•´åˆ†æ")
            return
        
        # åˆ›å»ºåˆ†æç»“æœè¡¨
        print(f"\nğŸ› ï¸ å‡†å¤‡åˆ†æè¡¨...")
        
        analysis_table = "bbox_overlap_analysis_results"
        
        # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
        check_table_sql = text(f"""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_schema = 'public' 
                AND table_name = '{analysis_table}'
            );
        """)
        
        with engine.connect() as conn:
            result = conn.execute(check_table_sql)
            table_exists = result.scalar()
            
            if not table_exists:
                print(f"ğŸ“Œ åˆ†æè¡¨ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°è¡¨...")
                
                # ç›´æ¥ä½¿ç”¨å†…ç½®SQLåˆ›å»ºè¡¨
                create_sql = f"""
                CREATE TABLE {analysis_table} (
                    id SERIAL PRIMARY KEY,
                    analysis_id VARCHAR(100) NOT NULL,
                    analysis_type VARCHAR(50) DEFAULT 'bbox_overlap',
                    analysis_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    hotspot_rank INTEGER,
                    overlap_count INTEGER,
                    total_overlap_area NUMERIC,
                    subdataset_count INTEGER,
                    scene_count INTEGER,
                    involved_subdatasets TEXT[],
                    involved_scenes TEXT[],
                    analysis_params TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
                
                -- æ·»åŠ å‡ ä½•åˆ—
                SELECT AddGeometryColumn('public', '{analysis_table}', 'geometry', 4326, 'GEOMETRY', 2);
                
                -- åˆ›å»ºç´¢å¼•
                CREATE INDEX idx_{analysis_table}_analysis_id ON {analysis_table} (analysis_id);
                CREATE INDEX idx_{analysis_table}_rank ON {analysis_table} (hotspot_rank);
                CREATE INDEX idx_{analysis_table}_geom ON {analysis_table} USING GIST (geometry);
                """
                
                conn.execute(text(create_sql))
                conn.commit()
                print(f"âœ… åˆ†æè¡¨åˆ›å»ºæˆåŠŸ")
            else:
                print(f"âœ… åˆ†æè¡¨å·²å­˜åœ¨")
        
        # ç”Ÿæˆåˆ†æID
        if not args.analysis_id:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            analysis_id = f"overlap_docker_{timestamp}"
        else:
            analysis_id = args.analysis_id
        
        print(f"\nğŸš€ å¼€å§‹å ç½®åˆ†æ: {analysis_id}")
        
        # æ„å»ºè¿‡æ»¤æ¡ä»¶
        where_conditions = []
        if args.city:
            where_conditions.append(f"a.city_id = '{args.city}' AND b.city_id = '{args.city}'")
        
        if args.subdatasets:
            subdataset_list = "', '".join(args.subdatasets)
            where_conditions.append(f"a.subdataset_name IN ('{subdataset_list}') AND b.subdataset_name IN ('{subdataset_list}')")
        
        where_clause = "AND " + " AND ".join(where_conditions) if where_conditions else ""
        
        # æ‰§è¡Œåˆ†æ
        analysis_sql = f"""
        WITH overlapping_pairs AS (
            SELECT 
                a.qgis_id as bbox_a_id,
                b.qgis_id as bbox_b_id,
                a.subdataset_name as subdataset_a,
                b.subdataset_name as subdataset_b,
                a.scene_token as scene_a,
                b.scene_token as scene_b,
                ST_Intersection(a.geometry, b.geometry) as overlap_geometry,
                ST_Area(ST_Intersection(a.geometry, b.geometry)) as overlap_area
            FROM {view_name} a
            JOIN {view_name} b ON a.qgis_id < b.qgis_id
            WHERE ST_Intersects(a.geometry, b.geometry)
            AND ST_Area(ST_Intersection(a.geometry, b.geometry)) > {args.min_overlap_area}
            {where_clause}
        ),
        overlap_hotspots AS (
            SELECT 
                ST_Union(overlap_geometry) as hotspot_geometry,
                COUNT(*) as overlap_count,
                ARRAY_AGG(DISTINCT subdataset_a) || ARRAY_AGG(DISTINCT subdataset_b) as involved_subdatasets,
                ARRAY_AGG(DISTINCT scene_a) || ARRAY_AGG(DISTINCT scene_b) as involved_scenes,
                SUM(overlap_area) as total_overlap_area
            FROM overlapping_pairs
            GROUP BY ST_SnapToGrid(overlap_geometry, 0.001)
            HAVING COUNT(*) >= 2
        )
        INSERT INTO {analysis_table} 
        (analysis_id, hotspot_rank, overlap_count, total_overlap_area, 
         subdataset_count, scene_count, involved_subdatasets, involved_scenes, geometry, analysis_params)
        SELECT 
            '{analysis_id}' as analysis_id,
            ROW_NUMBER() OVER (ORDER BY overlap_count DESC) as hotspot_rank,
            overlap_count,
            total_overlap_area,
            ARRAY_LENGTH(involved_subdatasets, 1) as subdataset_count,
            ARRAY_LENGTH(involved_scenes, 1) as scene_count,
            involved_subdatasets,
            involved_scenes,
            hotspot_geometry as geometry,
            '{{"city_filter": "{args.city}", "min_overlap_area": {args.min_overlap_area}, "top_n": {args.top_n}}}' as analysis_params
        FROM overlap_hotspots
        ORDER BY overlap_count DESC
        LIMIT {args.top_n};
        """
        
        with engine.connect() as conn:
            conn.execute(text(analysis_sql))
            conn.commit()
            
            # è·å–ç»“æœç»Ÿè®¡
            count_sql = text(f"SELECT COUNT(*) FROM {analysis_table} WHERE analysis_id = '{analysis_id}';")
            count_result = conn.execute(count_sql)
            inserted_count = count_result.scalar()
            
            print(f"âœ… å ç½®åˆ†æå®Œæˆï¼Œå‘ç° {inserted_count} ä¸ªé‡å çƒ­ç‚¹")
            
            if inserted_count > 0:
                # æ˜¾ç¤ºTOPç»“æœ
                summary_sql = text(f"""
                    SELECT 
                        hotspot_rank,
                        overlap_count,
                        ROUND(total_overlap_area::numeric, 4) as total_overlap_area,
                        subdataset_count,
                        scene_count
                    FROM {analysis_table}
                    WHERE analysis_id = '{analysis_id}'
                    ORDER BY hotspot_rank
                    LIMIT 5;
                """)
                
                result_df = pd.read_sql(summary_sql, engine)
                print(f"\nğŸ“Š TOP 5 é‡å çƒ­ç‚¹:")
                print(result_df.to_string(index=False))
                
                # åˆ›å»ºQGISè§†å›¾
                print(f"\nğŸ¨ åˆ›å»ºQGISè§†å›¾...")
                qgis_view = "qgis_bbox_overlap_hotspots"
                
                view_sql = f"""
                CREATE OR REPLACE VIEW {qgis_view} AS
                SELECT 
                    id as qgis_id,
                    analysis_id,
                    hotspot_rank,
                    overlap_count,
                    total_overlap_area,
                    subdataset_count,
                    scene_count,
                    involved_subdatasets,
                    involved_scenes,
                    CASE 
                        WHEN overlap_count >= 10 THEN 'High Density'
                        WHEN overlap_count >= 5 THEN 'Medium Density'
                        ELSE 'Low Density'
                    END as density_level,
                    geometry,
                    created_at
                FROM {analysis_table}
                WHERE analysis_type = 'bbox_overlap'
                ORDER BY hotspot_rank;
                """
                
                conn.execute(text(view_sql))
                conn.commit()
                print(f"âœ… QGISè§†å›¾ {qgis_view} åˆ›å»ºæˆåŠŸ")
                
                # è¾“å‡ºQGISè¿æ¥ä¿¡æ¯
                print(f"\nğŸ¯ QGISå¯è§†åŒ–æŒ‡å¯¼")
                print(f"=" * 40)
                print(f"ğŸ“‹ æ•°æ®åº“è¿æ¥ä¿¡æ¯:")
                print(f"   host: local_pg")
                print(f"   port: 5432") 
                print(f"   database: postgres")
                print(f"   username: postgres")
                print(f"")
                print(f"ğŸ“Š æ¨èåŠ è½½çš„å›¾å±‚:")
                print(f"   1. {view_name} - æ‰€æœ‰bboxæ•°æ®ï¼ˆåº•å›¾ï¼‰")
                print(f"   2. {qgis_view} - é‡å çƒ­ç‚¹åŒºåŸŸ")
                print(f"")
                print(f"ğŸ¨ å¯è§†åŒ–å»ºè®®:")
                print(f"   â€¢ ä¸»é”®: qgis_id")
                print(f"   â€¢ å‡ ä½•åˆ—: geometry")
                print(f"   â€¢ æŒ‰ density_level å­—æ®µè®¾ç½®é¢œè‰²")
                print(f"   â€¢ æ˜¾ç¤º overlap_count æ ‡ç­¾")
                print(f"   â€¢ ä½¿ç”¨ analysis_id = '{analysis_id}' è¿‡æ»¤")
                
            else:
                print(f"âš ï¸ æœªå‘ç°é‡å çƒ­ç‚¹ï¼Œå»ºè®®:")
                print(f"   â€¢ é™ä½ --min-overlap-area é˜ˆå€¼")
                print(f"   â€¢ æ£€æŸ¥æ•°æ®æ˜¯å¦åœ¨åŒä¸€åŒºåŸŸ")
                print(f"   â€¢ å°è¯•ä¸åŒçš„åŸå¸‚è¿‡æ»¤æ¡ä»¶")
        
        print(f"\nâœ… åˆ†æå®Œæˆï¼åˆ†æID: {analysis_id}")
        
    except Exception as e:
        print(f"\nâŒ åˆ†æå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
