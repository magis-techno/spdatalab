#!/usr/bin/env python3
"""
Dockerå…¼å®¹çš„bboxå ç½®åˆ†æå¯åŠ¨è„šæœ¬

è¿™ä¸ªè„šæœ¬ä¸“é—¨ä¸ºDockerç¯å¢ƒè®¾è®¡ï¼Œè‡ªåŠ¨å¤„ç†è·¯å¾„å’Œä¾èµ–å¯¼å…¥é—®é¢˜ã€‚

ä½¿ç”¨æ–¹æ³•ï¼š
    # åœ¨Dockerå®¹å™¨ä¸­è¿è¡Œ
    python examples/dataset/bbox_examples/run_overlap_analysis.py

    # å¸¦å‚æ•°è¿è¡Œ
    python examples/dataset/bbox_examples/run_overlap_analysis.py \
        --city beijing --refresh-view --top-n 15
"""

import sys
import os
import signal
import atexit
from pathlib import Path

def setup_environment():
    """è®¾ç½®è¿è¡Œç¯å¢ƒï¼Œå¤„ç†è·¯å¾„å’Œå¯¼å…¥é—®é¢˜"""
    
    # è·å–é¡¹ç›®æ ¹ç›®å½•
    script_path = Path(__file__).resolve()
    project_root = script_path.parent.parent.parent
    
    print(f"ğŸ”§ è„šæœ¬ä½ç½®: {script_path}")
    print(f"ğŸ”§ é¡¹ç›®æ ¹ç›®å½•: {project_root}")
    
    # æ·»åŠ å¯èƒ½çš„è·¯å¾„
    paths_to_add = [
        str(project_root),
        str(project_root / "src"),
        "/workspace",
        "/workspace/src"
    ]
    
    for path in paths_to_add:
        if path not in sys.path:
            sys.path.insert(0, path)
    
    print(f"ğŸ”§ Pythonè·¯å¾„:")
    for i, path in enumerate(sys.path[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
        print(f"   {i}: {path}")
    
    # å°è¯•å¯¼å…¥æµ‹è¯•
    try:
        # å°è¯•æ–¹å¼1ï¼šç›´æ¥å¯¼å…¥
        from spdatalab.dataset.bbox import LOCAL_DSN
        print("âœ… å¯¼å…¥æ–¹å¼: ç›´æ¥å¯¼å…¥ spdatalab")
        return True
    except ImportError as e1:
        try:
            # å°è¯•æ–¹å¼2ï¼šä»srcå¯¼å…¥
            from src.spdatalab.dataset.bbox import LOCAL_DSN
            print("âœ… å¯¼å…¥æ–¹å¼: ä»srcå¯¼å…¥ spdatalab")
            return True
        except ImportError as e2:
            print(f"âŒ å¯¼å…¥å¤±è´¥:")
            print(f"   æ–¹å¼1é”™è¯¯: {e1}")
            print(f"   æ–¹å¼2é”™è¯¯: {e2}")
            
            # æ˜¾ç¤ºå½“å‰ç›®å½•ç»“æ„ä»¥ä¾›è°ƒè¯•
            print(f"\nğŸ” å½“å‰ç›®å½•ç»“æ„:")
            cwd = Path.cwd()
            print(f"   å½“å‰å·¥ä½œç›®å½•: {cwd}")
            
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨spdatalabæ¨¡å—
            possible_paths = [
                cwd / "spdatalab",
                cwd / "src" / "spdatalab", 
                project_root / "spdatalab",
                project_root / "src" / "spdatalab"
            ]
            
            for path in possible_paths:
                exists = path.exists()
                print(f"   {path}: {'å­˜åœ¨' if exists else 'ä¸å­˜åœ¨'}")
                
            return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ Dockerå…¼å®¹çš„BBoxå ç½®åˆ†æ")
    print("=" * 50)
    
    # è®¾ç½®ä¼˜é›…é€€å‡ºå¤„ç†
    shutdown_requested = False
    current_connection = None
    analysis_start_time = None
    
    def signal_handler(signum, frame):
        nonlocal shutdown_requested, current_connection, analysis_start_time
        print(f"\n\nğŸ›‘ æ”¶åˆ°é€€å‡ºä¿¡å· ({signal.Signals(signum).name})")
        shutdown_requested = True
        print(f"ğŸ”„ æ­£åœ¨å®‰å…¨é€€å‡º...")
        
        if analysis_start_time:
            elapsed = datetime.now() - analysis_start_time
            print(f"â±ï¸ å·²è¿è¡Œæ—¶é—´: {elapsed}")
        
        if current_connection:
            try:
                current_connection.close()
                print(f"âœ… æ•°æ®åº“è¿æ¥å·²å…³é—­")
            except Exception as e:
                print(f"âš ï¸ å…³é—­è¿æ¥æ—¶å‡ºé”™: {e}")
        
        print(f"âœ… ä¼˜é›…é€€å‡ºå®Œæˆ")
        sys.exit(0)
    
    def check_shutdown():
        if shutdown_requested:
            print(f"ğŸ›‘ æ£€æµ‹åˆ°é€€å‡ºè¯·æ±‚ï¼Œåœæ­¢æ‰§è¡Œ")
            sys.exit(0)
    
    # æ³¨å†Œä¿¡å·å¤„ç†å™¨
    try:
        signal.signal(signal.SIGINT, signal_handler)   # Ctrl+C
        signal.signal(signal.SIGTERM, signal_handler)  # ç»ˆæ­¢ä¿¡å·
        if hasattr(signal, 'SIGBREAK'):  # Windows
            signal.signal(signal.SIGBREAK, signal_handler)
    except ValueError:
        print("âš ï¸ æ— æ³•æ³¨å†Œä¿¡å·å¤„ç†å™¨")
    
    # è®¾ç½®ç¯å¢ƒ
    if not setup_environment():
        print("\nâŒ ç¯å¢ƒè®¾ç½®å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
        sys.exit(1)
    
    print("\nğŸš€ ç¯å¢ƒè®¾ç½®æˆåŠŸï¼Œå¼€å§‹å¯¼å…¥æ¨¡å—...")
    
    try:
        # å¯¼å…¥å¿…è¦çš„æ¨¡å—
        import argparse
        from datetime import datetime
        
        # å°è¯•å¯¼å…¥åˆ†æå™¨ï¼ˆä½¿ç”¨ç»Ÿä¸€è§†å›¾ï¼‰
        try:
            from spdatalab.dataset.bbox import (
                create_unified_view,
                list_bbox_tables,
                LOCAL_DSN
            )
        except ImportError:
            from src.spdatalab.dataset.bbox import (
                create_unified_view,
                list_bbox_tables,
                LOCAL_DSN
            )
        
        from sqlalchemy import create_engine, text
        import pandas as pd
        
        print("âœ… æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # è§£æå‘½ä»¤è¡Œå‚æ•°
        parser = argparse.ArgumentParser(description='Dockerå…¼å®¹çš„BBoxå ç½®åˆ†æï¼ˆä¼˜åŒ–ç‰ˆï¼‰')
        parser.add_argument('--city', required=False, help='åŸå¸‚è¿‡æ»¤ï¼ˆå¼ºçƒˆå»ºè®®æŒ‡å®šä»¥é¿å…æ€§èƒ½é—®é¢˜ï¼‰')
        parser.add_argument('--subdatasets', nargs='+', help='å­æ•°æ®é›†è¿‡æ»¤')
        parser.add_argument('--min-overlap-area', type=float, default=0.0, help='æœ€å°é‡å é¢ç§¯é˜ˆå€¼ï¼ˆintersect-onlyæ¨¡å¼ä¸‹å¿½ç•¥ï¼‰')
        parser.add_argument('--top-n', type=int, default=15, help='è¿”å›çš„çƒ­ç‚¹æ•°é‡')
        parser.add_argument('--analysis-id', help='è‡ªå®šä¹‰åˆ†æID')
        parser.add_argument('--refresh-view', action='store_true', help='å¼ºåˆ¶åˆ·æ–°ç»Ÿä¸€è§†å›¾')
        parser.add_argument('--test-only', action='store_true', help='åªè¿è¡Œæµ‹è¯•ï¼Œä¸æ‰§è¡Œåˆ†æ')
        parser.add_argument('--suggest-city', action='store_true', help='æ˜¾ç¤ºåŸå¸‚åˆ†æå»ºè®®å¹¶é€€å‡º')
        parser.add_argument('--estimate-time', action='store_true', help='ä¼°ç®—åˆ†ææ—¶é—´å¹¶é€€å‡º')
        parser.add_argument('--intersect-only', action='store_true', help='ğŸš€ å¿«é€Ÿæ¨¡å¼ï¼šåªè¦ç›¸äº¤å°±ç®—é‡å ï¼Œå¤§å¹…æå‡æ€§èƒ½ï¼ˆæ¨èï¼‰')
        
        args = parser.parse_args()
        
        print(f"\nğŸ“‹ åˆ†æå‚æ•°:")
        print(f"   åŸå¸‚è¿‡æ»¤: {args.city}")
        print(f"   æœ€å°é‡å é¢ç§¯: {args.min_overlap_area}")
        print(f"   è¿”å›æ•°é‡: {args.top_n}")
        print(f"   å¼ºåˆ¶åˆ·æ–°è§†å›¾: {args.refresh_view}")
        print(f"   å¿«é€Ÿæ¨¡å¼: {args.intersect_only}")
        if args.intersect_only:
            print(f"   ğŸ¯ ä½¿ç”¨å¿«é€Ÿæ¨¡å¼ï¼Œå°†è·³è¿‡é¢ç§¯è®¡ç®—ä»¥æå‡æ€§èƒ½")
        
        # åˆ›å»ºæ•°æ®åº“è¿æ¥
        print(f"\nğŸ”Œ è¿æ¥æ•°æ®åº“...")
        engine = create_engine(LOCAL_DSN, future=True)
        
        with engine.connect() as conn:
            result = conn.execute(text("SELECT 1 as test;"))
            print(f"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
        
        # æ£€æŸ¥bboxè¡¨
        print(f"\nğŸ“Š æ£€æŸ¥bboxåˆ†è¡¨...")
        tables = list_bbox_tables(engine)
        bbox_tables = [t for t in tables if t.startswith('clips_bbox_') and t != 'clips_bbox']
        print(f"âœ… å‘ç° {len(bbox_tables)} ä¸ªbboxåˆ†è¡¨")
        
        if len(bbox_tables) == 0:
            print("âŒ æ²¡æœ‰å‘ç°bboxåˆ†è¡¨ï¼Œæ— æ³•æ‰§è¡Œåˆ†æ")
            return
        
        # æ£€æŸ¥ç»Ÿä¸€è§†å›¾ï¼ˆä½¿ç”¨æ ‡å‡†è§†å›¾ï¼‰
        print(f"\nğŸ” æ£€æŸ¥ç»Ÿä¸€è§†å›¾...")
        view_name = "clips_bbox_unified"
        
        check_view_sql = text(f"""
            SELECT EXISTS (
                SELECT FROM information_schema.views 
                WHERE table_schema = 'public' 
                AND table_name = '{view_name}'
            );
        """)
        
        # åˆ›å»ºæŒä¹…è¿æ¥ç”¨äºæ•´ä¸ªåˆ†æè¿‡ç¨‹
        conn = engine.connect()
        
        try:
            result = conn.execute(check_view_sql)
            view_exists = result.scalar()
            
            if not view_exists or args.refresh_view:
                if args.refresh_view:
                    print(f"ğŸ”„ å¼ºåˆ¶åˆ·æ–°æ¨¡å¼ï¼Œé‡æ–°åˆ›å»ºè§†å›¾...")
                else:
                    print(f"ğŸ“Œ è§†å›¾ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°è§†å›¾...")
                
                success = create_unified_view(engine, view_name)
                if not success:
                    print("âŒ ç»Ÿä¸€è§†å›¾åˆ›å»ºå¤±è´¥")
                    return
                print(f"âœ… ç»Ÿä¸€è§†å›¾åˆ›å»ºæˆåŠŸ")
            else:
                print(f"âœ… ç»Ÿä¸€è§†å›¾å·²å­˜åœ¨")
            
            # æ£€æŸ¥æ•°æ®é‡
            count_sql = text(f"SELECT COUNT(*) FROM {view_name};")
            count_result = conn.execute(count_sql)
            row_count = count_result.scalar()
            print(f"ğŸ“Š ç»Ÿä¸€è§†å›¾åŒ…å« {row_count:,} æ¡bboxè®°å½•")
            
            if row_count == 0:
                print("âš ï¸ ç»Ÿä¸€è§†å›¾ä¸ºç©ºï¼Œå¯èƒ½åˆ†è¡¨ä¸­æ²¡æœ‰æ•°æ®")
                return
            
            # å¦‚æœåªæ˜¯æµ‹è¯•æ¨¡å¼ï¼Œåˆ°è¿™é‡Œå°±ç»“æŸ
            if args.test_only:
                print(f"\nâœ… æµ‹è¯•æ¨¡å¼å®Œæˆï¼Œæ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼")
                print(f"ğŸ’¡ ç§»é™¤ --test-only å‚æ•°å¯ä»¥æ‰§è¡Œå®Œæ•´åˆ†æ")
                return
            
            # å¦‚æœç”¨æˆ·æƒ³æŸ¥çœ‹åŸå¸‚å»ºè®®
            if args.suggest_city:
                print(f"\nğŸ™ï¸ åŸå¸‚åˆ†æå»ºè®®")
                print("-" * 40)
                
                city_stats_sql = f"""
                SELECT 
                    city_id,
                    COUNT(*) as total_count,
                    COUNT(*) FILTER (WHERE all_good = true) as good_count,
                    ROUND(100.0 * COUNT(*) FILTER (WHERE all_good = true) / COUNT(*), 1) as good_percent,
                    CASE 
                        WHEN COUNT(*) FILTER (WHERE all_good = true) > 50000 THEN '> 10åˆ†é’Ÿ'
                        WHEN COUNT(*) FILTER (WHERE all_good = true) > 10000 THEN '2-10åˆ†é’Ÿ'
                        WHEN COUNT(*) FILTER (WHERE all_good = true) > 1000 THEN '< 2åˆ†é’Ÿ'
                        ELSE '< 30ç§’'
                    END as estimated_time,
                    CASE 
                        WHEN COUNT(*) FILTER (WHERE all_good = true) BETWEEN 1000 AND 20000 AND 
                             100.0 * COUNT(*) FILTER (WHERE all_good = true) / COUNT(*) > 90 THEN 'â­â­â­ æ¨è'
                        WHEN COUNT(*) FILTER (WHERE all_good = true) BETWEEN 500 AND 50000 AND 
                             100.0 * COUNT(*) FILTER (WHERE all_good = true) / COUNT(*) > 85 THEN 'â­â­ è¾ƒå¥½'
                        WHEN COUNT(*) FILTER (WHERE all_good = true) > 100 THEN 'â­ å¯ç”¨'
                        ELSE 'âŒ ä¸å»ºè®®'
                    END as recommendation
                FROM {view_name}
                WHERE city_id IS NOT NULL
                GROUP BY city_id
                HAVING COUNT(*) FILTER (WHERE all_good = true) > 0
                ORDER BY 
                    CASE 
                        WHEN COUNT(*) FILTER (WHERE all_good = true) BETWEEN 1000 AND 20000 AND 
                             100.0 * COUNT(*) FILTER (WHERE all_good = true) / COUNT(*) > 90 THEN 1
                        WHEN COUNT(*) FILTER (WHERE all_good = true) BETWEEN 500 AND 50000 AND 
                             100.0 * COUNT(*) FILTER (WHERE all_good = true) / COUNT(*) > 85 THEN 2
                        WHEN COUNT(*) FILTER (WHERE all_good = true) > 100 THEN 3
                        ELSE 4
                    END,
                    COUNT(*) FILTER (WHERE all_good = true) DESC;
                """
                
                city_df = pd.read_sql(city_stats_sql, engine)
                if not city_df.empty:
                    print("ğŸ“Š åŸå¸‚åˆ†æå»ºè®®è¡¨:")
                    print(city_df.to_string(index=False))
                    
                    recommended = city_df[city_df['recommendation'].str.contains('â­â­â­')]
                    if not recommended.empty:
                        best_city = recommended.iloc[0]['city_id']
                        print(f"\nğŸ’¡ æ¨èåŸå¸‚: {best_city}")
                        print(f"   - å»ºè®®å‘½ä»¤: --city {best_city}")
                else:
                    print("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„åŸå¸‚æ•°æ®")
                return
            
            # å¦‚æœç”¨æˆ·æƒ³ä¼°ç®—æ—¶é—´
            if args.estimate_time:
                print(f"\nâ±ï¸ åˆ†ææ—¶é—´ä¼°ç®—")
                print("-" * 40)
                
                where_condition = f"WHERE city_id = '{args.city}'" if args.city else "WHERE city_id IS NOT NULL"
                time_estimate_sql = f"""
                SELECT 
                    COUNT(*) FILTER (WHERE all_good = true) as analyzable_count,
                    CASE 
                        WHEN COUNT(*) FILTER (WHERE all_good = true) > 100000 THEN 'âš ï¸ å¾ˆé•¿ (>30åˆ†é’Ÿ)'
                        WHEN COUNT(*) FILTER (WHERE all_good = true) > 50000 THEN 'â³ è¾ƒé•¿ (10-30åˆ†é’Ÿ)'
                        WHEN COUNT(*) FILTER (WHERE all_good = true) > 10000 THEN 'â° ä¸­ç­‰ (2-10åˆ†é’Ÿ)'
                        WHEN COUNT(*) FILTER (WHERE all_good = true) > 1000 THEN 'âš¡ è¾ƒå¿« (<2åˆ†é’Ÿ)'
                        ELSE 'ğŸš€ å¾ˆå¿« (<30ç§’)'
                    END as time_estimate,
                    '{args.city if args.city else "å…¨éƒ¨åŸå¸‚"}' as scope
                FROM {view_name}
                {where_condition};
                """
                
                estimate_result = conn.execute(text(time_estimate_sql)).fetchone()
                print(f"ğŸ“Š åˆ†æèŒƒå›´: {estimate_result.scope}")
                print(f"ğŸ“ˆ å¯åˆ†ææ•°æ®: {estimate_result.analyzable_count:,} ä¸ªbbox")
                print(f"â±ï¸ é¢„ä¼°æ—¶é—´: {estimate_result.time_estimate}")
                
                if estimate_result.analyzable_count > 50000:
                    print(f"ğŸ’¡ å»ºè®®: æ•°æ®é‡è¾ƒå¤§ï¼Œå»ºè®®æŒ‡å®šå…·ä½“åŸå¸‚è¿›è¡Œåˆ†æ")
                return
        
        finally:
            # ç¡®ä¿è¿æ¥æ€»æ˜¯ä¼šè¢«å…³é—­
            if conn:
                conn.close()
        
        # åˆ›å»ºåˆ†æç»“æœè¡¨
        print(f"\nğŸ› ï¸ å‡†å¤‡åˆ†æè¡¨...")
        
        analysis_table = "bbox_overlap_analysis_results"
        
        # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
        check_table_sql = text(f"""
            SELECT EXISTS (
                SELECT FROM information_schema.tables 
                WHERE table_schema = 'public' 
                AND table_name = '{analysis_table}'
            );
        """)
        
        with engine.connect() as conn:
            result = conn.execute(check_table_sql)
            table_exists = result.scalar()
            
            if not table_exists:
                print(f"ğŸ“Œ åˆ†æè¡¨ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°è¡¨...")
                
                # ç›´æ¥ä½¿ç”¨å†…ç½®SQLåˆ›å»ºè¡¨
                create_sql = f"""
                CREATE TABLE {analysis_table} (
                    id SERIAL PRIMARY KEY,
                    analysis_id VARCHAR(100) NOT NULL,
                    analysis_type VARCHAR(50) DEFAULT 'bbox_overlap',
                    analysis_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    hotspot_rank INTEGER,
                    overlap_count INTEGER,
                    total_overlap_area NUMERIC,
                    subdataset_count INTEGER,
                    scene_count INTEGER,
                    involved_subdatasets TEXT[],
                    involved_scenes TEXT[],
                    analysis_params TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
                
                -- æ·»åŠ å‡ ä½•åˆ—
                SELECT AddGeometryColumn('public', '{analysis_table}', 'geometry', 4326, 'GEOMETRY', 2);
                
                -- åˆ›å»ºç´¢å¼•
                CREATE INDEX idx_{analysis_table}_analysis_id ON {analysis_table} (analysis_id);
                CREATE INDEX idx_{analysis_table}_rank ON {analysis_table} (hotspot_rank);
                CREATE INDEX idx_{analysis_table}_geom ON {analysis_table} USING GIST (geometry);
                """
                
                conn.execute(text(create_sql))
                conn.commit()
                print(f"âœ… åˆ†æè¡¨åˆ›å»ºæˆåŠŸ")
            else:
                print(f"âœ… åˆ†æè¡¨å·²å­˜åœ¨")
        
        # ç”Ÿæˆåˆ†æID
        if not args.analysis_id:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            analysis_id = f"overlap_docker_{timestamp}"
        else:
            analysis_id = args.analysis_id
        
        print(f"\nğŸš€ å¼€å§‹å ç½®åˆ†æ: {analysis_id}")
        
        # ğŸš¨ å¼ºåˆ¶åŸå¸‚è¿‡æ»¤æœºåˆ¶
        if not args.city:
            print("âŒ é”™è¯¯: å¿…é¡»æŒ‡å®šåŸå¸‚è¿‡æ»¤æ¡ä»¶ä»¥é¿å…æ€§èƒ½é—®é¢˜")
            print("ğŸ’¡ ä½¿ç”¨ --suggest-city æŸ¥çœ‹æ¨èçš„åŸå¸‚")
            print("ğŸ’¡ æˆ–ä½¿ç”¨ --city your_city_name æŒ‡å®šåŸå¸‚")
            print("ğŸ’¡ ç¤ºä¾‹: --city A72")
            return
        
        print(f"ğŸ™ï¸ åŸå¸‚è¿‡æ»¤: {args.city}")
        
        # æ„å»ºé¢å¤–è¿‡æ»¤æ¡ä»¶
        where_conditions = []
        if args.subdatasets:
            subdataset_list = "', '".join(args.subdatasets)
            where_conditions.append(f"a.subdataset_name IN ('{subdataset_list}') AND b.subdataset_name IN ('{subdataset_list}')")
            print(f"ğŸ“¦ å­æ•°æ®é›†è¿‡æ»¤: {len(args.subdatasets)} ä¸ª")
        
        where_clause = "AND " + " AND ".join(where_conditions) if where_conditions else ""
        
        # ğŸš€ æ‰§è¡Œä¼˜åŒ–åçš„åˆ†æSQL
        if args.intersect_only:
            # ğŸ¯ å¿«é€Ÿæ¨¡å¼ï¼šè·³è¿‡é¢ç§¯è®¡ç®—
            print(f"ğŸš€ ä½¿ç”¨å¿«é€Ÿæ¨¡å¼ï¼ˆintersect-onlyï¼‰ï¼Œå¤§å¹…æå‡æ€§èƒ½...")
            analysis_sql = f"""
            WITH candidate_pairs AS (
                SELECT 
                    a.id as bbox_a_id,
                    b.id as bbox_b_id,
                    a.subdataset_name as subdataset_a,
                    b.subdataset_name as subdataset_b,
                    a.scene_token as scene_a,
                    b.scene_token as scene_b
                FROM {view_name} a
                JOIN {view_name} b ON a.id < b.id
                WHERE a.city_id = '{args.city}'  -- ğŸš€ ä¼˜å…ˆè¿‡æ»¤åŸå¸‚
                AND b.city_id = '{args.city}'
                AND a.all_good = true  -- ğŸš€ ä¼˜å…ˆè¿‡æ»¤è´¨é‡
                AND b.all_good = true
                AND a.geometry && b.geometry  -- ğŸš€ å¿«é€Ÿè¾¹ç•Œæ¡†æ£€æŸ¥
                AND ST_Intersects(a.geometry, b.geometry)  -- ç²¾ç¡®ç›¸äº¤æ£€æŸ¥
                AND NOT ST_Equals(a.geometry, b.geometry)
                {where_clause}
            ),
            overlapping_areas AS (
                SELECT 
                    *,
                    -- ğŸ¯ ç®€åŒ–æ¨¡å¼ï¼šä½¿ç”¨è™šæ‹Ÿå‡ ä½•å’Œé¢ç§¯
                    ST_Point(0, 0) as overlap_geometry,
                    1.0 as overlap_area
                FROM candidate_pairs
            ),
            overlap_hotspots AS (
                SELECT 
                    ST_Point(0, 0) as hotspot_geometry,
                    COUNT(*) as overlap_count,
                    ARRAY_AGG(DISTINCT subdataset_a) || ARRAY_AGG(DISTINCT subdataset_b) as involved_subdatasets,
                    ARRAY_AGG(DISTINCT scene_a) || ARRAY_AGG(DISTINCT scene_b) as involved_scenes,
                    SUM(overlap_area) as total_overlap_area
                FROM overlapping_areas
                GROUP BY 1
                HAVING COUNT(*) >= 1
            )
            INSERT INTO {analysis_table} 
            (analysis_id, hotspot_rank, overlap_count, total_overlap_area, 
             subdataset_count, scene_count, involved_subdatasets, involved_scenes, geometry, analysis_params)
            SELECT 
                '{analysis_id}' as analysis_id,
                ROW_NUMBER() OVER (ORDER BY overlap_count DESC) as hotspot_rank,
                overlap_count,
                total_overlap_area,
                ARRAY_LENGTH(involved_subdatasets, 1) as subdataset_count,
                ARRAY_LENGTH(involved_scenes, 1) as scene_count,
                involved_subdatasets,
                involved_scenes,
                hotspot_geometry as geometry,
                '{{"city_filter": "{args.city}", "min_overlap_area": {args.min_overlap_area}, "top_n": {args.top_n}, "intersect_only": true}}' as analysis_params
            FROM overlap_hotspots
            ORDER BY overlap_count DESC
            LIMIT {args.top_n};
            """
        else:
            # ğŸ“Š å®Œæ•´æ¨¡å¼ï¼šè®¡ç®—å®é™…é‡å å‡ ä½•å’Œé¢ç§¯
            print(f"ğŸ“Š ä½¿ç”¨å®Œæ•´æ¨¡å¼ï¼Œè®¡ç®—ç²¾ç¡®é‡å é¢ç§¯...")
            analysis_sql = f"""
            WITH intersections_precalc AS (
                SELECT 
                    a.id as bbox_a_id,
                    b.id as bbox_b_id,
                    a.subdataset_name as subdataset_a,
                    b.subdataset_name as subdataset_b,
                    a.scene_token as scene_a,
                    b.scene_token as scene_b,
                    ST_Intersection(a.geometry, b.geometry) as overlap_geometry
                FROM {view_name} a
                JOIN {view_name} b ON a.id < b.id
                WHERE a.city_id = '{args.city}'  -- ğŸš€ ä¼˜å…ˆè¿‡æ»¤åŸå¸‚
                AND b.city_id = '{args.city}'
                AND a.all_good = true  -- ğŸš€ ä¼˜å…ˆè¿‡æ»¤è´¨é‡
                AND b.all_good = true
                AND a.geometry && b.geometry  -- ğŸš€ å¿«é€Ÿè¾¹ç•Œæ¡†æ£€æŸ¥
                AND ST_Intersects(a.geometry, b.geometry)  -- ç²¾ç¡®ç›¸äº¤æ£€æŸ¥
                AND NOT ST_Equals(a.geometry, b.geometry)
                {where_clause}
            ),
            overlapping_areas AS (
                SELECT 
                    *,
                    overlap_geometry,
                    ST_Area(overlap_geometry) as overlap_area  -- ğŸ¯ åªè®¡ç®—ä¸€æ¬¡é¢ç§¯
                FROM intersections_precalc
                WHERE ST_Area(overlap_geometry) > {args.min_overlap_area}  -- é¢ç§¯è¿‡æ»¤åœ¨è¿™é‡Œè¿›è¡Œ
            ),
            overlap_hotspots AS (
                SELECT 
                    ST_Union(overlap_geometry) as hotspot_geometry,
                    COUNT(*) as overlap_count,
                    ARRAY_AGG(DISTINCT subdataset_a) || ARRAY_AGG(DISTINCT subdataset_b) as involved_subdatasets,
                    ARRAY_AGG(DISTINCT scene_a) || ARRAY_AGG(DISTINCT scene_b) as involved_scenes,
                    SUM(overlap_area) as total_overlap_area
                FROM overlapping_areas
                GROUP BY ST_SnapToGrid(overlap_geometry, 0.001)
                HAVING COUNT(*) >= 2
            )
            INSERT INTO {analysis_table} 
            (analysis_id, hotspot_rank, overlap_count, total_overlap_area, 
             subdataset_count, scene_count, involved_subdatasets, involved_scenes, geometry, analysis_params)
            SELECT 
                '{analysis_id}' as analysis_id,
                ROW_NUMBER() OVER (ORDER BY overlap_count DESC) as hotspot_rank,
                overlap_count,
                total_overlap_area,
                ARRAY_LENGTH(involved_subdatasets, 1) as subdataset_count,
                ARRAY_LENGTH(involved_scenes, 1) as scene_count,
                involved_subdatasets,
                involved_scenes,
                hotspot_geometry as geometry,
                '{{"city_filter": "{args.city}", "min_overlap_area": {args.min_overlap_area}, "top_n": {args.top_n}, "intersect_only": false}}' as analysis_params
            FROM overlap_hotspots
            ORDER BY overlap_count DESC
            LIMIT {args.top_n};
            """
        
        print(f"âš¡ æ‰§è¡Œç©ºé—´å ç½®åˆ†æSQL...")
        print(f"ğŸ’¡ å¯ä»¥ä½¿ç”¨ Ctrl+C å®‰å…¨é€€å‡º")
        analysis_start_time = datetime.now()
        check_shutdown()  # æ‰§è¡Œå‰æ£€æŸ¥
        
        with engine.connect() as conn:
            current_connection = conn  # ä¿å­˜è¿æ¥å¼•ç”¨
            
            conn.execute(text(analysis_sql))
            check_shutdown()  # SQLæ‰§è¡Œåæ£€æŸ¥
            
            conn.commit()
            print(f"âœ… SQLæ‰§è¡Œå®Œæˆï¼Œæ­£åœ¨ç»Ÿè®¡ç»“æœ...")
            current_connection = None  # æ¸…é™¤è¿æ¥å¼•ç”¨
            
            # è·å–ç»“æœç»Ÿè®¡
            count_sql = text(f"SELECT COUNT(*) FROM {analysis_table} WHERE analysis_id = '{analysis_id}';")
            count_result = conn.execute(count_sql)
            inserted_count = count_result.scalar()
            
            print(f"âœ… å ç½®åˆ†æå®Œæˆï¼Œå‘ç° {inserted_count} ä¸ªé‡å çƒ­ç‚¹")
            
            if inserted_count > 0:
                # æ˜¾ç¤ºTOPç»“æœ
                summary_sql = text(f"""
                    SELECT 
                        hotspot_rank,
                        overlap_count,
                        ROUND(total_overlap_area::numeric, 4) as total_overlap_area,
                        subdataset_count,
                        scene_count
                    FROM {analysis_table}
                    WHERE analysis_id = '{analysis_id}'
                    ORDER BY hotspot_rank
                    LIMIT 5;
                """)
                
                result_df = pd.read_sql(summary_sql, engine)
                print(f"\nğŸ“Š TOP 5 é‡å çƒ­ç‚¹:")
                print(result_df.to_string(index=False))
                
                # åˆ›å»ºQGISè§†å›¾
                print(f"\nğŸ¨ åˆ›å»ºQGISè§†å›¾...")
                qgis_view = "qgis_bbox_overlap_hotspots"
                
                view_sql = f"""
                CREATE OR REPLACE VIEW {qgis_view} AS
                SELECT 
                    id,
                    analysis_id,
                    hotspot_rank,
                    overlap_count,
                    total_overlap_area,
                    subdataset_count,
                    scene_count,
                    involved_subdatasets,
                    involved_scenes,
                    CASE 
                        WHEN overlap_count >= 10 THEN 'High Density'
                        WHEN overlap_count >= 5 THEN 'Medium Density'
                        ELSE 'Low Density'
                    END as density_level,
                    geometry,
                    created_at
                FROM {analysis_table}
                WHERE analysis_type = 'bbox_overlap'
                ORDER BY hotspot_rank;
                """
                
                conn.execute(text(view_sql))
                conn.commit()
                print(f"âœ… QGISè§†å›¾ {qgis_view} åˆ›å»ºæˆåŠŸ")
                
                # è¾“å‡ºQGISè¿æ¥ä¿¡æ¯
                print(f"\nğŸ¯ QGISå¯è§†åŒ–æŒ‡å¯¼")
                print(f"=" * 40)
                print(f"ğŸ“‹ æ•°æ®åº“è¿æ¥ä¿¡æ¯:")
                print(f"   host: local_pg")
                print(f"   port: 5432") 
                print(f"   database: postgres")
                print(f"   username: postgres")
                print(f"")
                print(f"ğŸ“Š æ¨èåŠ è½½çš„å›¾å±‚:")
                print(f"   1. {view_name} - æ‰€æœ‰bboxæ•°æ®ï¼ˆåº•å›¾ï¼‰")
                print(f"   2. {qgis_view} - é‡å çƒ­ç‚¹åŒºåŸŸ")
                print(f"")
                print(f"ğŸ¨ å¯è§†åŒ–å»ºè®®:")
                print(f"   â€¢ ä¸»é”®: id")
                print(f"   â€¢ å‡ ä½•åˆ—: geometry")
                print(f"   â€¢ æŒ‰ density_level å­—æ®µè®¾ç½®é¢œè‰²")
                print(f"   â€¢ æ˜¾ç¤º overlap_count æ ‡ç­¾")
                print(f"   â€¢ ä½¿ç”¨ analysis_id = '{analysis_id}' è¿‡æ»¤")
                
            else:
                print(f"âš ï¸ æœªå‘ç°é‡å çƒ­ç‚¹ï¼Œå»ºè®®:")
                print(f"   â€¢ é™ä½ --min-overlap-area é˜ˆå€¼")
                print(f"   â€¢ æ£€æŸ¥æ•°æ®æ˜¯å¦åœ¨åŒä¸€åŒºåŸŸ")
                print(f"   â€¢ å°è¯•ä¸åŒçš„åŸå¸‚è¿‡æ»¤æ¡ä»¶")
        
        print(f"\nâœ… åˆ†æå®Œæˆï¼åˆ†æID: {analysis_id}")
        
    except Exception as e:
        print(f"\nâŒ åˆ†æå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
