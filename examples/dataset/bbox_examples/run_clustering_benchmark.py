#!/usr/bin/env python3
"""
PGèšç±»æ€§èƒ½åŸºå‡†æµ‹è¯•è„šæœ¬
====================

è‡ªåŠ¨è¿è¡ŒPostgreSQLèšç±»æ€§èƒ½æµ‹è¯•å¹¶åˆ†æç»“æœ

ä½¿ç”¨æ–¹æ³•ï¼š
    python examples/dataset/bbox_examples/run_clustering_benchmark.py --city A263
"""

import sys
import time
from pathlib import Path
import argparse
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

try:
    from spdatalab.dataset.bbox import LOCAL_DSN
except ImportError:
    sys.path.insert(0, str(project_root / "src"))
    from spdatalab.dataset.bbox import LOCAL_DSN

from sqlalchemy import create_engine, text
import pandas as pd

def create_clustering_results_table(conn):
    """åˆ›å»ºèšç±»ç»“æœè¡¨"""
    create_table_sql = text("""
        CREATE TABLE IF NOT EXISTS clustering_benchmark_results (
            id SERIAL PRIMARY KEY,
            city_id VARCHAR(50),
            method_name VARCHAR(50),
            cluster_id INTEGER,
            bbox_count INTEGER,
            cluster_rank INTEGER,
            test_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            performance_metrics JSONB
        );
        
        -- æ·»åŠ å‡ ä½•åˆ—
        DO $$
        BEGIN
            IF NOT EXISTS (
                SELECT 1 FROM information_schema.columns 
                WHERE table_name = 'clustering_benchmark_results' 
                AND column_name = 'geometry'
            ) THEN
                PERFORM AddGeometryColumn('public', 'clustering_benchmark_results', 'geometry', 4326, 'GEOMETRY', 2);
            END IF;
        END $$;
        
        -- åˆ›å»ºç´¢å¼•
        CREATE INDEX IF NOT EXISTS idx_clustering_results_city_method 
        ON clustering_benchmark_results (city_id, method_name);
        CREATE INDEX IF NOT EXISTS idx_clustering_results_geom 
        ON clustering_benchmark_results USING GIST (geometry);
    """)
    
    conn.execute(create_table_sql)
    conn.commit()

def save_clustering_results_to_db(conn, city_id, performance_results):
    """ä¿å­˜èšç±»ç»“æœåˆ°æ•°æ®åº“ä¾›QGISå¯è§†åŒ–"""
    
    print(f"\nğŸ’¾ ä¿å­˜èšç±»ç»“æœåˆ°æ•°æ®åº“...")
    
    # åˆ›å»ºç»“æœè¡¨
    create_clustering_results_table(conn)
    
    # æ¸…ç†è¯¥åŸå¸‚çš„æ—§ç»“æœ
    cleanup_sql = text(f"""
        DELETE FROM clustering_benchmark_results 
        WHERE city_id = '{city_id}' 
        AND test_timestamp < NOW() - INTERVAL '1 hour';
    """)
    conn.execute(cleanup_sql)
    
    # 1. ä¿å­˜DBSCANèšç±»ç»“æœ
    print("   ğŸ“Š ä¿å­˜DBSCANèšç±»ç»“æœ...")
    dbscan_sql = text(f"""
        WITH dbscan_clusters AS (
            SELECT 
                id,
                geometry,
                ST_ClusterDBSCAN(geometry, 0.002, 5) OVER() as cluster_id
            FROM clips_bbox_unified 
            WHERE city_id = '{city_id}' AND all_good = true
        ),
        cluster_stats AS (
            SELECT 
                cluster_id,
                COUNT(*) as bbox_count,
                ST_Centroid(ST_Collect(geometry)) as cluster_center,
                ST_ConvexHull(ST_Collect(geometry)) as cluster_boundary,
                ROW_NUMBER() OVER (ORDER BY COUNT(*) DESC) as cluster_rank
            FROM dbscan_clusters 
            WHERE cluster_id IS NOT NULL
            GROUP BY cluster_id
        )
        INSERT INTO clustering_benchmark_results 
        (city_id, method_name, cluster_id, bbox_count, cluster_rank, geometry, performance_metrics)
        SELECT 
            '{city_id}',
            'DBSCAN',
            cluster_id,
            bbox_count,
            cluster_rank,
            cluster_boundary,
            '{{"eps": 0.002, "min_samples": 5, "query_time": {performance_results["dbscan"]["query_time"]}}}'::jsonb
        FROM cluster_stats
        WHERE bbox_count >= 5;  -- åªä¿å­˜æœ‰æ„ä¹‰çš„èšç±»
    """)
    
    result = conn.execute(dbscan_sql)
    dbscan_count = result.rowcount
    
    # 2. ä¿å­˜ç½‘æ ¼æ–¹æ³•ç»“æœ
    print("   ğŸ”² ä¿å­˜ç½‘æ ¼æ–¹æ³•ç»“æœ...")
    grid_sql = text(f"""
        WITH grid_density AS (
            SELECT 
                floor(ST_X(ST_Centroid(geometry)) / 0.002)::int as grid_x,
                floor(ST_Y(ST_Centroid(geometry)) / 0.002)::int as grid_y,
                COUNT(*) as bbox_count
            FROM clips_bbox_unified 
            WHERE city_id = '{city_id}' AND all_good = true
            GROUP BY grid_x, grid_y
            HAVING COUNT(*) >= 5
        ),
        grid_with_geom AS (
            SELECT 
                (grid_x || '_' || grid_y)::integer as grid_id,
                bbox_count,
                ROW_NUMBER() OVER (ORDER BY bbox_count DESC) as grid_rank,
                ST_MakeEnvelope(
                    grid_x * 0.002, 
                    grid_y * 0.002,
                    (grid_x + 1) * 0.002, 
                    (grid_y + 1) * 0.002, 
                    4326
                ) as grid_geom
            FROM grid_density
        )
        INSERT INTO clustering_benchmark_results 
        (city_id, method_name, cluster_id, bbox_count, cluster_rank, geometry, performance_metrics)
        SELECT 
            '{city_id}',
            'Grid',
            grid_id,
            bbox_count,
            grid_rank,
            grid_geom,
            '{{"grid_size": 0.002, "min_density": 5, "query_time": {performance_results["grid"]["query_time"]}}}'::jsonb
        FROM grid_with_geom;
    """)
    
    result = conn.execute(grid_sql)
    grid_count = result.rowcount
    
    # 3. ä¿å­˜åˆ†å±‚èšç±»ç»“æœ
    print("   ğŸ—ï¸ ä¿å­˜åˆ†å±‚èšç±»ç»“æœ...")
    hierarchical_sql = text(f"""
        WITH coarse_clusters AS (
            SELECT 
                geometry,
                ST_ClusterDBSCAN(geometry, 0.01, 20) OVER() as coarse_id
            FROM clips_bbox_unified 
            WHERE city_id = '{city_id}' AND all_good = true
        ),
        fine_clusters AS (
            SELECT 
                coarse_id,
                geometry,
                ST_ClusterDBSCAN(geometry, 0.002, 5) OVER(PARTITION BY coarse_id) as fine_id
            FROM coarse_clusters 
            WHERE coarse_id IS NOT NULL
        ),
        hierarchical_stats AS (
            SELECT 
                (coarse_id * 1000 + fine_id) as hierarchical_id,
                COUNT(*) as bbox_count,
                ST_Centroid(ST_Collect(geometry)) as cluster_center,
                ST_ConvexHull(ST_Collect(geometry)) as cluster_boundary,
                ROW_NUMBER() OVER (ORDER BY COUNT(*) DESC) as cluster_rank
            FROM fine_clusters
            WHERE fine_id IS NOT NULL
            GROUP BY coarse_id, fine_id
        )
        INSERT INTO clustering_benchmark_results 
        (city_id, method_name, cluster_id, bbox_count, cluster_rank, geometry, performance_metrics)
        SELECT 
            '{city_id}',
            'Hierarchical',
            hierarchical_id,
            bbox_count,
            cluster_rank,
            cluster_boundary,
            '{{"coarse_eps": 0.01, "fine_eps": 0.002, "query_time": {performance_results["hierarchical"]["query_time"]}}}'::jsonb
        FROM hierarchical_stats
        WHERE bbox_count >= 3;
    """)
    
    result = conn.execute(hierarchical_sql)
    hierarchical_count = result.rowcount
    
    conn.commit()
    
    print(f"   âœ… DBSCANç»“æœ: {dbscan_count} ä¸ªèšç±»")
    print(f"   âœ… ç½‘æ ¼ç»“æœ: {grid_count} ä¸ªç½‘æ ¼")  
    print(f"   âœ… åˆ†å±‚ç»“æœ: {hierarchical_count} ä¸ªèšç±»")
    
    # åˆ›å»ºQGISå‹å¥½çš„è§†å›¾
    create_qgis_views(conn, city_id)

def create_qgis_views(conn, city_id):
    """åˆ›å»ºQGISå‹å¥½çš„è§†å›¾"""
    
    print("   ğŸ¨ åˆ›å»ºQGISå¯è§†åŒ–è§†å›¾...")
    
    view_sql = text(f"""
        -- èšç±»å¯¹æ¯”è§†å›¾
        CREATE OR REPLACE VIEW qgis_clustering_comparison AS
        SELECT 
            id,
            city_id,
            method_name,
            cluster_id,
            bbox_count,
            cluster_rank,
            CASE 
                WHEN method_name = 'DBSCAN' THEN '#FF6B6B'
                WHEN method_name = 'Grid' THEN '#4ECDC4'  
                WHEN method_name = 'Hierarchical' THEN '#45B7D1'
            END as method_color,
            CASE 
                WHEN bbox_count >= 50 THEN 'Very High'
                WHEN bbox_count >= 20 THEN 'High'
                WHEN bbox_count >= 10 THEN 'Medium'
                ELSE 'Low'
            END as density_level,
            geometry,
            performance_metrics,
            test_timestamp
        FROM clustering_benchmark_results
        WHERE city_id = '{city_id}'
        ORDER BY method_name, cluster_rank;
        
        -- æ–¹æ³•æ€§èƒ½å¯¹æ¯”è§†å›¾
        CREATE OR REPLACE VIEW qgis_method_performance AS
        SELECT 
            method_name,
            COUNT(*) as cluster_count,
            MAX(bbox_count) as max_density,
            ROUND(AVG(bbox_count)::numeric, 2) as avg_density,
            (performance_metrics->>'query_time')::float as query_time_seconds,
            ST_ConvexHull(ST_Collect(geometry)) as method_coverage
        FROM clustering_benchmark_results
        WHERE city_id = '{city_id}'
        GROUP BY method_name, performance_metrics->>'query_time'
        ORDER BY query_time_seconds;
    """)
    
    conn.execute(view_sql)
    conn.commit()
    
    print(f"   âœ… åˆ›å»ºè§†å›¾: qgis_clustering_comparison")
    print(f"   âœ… åˆ›å»ºè§†å›¾: qgis_method_performance")

def run_clustering_benchmark(city_id='A263'):
    """è¿è¡Œèšç±»æ€§èƒ½åŸºå‡†æµ‹è¯•"""
    
    print("ğŸš€ PostgreSQLèšç±»æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("=" * 50)
    print(f"æµ‹è¯•åŸå¸‚: {city_id}")
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    engine = create_engine(LOCAL_DSN, future=True)
    
    results = {}
    
    with engine.connect() as conn:
        
        # æµ‹è¯•1: åŸºç¡€æ•°æ®ç»Ÿè®¡
        print("\nğŸ“Š æµ‹è¯•1: åŸºç¡€æ•°æ®ç»Ÿè®¡")
        start_time = time.time()
        
        basic_stats_sql = text(f"""
            SELECT 
                COUNT(*) as total_bbox,
                COUNT(*) FILTER (WHERE all_good = true) as good_bbox,
                ROUND(AVG(ST_Area(geometry))::numeric, 8) as avg_area,
                ST_XMax(ST_Extent(geometry)) - ST_XMin(ST_Extent(geometry)) as width_deg,
                ST_YMax(ST_Extent(geometry)) - ST_YMin(ST_Extent(geometry)) as height_deg
            FROM clips_bbox_unified 
            WHERE city_id = '{city_id}' AND all_good = true;
        """)
        
        basic_stats = conn.execute(basic_stats_sql).fetchone()
        basic_time = time.time() - start_time
        
        print(f"   æ€»bboxæ•°: {basic_stats.total_bbox:,}")
        print(f"   ä¼˜è´¨bboxæ•°: {basic_stats.good_bbox:,}")
        print(f"   åŸå¸‚èŒƒå›´: {basic_stats.width_deg:.4f}Â° Ã— {basic_stats.height_deg:.4f}Â°")
        print(f"   æŸ¥è¯¢è€—æ—¶: {basic_time:.2f}ç§’")
        
        results['basic_stats'] = {
            'total_bbox': basic_stats.total_bbox,
            'good_bbox': basic_stats.good_bbox,
            'query_time': basic_time
        }
        
        # æµ‹è¯•2: DBSCANèšç±»æ€§èƒ½
        print("\nâš¡ æµ‹è¯•2: DBSCANèšç±»æ€§èƒ½")
        start_time = time.time()
        
        dbscan_sql = text(f"""
            WITH dbscan_clusters AS (
                SELECT 
                    ST_ClusterDBSCAN(geometry, 0.002, 5) OVER() as cluster_id
                FROM clips_bbox_unified 
                WHERE city_id = '{city_id}' AND all_good = true
            )
            SELECT 
                COUNT(DISTINCT cluster_id) FILTER (WHERE cluster_id IS NOT NULL) as cluster_count,
                COUNT(*) FILTER (WHERE cluster_id IS NULL) as noise_points,
                COUNT(*) as total_points
            FROM dbscan_clusters;
        """)
        
        dbscan_stats = conn.execute(dbscan_sql).fetchone()
        dbscan_time = time.time() - start_time
        
        print(f"   èšç±»æ•°é‡: {dbscan_stats.cluster_count}")
        print(f"   å™ªå£°ç‚¹æ•°: {dbscan_stats.noise_points}")
        print(f"   èšç±»ç‡: {(1 - dbscan_stats.noise_points/dbscan_stats.total_points)*100:.1f}%")
        print(f"   æŸ¥è¯¢è€—æ—¶: {dbscan_time:.2f}ç§’")
        
        results['dbscan'] = {
            'cluster_count': dbscan_stats.cluster_count,
            'noise_points': dbscan_stats.noise_points,
            'clustering_rate': (1 - dbscan_stats.noise_points/dbscan_stats.total_points)*100,
            'query_time': dbscan_time
        }
        
        # æµ‹è¯•3: ç½‘æ ¼æ–¹æ³•å¯¹æ¯”
        print("\nğŸ”² æµ‹è¯•3: ç½‘æ ¼æ–¹æ³•åŸºå‡†")
        start_time = time.time()
        
        grid_sql = text(f"""
            WITH grid_density AS (
                SELECT 
                    floor(ST_X(ST_Centroid(geometry)) / 0.002)::int as grid_x,
                    floor(ST_Y(ST_Centroid(geometry)) / 0.002)::int as grid_y,
                    COUNT(*) as bbox_count
                FROM clips_bbox_unified 
                WHERE city_id = '{city_id}' AND all_good = true
                GROUP BY grid_x, grid_y
                HAVING COUNT(*) >= 5
            )
            SELECT 
                COUNT(*) as total_grids,
                MAX(bbox_count) as max_density,
                ROUND(AVG(bbox_count)::numeric, 2) as avg_density
            FROM grid_density;
        """)
        
        grid_stats = conn.execute(grid_sql).fetchone()
        grid_time = time.time() - start_time
        
        print(f"   ç½‘æ ¼æ•°é‡: {grid_stats.total_grids}")
        print(f"   æœ€é«˜å¯†åº¦: {grid_stats.max_density}")
        print(f"   å¹³å‡å¯†åº¦: {grid_stats.avg_density}")
        print(f"   æŸ¥è¯¢è€—æ—¶: {grid_time:.2f}ç§’")
        
        results['grid'] = {
            'total_grids': grid_stats.total_grids,
            'max_density': grid_stats.max_density,
            'avg_density': float(grid_stats.avg_density),
            'query_time': grid_time
        }
        
        # æµ‹è¯•4: åˆ†å±‚èšç±»æ¨¡æ‹Ÿ
        print("\nğŸ—ï¸ æµ‹è¯•4: åˆ†å±‚èšç±»æ€§èƒ½")
        start_time = time.time()
        
        hierarchical_sql = text(f"""
            WITH coarse_clusters AS (
                SELECT 
                    geometry,
                    ST_ClusterDBSCAN(geometry, 0.01, 20) OVER() as coarse_id
                FROM clips_bbox_unified 
                WHERE city_id = '{city_id}' AND all_good = true
            ),
            fine_clusters AS (
                SELECT 
                    coarse_id,
                    ST_ClusterDBSCAN(geometry, 0.002, 5) OVER(PARTITION BY coarse_id) as fine_id
                FROM coarse_clusters 
                WHERE coarse_id IS NOT NULL
            )
            SELECT 
                COUNT(DISTINCT coarse_id) as coarse_clusters,
                COUNT(DISTINCT (coarse_id, fine_id)) FILTER (WHERE fine_id IS NOT NULL) as fine_clusters
            FROM fine_clusters;
        """)
        
        hierarchical_stats = conn.execute(hierarchical_sql).fetchone()
        hierarchical_time = time.time() - start_time
        
        print(f"   ç²—èšç±»æ•°: {hierarchical_stats.coarse_clusters}")
        print(f"   ç»†èšç±»æ•°: {hierarchical_stats.fine_clusters}")
        print(f"   æŸ¥è¯¢è€—æ—¶: {hierarchical_time:.2f}ç§’")
        
        results['hierarchical'] = {
            'coarse_clusters': hierarchical_stats.coarse_clusters,
            'fine_clusters': hierarchical_stats.fine_clusters,
            'query_time': hierarchical_time
        }
        
        # ä¿å­˜è¯¦ç»†èšç±»ç»“æœåˆ°æ•°æ®åº“è¡¨ä¾›QGISå¯è§†åŒ–
        save_clustering_results_to_db(conn, city_id, results)
    
    # æ€§èƒ½åˆ†æå’Œå»ºè®®
    print("\n" + "=" * 50)
    print("ğŸ“ˆ æ€§èƒ½åˆ†ææŠ¥å‘Š")
    print("=" * 50)
    
    total_bbox = results['basic_stats']['good_bbox']
    
    print(f"\nğŸ¯ æ•°æ®è§„æ¨¡: {total_bbox:,} bbox")
    
    # æ•ˆç‡å¯¹æ¯”
    print(f"\nâ±ï¸ æ–¹æ³•è€—æ—¶å¯¹æ¯”:")
    print(f"   ç½‘æ ¼æ–¹æ³•:     {results['grid']['query_time']:.2f}ç§’")
    print(f"   DBSCANèšç±»:   {results['dbscan']['query_time']:.2f}ç§’")
    print(f"   åˆ†å±‚èšç±»:     {results['hierarchical']['query_time']:.2f}ç§’")
    
    # ç»“æœè´¨é‡å¯¹æ¯”
    print(f"\nğŸ“Š ç»“æœè´¨é‡å¯¹æ¯”:")
    print(f"   ç½‘æ ¼çƒ­ç‚¹æ•°:   {results['grid']['total_grids']}")
    print(f"   DBSCANèšç±»æ•°: {results['dbscan']['cluster_count']}")
    print(f"   åˆ†å±‚ç»†èšç±»æ•°: {results['hierarchical']['fine_clusters']}")
    
    # æ€§èƒ½å»ºè®®
    print(f"\nğŸ’¡ æ€§èƒ½å»ºè®®:")
    if total_bbox < 10000:
        print("   âœ… æ•°æ®é‡è¾ƒå°ï¼Œå»ºè®®ä½¿ç”¨ç½‘æ ¼æ–¹æ³•ï¼ˆæœ€å¿«ï¼‰")
    elif total_bbox < 50000:
        print("   âš–ï¸ æ•°æ®é‡é€‚ä¸­ï¼ŒDBSCANå’Œç½‘æ ¼æ–¹æ³•æ€§èƒ½æ¥è¿‘")
        print("   ğŸ’¡ å»ºè®®ï¼šç½‘æ ¼æ–¹æ³•ç”¨äºå¯†åº¦åˆ†æï¼ŒDBSCANç”¨äºå½¢çŠ¶è¯†åˆ«")
    else:
        print("   ğŸš€ æ•°æ®é‡è¾ƒå¤§ï¼Œå»ºè®®ä½¿ç”¨åˆ†å±‚èšç±»æ–¹æ³•")
        print("   ğŸ’¡ ç­–ç•¥ï¼šDBSCANç²—ç­› + ç½‘æ ¼ç²¾åŒ–")
    
    # æ•ˆç‡æ¯”è¾ƒ
    grid_speed = total_bbox / results['grid']['query_time']
    dbscan_speed = total_bbox / results['dbscan']['query_time']
    
    print(f"\nğŸ“Š å¤„ç†é€Ÿåº¦:")
    print(f"   ç½‘æ ¼æ–¹æ³•: {grid_speed:,.0f} bbox/ç§’")
    print(f"   DBSCAN:   {dbscan_speed:,.0f} bbox/ç§’")
    
    if dbscan_speed > grid_speed * 0.8:
        print("   ğŸ¯ DBSCANæ€§èƒ½å¯æ¥å—ï¼Œå¯è€ƒè™‘ç»“åˆä½¿ç”¨")
    else:
        print("   âš¡ ç½‘æ ¼æ–¹æ³•æ˜æ˜¾æ›´å¿«ï¼Œå»ºè®®ä¼˜å…ˆä½¿ç”¨")
    
    return results

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='PostgreSQLèšç±»æ€§èƒ½åŸºå‡†æµ‹è¯•')
    parser.add_argument('--city', default='A263', help='æµ‹è¯•åŸå¸‚ID')
    
    args = parser.parse_args()
    
    try:
        results = run_clustering_benchmark(args.city)
        
        print(f"\nâœ… æµ‹è¯•å®Œæˆï¼")
        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°æ•°æ®åº“è¡¨: clustering_benchmark_results")
        print(f"ğŸ¨ QGISå¯è§†åŒ–è§†å›¾å·²åˆ›å»º:")
        print(f"   â€¢ qgis_clustering_comparison - èšç±»å¯¹æ¯”è§†å›¾")
        print(f"   â€¢ qgis_method_performance - æ€§èƒ½å¯¹æ¯”è§†å›¾")
        print(f"\nğŸ¯ QGISä½¿ç”¨æŒ‡å—:")
        print(f"   1. è¿æ¥æ•°æ®åº“: host=local_pg, database=postgres")
        print(f"   2. åŠ è½½å›¾å±‚: qgis_clustering_comparison")
        print(f"   3. æŒ‰ method_name å­—æ®µåˆ†ç±»æ˜¾ç¤º")
        print(f"   4. ä½¿ç”¨ method_color å­—æ®µè®¾ç½®é¢œè‰²")
        print(f"   5. æŒ‰ density_level å­—æ®µè®¾ç½®ç¬¦å·å¤§å°")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
