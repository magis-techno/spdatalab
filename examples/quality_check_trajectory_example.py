"""è´¨æ£€è½¨è¿¹æŸ¥è¯¢ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨quality_check_trajectory_queryæ¨¡å—å¤„ç†Excelè´¨æ£€ç»“æœï¼š
1. åŠ è½½Excelæ–‡ä»¶å¹¶è§£æè´¨æ£€è®°å½•
2. æŸ¥è¯¢å¯¹åº”çš„è½¨è¿¹æ•°æ®å¹¶è¿›è¡Œæ—¶é—´åˆ†æ®µ
3. åˆå¹¶resultå’Œother_scenarioå­—æ®µ
4. ä¿å­˜åˆ°æ•°æ®åº“å’Œå¯¼å‡ºGeoJSONæ–‡ä»¶

ä½¿ç”¨åœºæ™¯ï¼š
- åŸºäºè´¨æ£€ç»“æœExcelæ–‡ä»¶æŸ¥æ‰¾å¯¹åº”è½¨è¿¹
- æ ¹æ®æ—¶é—´åŒºé—´å¯¹è½¨è¿¹è¿›è¡Œåˆ†æ®µå¤„ç†
- ç»Ÿä¸€MultiLineStringæ ¼å¼è¾“å‡º
"""

import logging
import sys
from pathlib import Path

from spdatalab.dataset.quality_check_trajectory_query import (
    process_quality_check_excel,
    QualityCheckConfig,
    QualityCheckTrajectoryQuery,
    ExcelDataParser,
    ResultFieldProcessor
)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def example_basic_usage():
    """åŸºç¡€ç”¨æ³•ç¤ºä¾‹ï¼šå¤„ç†Excelæ–‡ä»¶å¹¶ä¿å­˜ç»“æœ"""
    
    excel_file = "data/quality_check_sample.xlsx"  # æ›¿æ¢ä¸ºå®é™…æ–‡ä»¶è·¯å¾„
    output_table = "quality_check_trajectories_demo"
    output_geojson = "output/quality_trajectories_demo.geojson"
    
    logger.info("=" * 50)
    logger.info("ğŸ”¥ è´¨æ£€è½¨è¿¹æŸ¥è¯¢åŸºç¡€ç”¨æ³•ç¤ºä¾‹")
    logger.info("=" * 50)
    
    try:
        # ä½¿ç”¨é»˜è®¤é…ç½®å¤„ç†Excelæ–‡ä»¶
        stats = process_quality_check_excel(
            excel_file=excel_file,
            output_table=output_table,
            output_geojson=output_geojson
        )
        
        # è¾“å‡ºå¤„ç†ç»“æœ
        if stats.get('success'):
            logger.info("âœ… å¤„ç†æˆåŠŸå®Œæˆï¼")
            logger.info(f"ğŸ“Š å¤„ç†ç»Ÿè®¡: {stats['valid_trajectories']}/{stats['total_records']} æ¡è®°å½•æˆåŠŸ")
            logger.info(f"â±ï¸ æ€»è€—æ—¶: {stats['workflow_duration']:.2f}s")
        else:
            logger.error(f"âŒ å¤„ç†å¤±è´¥: {stats.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
    except Exception as e:
        logger.error(f"âŒ ç¤ºä¾‹æ‰§è¡Œå¤±è´¥: {str(e)}")

def example_custom_config():
    """è‡ªå®šä¹‰é…ç½®ç¤ºä¾‹ï¼šè°ƒæ•´å¤„ç†å‚æ•°"""
    
    excel_file = "data/quality_check_large.xlsx"  # æ›¿æ¢ä¸ºå®é™…æ–‡ä»¶è·¯å¾„
    output_table = "quality_check_trajectories_custom"
    
    logger.info("=" * 50)
    logger.info("ğŸ”§ è´¨æ£€è½¨è¿¹æŸ¥è¯¢è‡ªå®šä¹‰é…ç½®ç¤ºä¾‹")
    logger.info("=" * 50)
    
    try:
        # è‡ªå®šä¹‰é…ç½®
        config = QualityCheckConfig(
            excel_batch_size=500,           # è¾ƒå°çš„æ‰¹é‡å¤„ç†å¤§å°
            min_points_per_segment=3,       # æ›´ä¸¥æ ¼çš„æœ€å°ç‚¹æ•°è¦æ±‚
            time_tolerance=0.2,             # æ›´å®½æ¾çš„æ—¶é—´å®¹å·®
            simplify_geometry=True,         # å¯ç”¨å‡ ä½•ç®€åŒ–
            simplify_tolerance=0.00005,     # å‡ ä½•ç®€åŒ–å®¹å·®
            batch_insert_size=500,          # è¾ƒå°çš„æ’å…¥æ‰¹æ¬¡
            cache_scene_mappings=True       # å¯ç”¨åœºæ™¯æ˜ å°„ç¼“å­˜
        )
        
        logger.info("ğŸ”§ ä½¿ç”¨è‡ªå®šä¹‰é…ç½®:")
        logger.info(f"   â€¢ æœ€å°åˆ†æ®µç‚¹æ•°: {config.min_points_per_segment}")
        logger.info(f"   â€¢ æ—¶é—´å®¹å·®: {config.time_tolerance}s")
        logger.info(f"   â€¢ å‡ ä½•ç®€åŒ–: {'å¯ç”¨' if config.simplify_geometry else 'ç¦ç”¨'}")
        logger.info(f"   â€¢ åœºæ™¯æ˜ å°„ç¼“å­˜: {'å¯ç”¨' if config.cache_scene_mappings else 'ç¦ç”¨'}")
        
        # æ‰§è¡Œå¤„ç†
        stats = process_quality_check_excel(
            excel_file=excel_file,
            output_table=output_table,
            config=config
        )
        
        # è¾“å‡ºç»“æœ
        if stats.get('success'):
            logger.info("âœ… è‡ªå®šä¹‰é…ç½®å¤„ç†æˆåŠŸï¼")
            logger.info(f"ğŸ“Š æœ‰æ•ˆè½¨è¿¹: {stats['valid_trajectories']} æ¡")
            logger.info(f"ğŸ“Š å¤±è´¥è®°å½•: {stats['failed_records']} æ¡")
        else:
            logger.error(f"âŒ è‡ªå®šä¹‰é…ç½®å¤„ç†å¤±è´¥: {stats.get('error')}")
            
    except Exception as e:
        logger.error(f"âŒ è‡ªå®šä¹‰é…ç½®ç¤ºä¾‹å¤±è´¥: {str(e)}")

def example_step_by_step():
    """åˆ†æ­¥å¤„ç†ç¤ºä¾‹ï¼šæ‰‹åŠ¨æ§åˆ¶å¤„ç†æµç¨‹"""
    
    excel_file = "data/quality_check_sample.xlsx"  # æ›¿æ¢ä¸ºå®é™…æ–‡ä»¶è·¯å¾„
    
    logger.info("=" * 50)
    logger.info("ğŸ” è´¨æ£€è½¨è¿¹æŸ¥è¯¢åˆ†æ­¥å¤„ç†ç¤ºä¾‹")
    logger.info("=" * 50)
    
    try:
        # åˆ›å»ºé…ç½®å’ŒæŸ¥è¯¢å™¨
        config = QualityCheckConfig()
        query_processor = QualityCheckTrajectoryQuery(config)
        
        # æ­¥éª¤1: è§£æExcelæ–‡ä»¶
        logger.info("ğŸ“– æ­¥éª¤1: è§£æExcelæ–‡ä»¶...")
        records = query_processor.excel_parser.load_excel_data(excel_file)
        logger.info(f"âœ… è§£æå®Œæˆ: {len(records)} æ¡è®°å½•")
        
        # æ­¥éª¤2: æ¼”ç¤ºç»“æœå­—æ®µå¤„ç†
        logger.info("ğŸ”§ æ­¥éª¤2: æ¼”ç¤ºç»“æœå­—æ®µå¤„ç†...")
        if records:
            sample_record = records[0]
            merged_results = query_processor.result_processor.merge_and_clean_results(
                sample_record.result, sample_record.other_scenario
            )
            logger.info(f"   åŸå§‹result: {sample_record.result}")
            logger.info(f"   åŸå§‹other_scenario: {sample_record.other_scenario}")
            logger.info(f"   åˆå¹¶åç»“æœ: {merged_results}")
        
        # æ­¥éª¤3: æ‰¹é‡æŸ¥è¯¢åœºæ™¯æ˜ å°„
        logger.info("ğŸ” æ­¥éª¤3: æŸ¥è¯¢åœºæ™¯æ˜ å°„...")
        autoscene_ids = [record.autoscene_id for record in records[:5]]  # åªå¤„ç†å‰5æ¡
        scene_mappings = query_processor.scene_mapper.batch_query_scene_mappings(autoscene_ids)
        logger.info(f"âœ… åœºæ™¯æ˜ å°„æŸ¥è¯¢å®Œæˆ: {len(scene_mappings)} ä¸ªæ˜ å°„")
        
        # æ­¥éª¤4: æ¼”ç¤ºè½¨è¿¹åˆ†æ®µ
        logger.info("ğŸ”§ æ­¥éª¤4: æ¼”ç¤ºè½¨è¿¹åˆ†æ®µ...")
        for record in records[:2]:  # åªå¤„ç†å‰2æ¡è®°å½•
            scene_info = scene_mappings.get(record.autoscene_id)
            if scene_info and scene_info.get('dataset_name'):
                dataset_name = scene_info['dataset_name']
                logger.info(f"   å¤„ç†è½¨è¿¹: {record.autoscene_id} -> {dataset_name}")
                
                # æŸ¥è¯¢å®Œæ•´è½¨è¿¹
                trajectory_df = query_processor.trajectory_segmenter.query_complete_trajectory(dataset_name)
                if not trajectory_df.empty:
                    logger.info(f"   æŸ¥è¯¢åˆ°è½¨è¿¹: {len(trajectory_df)} ä¸ªç‚¹")
                    
                    # åˆ†æ®µå¤„ç†
                    if record.description:
                        logger.info(f"   æ—¶é—´åŒºé—´: {record.description}")
                        geometry, segment_count = query_processor.trajectory_segmenter.segment_trajectory_by_time_ranges(
                            trajectory_df, record.description
                        )
                        logger.info(f"   åˆ†æ®µç»“æœ: {segment_count} ä¸ªåˆ†æ®µ")
                    else:
                        logger.info("   æ— æ—¶é—´åŒºé—´ï¼Œä½¿ç”¨å®Œæ•´è½¨è¿¹")
                        geometry, _ = query_processor.trajectory_segmenter.create_complete_trajectory(trajectory_df)
                        
                    logger.info(f"   å‡ ä½•ç±»å‹: {geometry.geom_type}")
                else:
                    logger.warning(f"   æœªæŸ¥è¯¢åˆ°è½¨è¿¹æ•°æ®: {dataset_name}")
        
        logger.info("âœ… åˆ†æ­¥å¤„ç†æ¼”ç¤ºå®Œæˆ")
        
    except Exception as e:
        logger.error(f"âŒ åˆ†æ­¥å¤„ç†ç¤ºä¾‹å¤±è´¥: {str(e)}")

def example_result_field_processing():
    """ç»“æœå­—æ®µå¤„ç†æ¼”ç¤º"""
    
    logger.info("=" * 50)
    logger.info("ğŸ”§ ç»“æœå­—æ®µå¤„ç†æ¼”ç¤º")
    logger.info("=" * 50)
    
    processor = ResultFieldProcessor()
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {
            'result': "å‹çº¿è¡Œé©¶",
            'other_scenario': "å‹æ–‘é©¬çº¿",
            'expected': ['å‹æ–‘é©¬çº¿', 'å‹çº¿è¡Œé©¶']
        },
        {
            'result': ['å‹çº¿è¡Œé©¶', 'å‹çº¿è¡Œé©¶'],
            'other_scenario': ['å‹æ–‘é©¬çº¿'],
            'expected': ['å‹æ–‘é©¬çº¿', 'å‹çº¿è¡Œé©¶']
        },
        {
            'result': "['è¶…é€Ÿè¡Œé©¶', 'æ€¥åˆ¹è½¦']",
            'other_scenario': "",
            'expected': ['æ€¥åˆ¹è½¦', 'è¶…é€Ÿè¡Œé©¶']
        },
        {
            'result': [],
            'other_scenario': "è¿è§„å˜é“",
            'expected': ['è¿è§„å˜é“']
        }
    ]
    
    for i, case in enumerate(test_cases, 1):
        logger.info(f"ğŸ§ª æµ‹è¯•ç”¨ä¾‹ {i}:")
        logger.info(f"   è¾“å…¥result: {case['result']}")
        logger.info(f"   è¾“å…¥other_scenario: {case['other_scenario']}")
        
        result = processor.merge_and_clean_results(case['result'], case['other_scenario'])
        
        logger.info(f"   è¾“å‡ºç»“æœ: {result}")
        logger.info(f"   æœŸæœ›ç»“æœ: {case['expected']}")
        logger.info(f"   âœ… {'é€šè¿‡' if result == case['expected'] else 'âŒ å¤±è´¥'}")
        logger.info("")

def main():
    """ä¸»å‡½æ•°ï¼šè¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    logger.info("ğŸš€ å¼€å§‹è¿è¡Œè´¨æ£€è½¨è¿¹æŸ¥è¯¢ç¤ºä¾‹")
    
    try:
        # è¿è¡Œç»“æœå­—æ®µå¤„ç†æ¼”ç¤º
        example_result_field_processing()
        
        # æ³¨æ„ï¼šä»¥ä¸‹ç¤ºä¾‹éœ€è¦å®é™…çš„Excelæ–‡ä»¶æ‰èƒ½è¿è¡Œ
        logger.info("âš ï¸  ä»¥ä¸‹ç¤ºä¾‹éœ€è¦å®é™…çš„Excelæ–‡ä»¶ï¼Œè¯·æ ¹æ®éœ€è¦è°ƒæ•´æ–‡ä»¶è·¯å¾„")
        
        # å¦‚æœæœ‰å®é™…æ–‡ä»¶ï¼Œå¯ä»¥å–æ¶ˆæ³¨é‡Šä»¥ä¸‹ä»£ç 
        # example_basic_usage()
        # example_custom_config()
        # example_step_by_step()
        
        logger.info("ğŸ‰ ç¤ºä¾‹æ¼”ç¤ºå®Œæˆ")
        
    except Exception as e:
        logger.error(f"âŒ ç¤ºä¾‹è¿è¡Œå¤±è´¥: {str(e)}")
        return 1
    
    return 0

if __name__ == '__main__':
    sys.exit(main()) 