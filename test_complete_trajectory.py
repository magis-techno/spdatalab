#!/usr/bin/env python3
"""
æµ‹è¯•å®Œæ•´è½¨è¿¹ç‰‡æ®µä¿å­˜åŠŸèƒ½
éªŒè¯å½“ä¸€ä¸ªè½¨è¿¹ç‚¹è½å…¥æ”¶è´¹ç«™æ—¶ï¼Œä¿å­˜è¯¥è½¨è¿¹çš„å®Œæ•´ç‰‡æ®µ
"""

import sys
from pathlib import Path
from sqlalchemy import text
import pandas as pd

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

try:
    from src.spdatalab.fusion.toll_station_analysis import TollStationAnalyzer
    print("âœ… æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

def analyze_trajectory_completeness(analyzer, analysis_id: str):
    """åˆ†æè½¨è¿¹å®Œæ•´æ€§"""
    print("\nğŸ” åˆ†æè½¨è¿¹å®Œæ•´æ€§...")
    
    # 1. è·å–æ”¶è´¹ç«™æ•°æ®
    with analyzer.local_engine.connect() as conn:
        toll_stations = pd.read_sql(text(f"""
            SELECT intersection_id, ST_AsText(geometry) as geometry_wkt
            FROM {analyzer.config.toll_station_table}
            WHERE analysis_id = '{analysis_id}'
        """), conn)
    
    if toll_stations.empty:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æ”¶è´¹ç«™æ•°æ®")
        return
    
    # 2. å¯¹æ¯ä¸ªæ”¶è´¹ç«™åˆ†æè½¨è¿¹å®Œæ•´æ€§
    for _, toll_station in toll_stations.iterrows():
        toll_station_id = toll_station['intersection_id']
        geometry_wkt = toll_station['geometry_wkt']
        
        print(f"\nğŸ“Š æ”¶è´¹ç«™ {toll_station_id} çš„è½¨è¿¹åˆ†æ:")
        
        # 2.1 è·å–è¯¥æ”¶è´¹ç«™çš„æ‰€æœ‰è½¨è¿¹ç‰‡æ®µ
        with analyzer.local_engine.connect() as conn:
            trajectory_results = pd.read_sql(text(f"""
                SELECT 
                    dataset_name,
                    scene_token,
                    point_count,
                    trajectory_geometry
                FROM {analyzer.config.trajectory_results_table}
                WHERE analysis_id = '{analysis_id}'
                AND toll_station_id = '{toll_station_id}'
            """), conn)
        
        if trajectory_results.empty:
            print(f"   âš ï¸ æ²¡æœ‰æ‰¾åˆ°è½¨è¿¹æ•°æ®")
            continue
        
        print(f"   æ‰¾åˆ° {len(trajectory_results)} ä¸ªè½¨è¿¹ç‰‡æ®µ")
        
        # 2.2 åˆ†ææ¯ä¸ªè½¨è¿¹ç‰‡æ®µ
        for _, trajectory in trajectory_results.iterrows():
            dataset_name = trajectory['dataset_name']
            scene_token = trajectory['scene_token']
            point_count = trajectory['point_count']
            
            # 2.3 è·å–åŸå§‹è½¨è¿¹æ•°æ®
            with analyzer.trajectory_engine.connect() as conn:
                original_trajectory = pd.read_sql(text(f"""
                    SELECT 
                        COUNT(*) as total_points,
                        COUNT(CASE WHEN ST_Intersects(
                            ST_SetSRID(ST_GeomFromText('{geometry_wkt}'), 4326),
                            ST_SetSRID(ST_MakePoint(longitude, latitude), 4326)
                        ) THEN 1 END) as intersecting_points
                    FROM {analyzer.config.trajectory_table}
                    WHERE dataset_name = '{dataset_name}'
                    AND scene_token = '{scene_token}'
                """), conn)
            
            if not original_trajectory.empty:
                total_points = original_trajectory['total_points'].iloc[0]
                intersecting_points = original_trajectory['intersecting_points'].iloc[0]
                
                print(f"\n   è½¨è¿¹ç‰‡æ®µ: {dataset_name} @ {scene_token}")
                print(f"   - æ€»ç‚¹æ•°: {total_points}")
                print(f"   - æ”¶è´¹ç«™å†…ç‚¹æ•°: {intersecting_points}")
                print(f"   - æ”¶è´¹ç«™å¤–ç‚¹æ•°: {total_points - intersecting_points}")
                print(f"   - ä¿å­˜çš„ç‚¹æ•°: {point_count}")
                
                # éªŒè¯å®Œæ•´æ€§
                if point_count == total_points:
                    print("   âœ… è½¨è¿¹å®Œæ•´æ€§éªŒè¯é€šè¿‡")
                else:
                    print("   âš ï¸ è½¨è¿¹å®Œæ•´æ€§éªŒè¯å¤±è´¥")
                    print(f"     ä¿å­˜çš„ç‚¹æ•° ({point_count}) ä¸æ€»ç‚¹æ•° ({total_points}) ä¸åŒ¹é…")

def main():
    """æµ‹è¯•å®Œæ•´è½¨è¿¹ç‰‡æ®µä¿å­˜åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•å®Œæ•´è½¨è¿¹ç‰‡æ®µä¿å­˜åŠŸèƒ½")
    print("-" * 40)
    
    try:
        analyzer = TollStationAnalyzer()
        
        # 1. æŸ¥æ‰¾æ”¶è´¹ç«™
        print("1ï¸âƒ£ æŸ¥æ‰¾æ”¶è´¹ç«™...")
        toll_stations_df, analysis_id = analyzer.find_toll_stations(limit=2)
        print(f"   æ‰¾åˆ° {len(toll_stations_df)} ä¸ªæ”¶è´¹ç«™")
        
        if toll_stations_df.empty:
            print("âŒ æ²¡æœ‰æ”¶è´¹ç«™æ•°æ®ï¼Œé€€å‡ºæµ‹è¯•")
            return
        
        # 2. åˆ†æè½¨è¿¹
        print("\n2ï¸âƒ£ åˆ†æè½¨è¿¹æ•°æ®...")
        trajectory_results = analyzer.analyze_trajectories_in_toll_stations(analysis_id)
        print(f"   æ‰¾åˆ° {len(trajectory_results)} ä¸ªè½¨è¿¹ç‰‡æ®µ")
        
        # 3. åˆ†æè½¨è¿¹å®Œæ•´æ€§
        analyze_trajectory_completeness(analyzer, analysis_id)
        
        print(f"\nâœ… æµ‹è¯•å®Œæˆï¼åˆ†æID: {analysis_id}")
        print("ğŸ’¡ éªŒè¯äº†å®Œæ•´è½¨è¿¹ç‰‡æ®µçš„ä¿å­˜åŠŸèƒ½")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 