#!/usr/bin/env python3
"""
æµ‹è¯•æ”¶è´¹ç«™åˆ†æåŠŸèƒ½ï¼ˆåŒ…å«å‡ ä½•æ•°æ®ï¼‰
"""

import sys
from pathlib import Path
from sqlalchemy import text
import pandas as pd

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

try:
    from src.spdatalab.fusion.toll_station_analysis import TollStationAnalyzer, TollStationAnalysisConfig
    print("âœ… æˆåŠŸå¯¼å…¥æ”¶è´¹ç«™åˆ†ææ¨¡å—")
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    sys.exit(1)

def test_with_geometry():
    """æµ‹è¯•åŒ…å«å‡ ä½•æ•°æ®çš„å®Œæ•´åˆ†ææµç¨‹"""
    print("ğŸ§ª æµ‹è¯•åŒ…å«å‡ ä½•æ•°æ®çš„æ”¶è´¹ç«™åˆ†æ...")
    
    try:
        # ä½¿ç”¨æ›´å¤§çš„ç¼“å†²åŒºè·ç¦»
        config = TollStationAnalysisConfig()
        config.buffer_distance_meters = 1000.0  # 1å…¬é‡Œç¼“å†²åŒº
        
        analyzer = TollStationAnalyzer(config)
        
        # æ­¥éª¤1: æŸ¥æ‰¾æ”¶è´¹ç«™
        print("1ï¸âƒ£ æŸ¥æ‰¾æ”¶è´¹ç«™...")
        toll_stations_df, analysis_id = analyzer.find_toll_stations(limit=3)
        
        if toll_stations_df.empty:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æ”¶è´¹ç«™")
            return False
        
        print(f"âœ… æ‰¾åˆ° {len(toll_stations_df)} ä¸ªæ”¶è´¹ç«™ï¼Œåˆ†æID: {analysis_id}")
        
        # æ£€æŸ¥æ”¶è´¹ç«™ä¿å­˜ç»“æœ
        check_toll_sql = text(f"""
            SELECT 
                COUNT(*) as total_count,
                COUNT(intersection_geometry) as geom_count,
                COUNT(buffered_geometry) as buffer_count
            FROM {analyzer.config.toll_station_table} 
            WHERE analysis_id = '{analysis_id}'
        """)
        
        with analyzer.local_engine.connect() as conn:
            toll_stats = conn.execute(check_toll_sql).fetchone()
        
        print(f"   ä¿å­˜çš„æ”¶è´¹ç«™: {toll_stats[0]} ä¸ª")
        print(f"   æœ‰åŸå§‹å‡ ä½•: {toll_stats[1]} ä¸ª")
        print(f"   æœ‰ç¼“å†²å‡ ä½•: {toll_stats[2]} ä¸ª")
        
        if toll_stats[0] == 0:
            print("âŒ æ”¶è´¹ç«™æ•°æ®æ²¡æœ‰ä¿å­˜")
            return False
        
        # æ­¥éª¤2: åˆ†æè½¨è¿¹æ•°æ®
        print("2ï¸âƒ£ åˆ†æè½¨è¿¹æ•°æ®...")
        trajectory_results = analyzer.analyze_trajectories_in_toll_stations(analysis_id, use_buffer=True)
        
        if trajectory_results.empty:
            print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°è½¨è¿¹æ•°æ®")
        else:
            print(f"âœ… æ‰¾åˆ° {len(trajectory_results)} ä¸ªæ•°æ®é›†-æ”¶è´¹ç«™ç»„åˆ")
            
            # æ˜¾ç¤ºè½¨è¿¹ç»“æœè¯¦æƒ…
            for _, row in trajectory_results.head(3).iterrows():
                print(f"   æ•°æ®é›†: {row['dataset_name']}")
                print(f"     è½¨è¿¹ç‚¹æ•°: {row['point_count']}")
                print(f"     å‡ ä½•é•¿åº¦: {len(row.get('trajectory_geometry', '')) if row.get('trajectory_geometry') else 0}")
        
        # æ£€æŸ¥è½¨è¿¹ä¿å­˜ç»“æœ
        check_traj_sql = text(f"""
            SELECT 
                COUNT(*) as total_count,
                COUNT(trajectory_geometry) as geom_count,
                AVG(point_count) as avg_points
            FROM {analyzer.config.trajectory_results_table} 
            WHERE analysis_id = '{analysis_id}'
        """)
        
        with analyzer.local_engine.connect() as conn:
            traj_stats = conn.execute(check_traj_sql).fetchone()
        
        print(f"   ä¿å­˜çš„è½¨è¿¹åˆ†æ: {traj_stats[0]} ä¸ª")
        print(f"   æœ‰è½¨è¿¹å‡ ä½•: {traj_stats[1]} ä¸ª")
        print(f"   å¹³å‡è½¨è¿¹ç‚¹æ•°: {traj_stats[2]:.1f}" if traj_stats[2] else "N/A")
        
        # æ­¥éª¤3: å¯¼å‡ºQGISè§†å›¾
        print("3ï¸âƒ£ å¯¼å‡ºQGISè§†å›¾...")
        export_info = analyzer.export_results_for_qgis(analysis_id)
        
        for view_type, view_name in export_info.items():
            print(f"   {view_type}: {view_name}")
        
        # æ­¥éª¤4: è·å–åˆ†ææ±‡æ€»
        print("4ï¸âƒ£ è·å–åˆ†ææ±‡æ€»...")
        summary = analyzer.get_analysis_summary(analysis_id)
        
        print("   åˆ†ææ±‡æ€»:")
        for key, value in summary.items():
            if key != 'analysis_time':
                print(f"     {key}: {value}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def check_geometry_quality():
    """æ£€æŸ¥å‡ ä½•æ•°æ®è´¨é‡"""
    print("\nğŸ” æ£€æŸ¥å‡ ä½•æ•°æ®è´¨é‡...")
    
    try:
        analyzer = TollStationAnalyzer()
        
        # æ£€æŸ¥æœ€è¿‘çš„åˆ†æç»“æœ
        recent_analysis_sql = text(f"""
            SELECT DISTINCT analysis_id 
            FROM {analyzer.config.toll_station_table} 
            ORDER BY created_at DESC 
            LIMIT 1
        """)
        
        with analyzer.local_engine.connect() as conn:
            recent_result = conn.execute(recent_analysis_sql).fetchone()
        
        if not recent_result:
            print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°åˆ†æç»“æœ")
            return False
        
        analysis_id = recent_result[0]
        print(f"ğŸ“Š æ£€æŸ¥åˆ†æID: {analysis_id}")
        
        # æ£€æŸ¥æ”¶è´¹ç«™å‡ ä½•
        toll_geom_sql = text(f"""
            SELECT 
                intersection_id,
                CASE WHEN intersection_geometry IS NOT NULL THEN 'YES' ELSE 'NO' END as has_orig_geom,
                CASE WHEN buffered_geometry IS NOT NULL THEN 'YES' ELSE 'NO' END as has_buffer_geom,
                CASE WHEN buffered_geometry IS NOT NULL THEN LENGTH(buffered_geometry) ELSE 0 END as buffer_length
            FROM {analyzer.config.toll_station_table}
            WHERE analysis_id = '{analysis_id}'
            ORDER BY intersection_id
        """)
        
        with analyzer.local_engine.connect() as conn:
            toll_geom_df = pd.read_sql(toll_geom_sql, conn)
        
        print("ğŸ“ æ”¶è´¹ç«™å‡ ä½•æ£€æŸ¥:")
        for _, row in toll_geom_df.iterrows():
            print(f"   æ”¶è´¹ç«™ {row['intersection_id']}: åŸå§‹å‡ ä½•={row['has_orig_geom']}, ç¼“å†²å‡ ä½•={row['has_buffer_geom']} (é•¿åº¦:{row['buffer_length']})")
        
        # æ£€æŸ¥è½¨è¿¹å‡ ä½•
        traj_geom_sql = text(f"""
            SELECT 
                dataset_name,
                toll_station_id,
                point_count,
                CASE WHEN trajectory_geometry IS NOT NULL THEN 'YES' ELSE 'NO' END as has_traj_geom,
                CASE WHEN trajectory_geometry IS NOT NULL THEN LENGTH(trajectory_geometry) ELSE 0 END as traj_length
            FROM {analyzer.config.trajectory_results_table}
            WHERE analysis_id = '{analysis_id}'
            ORDER BY point_count DESC
            LIMIT 5
        """)
        
        with analyzer.local_engine.connect() as conn:
            traj_geom_df = pd.read_sql(traj_geom_sql, conn)
        
        print("ğŸš— è½¨è¿¹å‡ ä½•æ£€æŸ¥ï¼ˆå‰5ä¸ªï¼‰:")
        for _, row in traj_geom_df.iterrows():
            print(f"   {row['dataset_name']} @ æ”¶è´¹ç«™{row['toll_station_id']}: {row['point_count']}ç‚¹, å‡ ä½•={row['has_traj_geom']} (é•¿åº¦:{row['traj_length']})")
        
        return True
        
    except Exception as e:
        print(f"âŒ å‡ ä½•è´¨é‡æ£€æŸ¥å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª æ”¶è´¹ç«™åˆ†æå‡ ä½•æ•°æ®æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•å®Œæ•´æµç¨‹
    test_ok = test_with_geometry()
    
    # æ£€æŸ¥å‡ ä½•è´¨é‡
    geom_ok = check_geometry_quality()
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ” æµ‹è¯•æ€»ç»“:")
    print(f"   å®Œæ•´æµç¨‹æµ‹è¯•: {'âœ…' if test_ok else 'âŒ'}")
    print(f"   å‡ ä½•è´¨é‡æ£€æŸ¥: {'âœ…' if geom_ok else 'âŒ'}")
    
    if test_ok and geom_ok:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ”¶è´¹ç«™åˆ†æåŠŸèƒ½ï¼ˆå«å‡ ä½•ï¼‰æ­£å¸¸å·¥ä½œ")
        print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
        print("   - ä½¿ç”¨ make clean-toll-station æ¸…ç†åˆ†æè¡¨")
        print("   - ä½¿ç”¨ spdatalab analyze-toll-stations è¿è¡Œåˆ†æ")
        print("   - åœ¨QGISä¸­è¿æ¥æœ¬åœ°æ•°æ®åº“æŸ¥çœ‹å‡ ä½•ç»“æœ")
    else:
        print("\nâš ï¸ ä»æœ‰é—®é¢˜éœ€è¦è§£å†³")

if __name__ == "__main__":
    main() 