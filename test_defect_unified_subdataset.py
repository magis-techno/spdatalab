#!/usr/bin/env python3
"""
æµ‹è¯•é—®é¢˜å•æ•°æ®é›†ç»Ÿä¸€subdatasetåŠŸèƒ½
éªŒè¯ä¿®æ”¹åçš„é—®é¢˜å•å¤„ç†æ˜¯å¦æ­£ç¡®åˆ›å»ºç»Ÿä¸€çš„subdataset
"""

import json
import tempfile
import logging
from pathlib import Path
from unittest.mock import patch, MagicMock
from src.spdatalab.dataset.dataset_manager import DatasetManager

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_unified_defect_subdataset():
    """æµ‹è¯•é—®é¢˜å•æ•°æ®é›†ç»Ÿä¸€subdatasetåŠŸèƒ½"""
    print("=" * 60)
    print("æµ‹è¯•é—®é¢˜å•æ•°æ®é›†ç»Ÿä¸€subdatasetåŠŸèƒ½")
    print("=" * 60)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_defect_urls = [
        "https://pre-prod.adscloud.huawei.com/ddi-app/#/layout/ddi-system-evaluation/event-list-detail?dataName=defect_001",
        "https://pre-prod.adscloud.huawei.com/ddi-app/#/layout/ddi-system-evaluation/event-list-detail?dataName=defect_002|priority=high",
        "https://pre-prod.adscloud.huawei.com/ddi-app/#/layout/ddi-system-evaluation/event-list-detail?dataName=defect_003|priority=medium|category=lane_detection",
        "https://pre-prod.adscloud.huawei.com/ddi-app/#/layout/ddi-system-evaluation/event-list-detail?dataName=defect_004|severity=critical|region=beijing",
    ]
    
    # åˆ›å»ºä¸´æ—¶æµ‹è¯•æ–‡ä»¶
    with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
        for url in test_defect_urls:
            f.write(url + '\n')
        temp_file = f.name
    
    try:
        # Mockæ•°æ®åº“æŸ¥è¯¢
        def mock_query_defect_data(data_name):
            # æ¨¡æ‹ŸæŸ¥è¯¢æˆåŠŸçš„åœºæ™¯
            scene_mapping = {
                'defect_001': 'scene_001',
                'defect_002': 'scene_002', 
                'defect_003': 'scene_003',
                'defect_004': 'scene_004'
            }
            return scene_mapping.get(data_name)
        
        # åˆ›å»ºDatasetManagerå¹¶æµ‹è¯•
        manager = DatasetManager(defect_mode=True)
        
        # ä½¿ç”¨patchæ¥æ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢
        with patch.object(manager, 'query_defect_data', side_effect=mock_query_defect_data):
            # æ„å»ºé—®é¢˜å•æ•°æ®é›†
            dataset = manager.build_dataset_from_defect_urls(
                temp_file,
                "test_unified_defects",
                "æµ‹è¯•ç»Ÿä¸€é—®é¢˜å•æ•°æ®é›†"
            )
            
            # éªŒè¯æ•°æ®é›†ç»“æ„
            print(f"\néªŒè¯æ•°æ®é›†ç»“æ„:")
            print(f"- æ•°æ®é›†åç§°: {dataset.name}")
            print(f"- å­æ•°æ®é›†æ•°é‡: {len(dataset.subdatasets)}")
            print(f"- æ€»åœºæ™¯æ•°: {dataset.total_scenes}")
            print(f"- å”¯ä¸€åœºæ™¯æ•°: {dataset.total_unique_scenes}")
            
            # éªŒè¯å­æ•°æ®é›†ç»“æ„
            assert len(dataset.subdatasets) == 1, f"æœŸæœ›1ä¸ªå­æ•°æ®é›†ï¼Œå®é™…å¾—åˆ°{len(dataset.subdatasets)}ä¸ª"
            
            subdataset = dataset.subdatasets[0]
            print(f"\néªŒè¯å­æ•°æ®é›†ç»“æ„:")
            print(f"- å­æ•°æ®é›†åç§°: {subdataset.name}")
            print(f"- åœºæ™¯æ•°é‡: {subdataset.scene_count}")
            print(f"- åœºæ™¯IDæ•°é‡: {len(subdataset.scene_ids)}")
            print(f"- é¢„æœŸåœºæ™¯ID: {sorted(subdataset.scene_ids)}")
            
            # éªŒè¯metadata
            metadata = subdataset.metadata
            print(f"\néªŒè¯metadata:")
            print(f"- æ•°æ®ç±»å‹: {metadata.get('data_type')}")
            print(f"- æºæ–‡ä»¶: {metadata.get('source_file')}")
            print(f"- æ€»URLæ•°: {metadata.get('total_urls')}")
            print(f"- æˆåŠŸåœºæ™¯æ•°: {metadata.get('successful_scenes')}")
            print(f"- é¢å¤–å±æ€§: {[k for k in metadata.keys() if k not in ['data_type', 'source_file', 'total_urls', 'successful_scenes']]}")
            
            # éªŒè¯æœŸæœ›çš„ç»“æœ
            expected_scene_ids = ['scene_001', 'scene_002', 'scene_003', 'scene_004']
            assert subdataset.scene_count == 4, f"æœŸæœ›4ä¸ªåœºæ™¯ï¼Œå®é™…å¾—åˆ°{subdataset.scene_count}ä¸ª"
            assert len(subdataset.scene_ids) == 4, f"æœŸæœ›4ä¸ªåœºæ™¯IDï¼Œå®é™…å¾—åˆ°{len(subdataset.scene_ids)}ä¸ª"
            assert sorted(subdataset.scene_ids) == sorted(expected_scene_ids), f"åœºæ™¯IDä¸åŒ¹é…"
            
            # éªŒè¯ç»Ÿä¸€çš„é¢å¤–å±æ€§
            expected_attributes = ['priority', 'category', 'severity', 'region']
            for attr in expected_attributes:
                assert attr in metadata, f"æœŸæœ›å±æ€§'{attr}'ä¸åœ¨metadataä¸­"
            
            print(f"\nâœ… æ‰€æœ‰éªŒè¯é€šè¿‡!")
            
            # ä¿å­˜æµ‹è¯•æ•°æ®é›†ä»¥ä¾›æ£€æŸ¥
            output_file = "test_unified_defect_dataset.json"
            manager.save_dataset(dataset, output_file, format='json')
            print(f"\næµ‹è¯•æ•°æ®é›†å·²ä¿å­˜åˆ°: {output_file}")
            
            # æ˜¾ç¤ºä¿å­˜çš„JSONç»“æ„
            with open(output_file, 'r', encoding='utf-8') as f:
                dataset_json = json.load(f)
                print(f"\nç”Ÿæˆçš„JSONç»“æ„:")
                print(json.dumps(dataset_json, ensure_ascii=False, indent=2))
                
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        Path(temp_file).unlink()

def test_defect_line_parsing():
    """æµ‹è¯•é—®é¢˜å•è¡Œè§£æåŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•é—®é¢˜å•è¡Œè§£æåŠŸèƒ½")
    print("=" * 60)
    
    manager = DatasetManager(defect_mode=True)
    
    test_cases = [
        {
            'input': 'https://example.com/defect?dataName=test_001',
            'expected_attributes': {}
        },
        {
            'input': 'https://example.com/defect?dataName=test_002|priority=high',
            'expected_attributes': {'priority': 'high'}
        },
        {
            'input': 'https://example.com/defect?dataName=test_003|priority=medium|category=lane_detection',
            'expected_attributes': {'priority': 'medium', 'category': 'lane_detection'}
        },
        {
            'input': 'https://example.com/defect?dataName=test_004|severity=3|region=beijing|urgent',
            'expected_attributes': {'severity': '3', 'region': 'beijing', 'urgent': True}
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\næµ‹è¯•ç”¨ä¾‹ {i}: {test_case['input']}")
        
        result = manager.parse_defect_line(test_case['input'])
        
        if result:
            print(f"- è§£ææˆåŠŸ")
            print(f"- URL: {result['url']}")
            print(f"- å±æ€§: {result['attributes']}")
            
            # éªŒè¯å±æ€§
            assert result['attributes'] == test_case['expected_attributes'], \
                f"å±æ€§ä¸åŒ¹é…: æœŸæœ›{test_case['expected_attributes']}, å®é™…{result['attributes']}"
            
            print(f"- âœ… éªŒè¯é€šè¿‡")
        else:
            print(f"- âŒ è§£æå¤±è´¥")

if __name__ == "__main__":
    try:
        test_defect_line_parsing()
        test_unified_defect_subdataset()
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc() 