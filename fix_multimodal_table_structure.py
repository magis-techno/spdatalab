#!/usr/bin/env python3
"""
å¤šæ¨¡æ€è½¨è¿¹è¡¨ç»“æ„ä¿®å¤è„šæœ¬

æ­¤è„šæœ¬ç”¨äºä¿®å¤å¤šæ¨¡æ€è½¨è¿¹æ£€ç´¢ä¸­çš„è¡¨ç»“æ„é—®é¢˜ï¼š
- åœ¨polygon_trajectory_query.pyä¸­æ·»åŠ å¤šæ¨¡æ€å­—æ®µåˆ°è¡¨åˆ›å»ºSQL
- æ”¯æŒquery_type, query_content, collectionå­—æ®µ
- è‡ªåŠ¨å¤‡ä»½å’ŒéªŒè¯ä¿®å¤æ•ˆæœ

é—®é¢˜èƒŒæ™¯ï¼š
å¤šæ¨¡æ€è½¨è¿¹æ£€ç´¢å°è¯•æ’å…¥query_typeç­‰å­—æ®µï¼Œä½†è¡¨ç»“æ„ä¸­æ²¡æœ‰è¿™äº›åˆ—

ä¿®å¤ç­–ç•¥ï¼š
åœ¨CREATE TABLEè¯­å¥ä¸­æ·»åŠ å¤šæ¨¡æ€ç›¸å…³å­—æ®µ
"""

import re
import logging
import shutil
from pathlib import Path
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class MultimodalTableStructureFixer:
    """å¤šæ¨¡æ€è¡¨ç»“æ„ä¿®å¤å™¨"""
    
    def __init__(self):
        self.target_file = Path("src/spdatalab/dataset/polygon_trajectory_query.py")
        self.backup_suffix = f"_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.py"
        
        # éœ€è¦æ·»åŠ çš„å¤šæ¨¡æ€å­—æ®µ
        self.multimodal_fields = [
            "query_type text",                    # æŸ¥è¯¢ç±»å‹ï¼š'text' æˆ– 'image'
            "query_content text",                 # æŸ¥è¯¢å†…å®¹
            "collection varchar(255)",            # collectionåç§°
            "source_polygons text"                # æºpolygonä¿¡æ¯
        ]
    
    def run_fix(self) -> bool:
        """è¿è¡Œè¡¨ç»“æ„ä¿®å¤"""
        logger.info("ğŸ”§ å¼€å§‹å¤šæ¨¡æ€è½¨è¿¹è¡¨ç»“æ„ä¿®å¤...")
        
        if not self.target_file.exists():
            logger.error(f"ç›®æ ‡æ–‡ä»¶ä¸å­˜åœ¨: {self.target_file}")
            return False
        
        try:
            # 1. è¯»å–åŸå§‹æ–‡ä»¶
            original_content = self.read_original_file()
            
            # 2. åˆ›å»ºå¤‡ä»½
            backup_path = self.create_backup()
            logger.info(f"ğŸ“ å¤‡ä»½åˆ›å»º: {backup_path}")
            
            # 3. åº”ç”¨ä¿®å¤
            modified_content = self.apply_multimodal_fields_fix(original_content)
            
            # 4. å†™å…¥ä¿®å¤åçš„å†…å®¹
            self.write_modified_file(modified_content)
            
            # 5. éªŒè¯ä¿®å¤æ•ˆæœ
            if self.verify_fix():
                logger.info("âœ… å¤šæ¨¡æ€è¡¨ç»“æ„ä¿®å¤æˆåŠŸï¼")
                return True
            else:
                logger.error("âŒ ä¿®å¤éªŒè¯å¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"ä¿®å¤è¿‡ç¨‹å¤±è´¥: {e}")
            return False
    
    def read_original_file(self) -> str:
        """è¯»å–åŸå§‹æ–‡ä»¶å†…å®¹"""
        with open(self.target_file, 'r', encoding='utf-8') as f:
            return f.read()
    
    def create_backup(self) -> Path:
        """åˆ›å»ºå¤‡ä»½æ–‡ä»¶"""
        backup_path = self.target_file.with_suffix(self.backup_suffix)
        shutil.copy2(self.target_file, backup_path)
        return backup_path
    
    def apply_multimodal_fields_fix(self, content: str) -> str:
        """åº”ç”¨å¤šæ¨¡æ€å­—æ®µä¿®å¤"""
        logger.info("ğŸ”„ åœ¨CREATE TABLEè¯­å¥ä¸­æ·»åŠ å¤šæ¨¡æ€å­—æ®µ...")
        
        # æŸ¥æ‰¾CREATE TABLEè¯­å¥çš„ä½ç½®
        create_table_pattern = r'(CREATE TABLE \{table_name\} \(\s*\n.*?polygon_ids text\[\],\s*\n.*?created_at timestamp DEFAULT CURRENT_TIMESTAMP\s*\n\s*\)\s*;)'
        
        def replacement_func(match):
            original_sql = match.group(1)
            logger.info("æ‰¾åˆ°CREATE TABLEè¯­å¥ï¼Œæ·»åŠ å¤šæ¨¡æ€å­—æ®µ...")
            
            # åœ¨created_atä¹‹å‰æ’å…¥å¤šæ¨¡æ€å­—æ®µ
            multimodal_fields_sql = ",\n                    ".join([
                "",  # ç©ºå­—ç¬¦ä¸²ç”¨äºåœ¨å¼€å¤´æ·»åŠ é€—å·
                *self.multimodal_fields
            ])
            
            # æ›¿æ¢ç­–ç•¥ï¼šåœ¨created_atè¡Œä¹‹å‰æ’å…¥å­—æ®µ
            modified_sql = original_sql.replace(
                "created_at timestamp DEFAULT CURRENT_TIMESTAMP",
                f"{multimodal_fields_sql.lstrip(',')},\n                    created_at timestamp DEFAULT CURRENT_TIMESTAMP"
            )
            
            logger.info("âœ… å¤šæ¨¡æ€å­—æ®µæ·»åŠ å®Œæˆ")
            return modified_sql
        
        # æ‰§è¡Œæ›¿æ¢
        modified_content = re.sub(create_table_pattern, replacement_func, content, flags=re.DOTALL)
        
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸä¿®æ”¹
        if modified_content == content:
            logger.warning("âš ï¸ æœªæ£€æµ‹åˆ°CREATE TABLEæ¨¡å¼ï¼Œå°è¯•æ‰‹åŠ¨æ¨¡å¼...")
            modified_content = self.apply_manual_fix(content)
        
        return modified_content
    
    def apply_manual_fix(self, content: str) -> str:
        """æ‰‹åŠ¨æ¨¡å¼ï¼šç›´æ¥æ›¿æ¢ç‰¹å®šè¡Œ"""
        logger.info("ğŸ”„ ä½¿ç”¨æ‰‹åŠ¨æ¨¡å¼ä¿®å¤...")
        
        # æŸ¥æ‰¾ç‰¹å®šçš„è¡Œå¹¶æ›¿æ¢
        target_line = "                    created_at timestamp DEFAULT CURRENT_TIMESTAMP"
        
        if target_line in content:
            # æ„å»ºæ’å…¥å†…å®¹
            multimodal_lines = [
                "                    query_type text,",
                "                    query_content text,",
                "                    collection varchar(255),",
                "                    source_polygons text,",
                "                    created_at timestamp DEFAULT CURRENT_TIMESTAMP"
            ]
            
            replacement_lines = "\n".join(multimodal_lines)
            
            # æ‰§è¡Œæ›¿æ¢
            modified_content = content.replace(target_line, replacement_lines)
            
            logger.info("âœ… æ‰‹åŠ¨æ¨¡å¼ä¿®å¤å®Œæˆ")
            return modified_content
        else:
            logger.error("âŒ æ— æ³•æ‰¾åˆ°ç›®æ ‡è¡Œè¿›è¡Œä¿®å¤")
            return content
    
    def write_modified_file(self, content: str):
        """å†™å…¥ä¿®å¤åçš„æ–‡ä»¶"""
        with open(self.target_file, 'w', encoding='utf-8') as f:
            f.write(content)
        logger.info(f"ğŸ“ ä¿®å¤åæ–‡ä»¶å·²å†™å…¥: {self.target_file}")
    
    def verify_fix(self) -> bool:
        """éªŒè¯ä¿®å¤æ•ˆæœ"""
        logger.info("ğŸ” éªŒè¯ä¿®å¤æ•ˆæœ...")
        
        with open(self.target_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æ£€æŸ¥å¤šæ¨¡æ€å­—æ®µæ˜¯å¦å·²æ·»åŠ 
        checks = [
            ("query_type text", "query_typeå­—æ®µ"),
            ("query_content text", "query_contentå­—æ®µ"),
            ("collection varchar", "collectionå­—æ®µ"),
            ("source_polygons text", "source_polygonså­—æ®µ")
        ]
        
        all_passed = True
        for field_sql, field_name in checks:
            if field_sql in content:
                logger.info(f"   âœ… {field_name}å·²æ·»åŠ ")
            else:
                logger.warning(f"   âŒ {field_name}æœªæ‰¾åˆ°")
                all_passed = False
        
        return all_passed
    
    def generate_test_sql(self) -> str:
        """ç”Ÿæˆæµ‹è¯•SQL"""
        return f"""
-- æµ‹è¯•å¤šæ¨¡æ€è½¨è¿¹è¡¨åˆ›å»º
CREATE TABLE test_discovered_trajectories (
    id serial PRIMARY KEY,
    dataset_name text NOT NULL,
    scene_id text,
    event_id integer,
    event_name varchar(765),
    start_time bigint,
    end_time bigint,
    duration bigint,
    point_count integer,
    avg_speed numeric(8,2),
    max_speed numeric(8,2),
    min_speed numeric(8,2),
    std_speed numeric(8,2),
    avp_ratio numeric(5,3),
    polygon_ids text[],
    query_type text,
    query_content text,
    collection varchar(255),
    source_polygons text,
    created_at timestamp DEFAULT CURRENT_TIMESTAMP
);

-- æ·»åŠ å‡ ä½•åˆ—
SELECT AddGeometryColumn('public', 'test_discovered_trajectories', 'geometry', 4326, 'LINESTRING', 2);

-- æµ‹è¯•æ’å…¥å¤šæ¨¡æ€æ•°æ®
INSERT INTO test_discovered_trajectories 
(dataset_name, query_type, query_content, collection) 
VALUES 
('test_dataset', 'text', 'bicycle crossing intersection', 'ddi_collection_camera_encoded_1');

-- æŸ¥è¯¢éªŒè¯
SELECT query_type, query_content, collection FROM test_discovered_trajectories;

-- æ¸…ç†
DROP TABLE test_discovered_trajectories;
"""

def create_manual_sql_fix():
    """åˆ›å»ºæ‰‹åŠ¨SQLä¿®å¤è„šæœ¬"""
    sql_script = """-- æ‰‹åŠ¨SQLä¿®å¤è„šæœ¬ï¼šä¸ºexistingè¡¨æ·»åŠ å¤šæ¨¡æ€å­—æ®µ

-- 1. æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
SELECT EXISTS (
    SELECT FROM information_schema.tables 
    WHERE table_schema = 'public' 
    AND table_name = 'discovered_trajectories'
);

-- 2. å¦‚æœè¡¨å­˜åœ¨ï¼Œæ·»åŠ ç¼ºå¤±å­—æ®µ
DO $$
BEGIN
    -- æ·»åŠ query_typeå­—æ®µ
    IF NOT EXISTS (
        SELECT 1 FROM information_schema.columns 
        WHERE table_schema = 'public' 
        AND table_name = 'discovered_trajectories' 
        AND column_name = 'query_type'
    ) THEN
        ALTER TABLE discovered_trajectories ADD COLUMN query_type text;
    END IF;
    
    -- æ·»åŠ query_contentå­—æ®µ
    IF NOT EXISTS (
        SELECT 1 FROM information_schema.columns 
        WHERE table_schema = 'public' 
        AND table_name = 'discovered_trajectories' 
        AND column_name = 'query_content'
    ) THEN
        ALTER TABLE discovered_trajectories ADD COLUMN query_content text;
    END IF;
    
    -- æ·»åŠ collectionå­—æ®µ
    IF NOT EXISTS (
        SELECT 1 FROM information_schema.columns 
        WHERE table_schema = 'public' 
        AND table_name = 'discovered_trajectories' 
        AND column_name = 'collection'
    ) THEN
        ALTER TABLE discovered_trajectories ADD COLUMN collection varchar(255);
    END IF;
    
    -- æ·»åŠ source_polygonså­—æ®µ
    IF NOT EXISTS (
        SELECT 1 FROM information_schema.columns 
        WHERE table_schema = 'public' 
        AND table_name = 'discovered_trajectories' 
        AND column_name = 'source_polygons'
    ) THEN
        ALTER TABLE discovered_trajectories ADD COLUMN source_polygons text;
    END IF;
END $$;

-- 3. éªŒè¯å­—æ®µæ˜¯å¦æ·»åŠ æˆåŠŸ
SELECT column_name, data_type, is_nullable 
FROM information_schema.columns 
WHERE table_schema = 'public' 
AND table_name = 'discovered_trajectories'
AND column_name IN ('query_type', 'query_content', 'collection', 'source_polygons')
ORDER BY column_name;
"""
    
    with open('fix_existing_table_structure.sql', 'w', encoding='utf-8') as f:
        f.write(sql_script)
    
    logger.info("âœ… å·²åˆ›å»ºæ‰‹åŠ¨SQLä¿®å¤è„šæœ¬: fix_existing_table_structure.sql")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ å¤šæ¨¡æ€è½¨è¿¹è¡¨ç»“æ„ä¿®å¤å·¥å…·")
    print("="*50)
    
    # åˆ›å»ºä¿®å¤å™¨
    fixer = MultimodalTableStructureFixer()
    
    # ç”Ÿæˆæµ‹è¯•SQL
    test_sql = fixer.generate_test_sql()
    with open('test_multimodal_table.sql', 'w', encoding='utf-8') as f:
        f.write(test_sql)
    logger.info("âœ… å·²åˆ›å»ºæµ‹è¯•SQLè„šæœ¬: test_multimodal_table.sql")
    
    # åˆ›å»ºæ‰‹åŠ¨SQLä¿®å¤è„šæœ¬ï¼ˆç”¨äºä¿®å¤å·²å­˜åœ¨çš„è¡¨ï¼‰
    create_manual_sql_fix()
    
    # è¿è¡Œä¿®å¤
    success = fixer.run_fix()
    
    print("\n" + "="*60)
    print("ğŸ¯ ä¸‹ä¸€æ­¥æ“ä½œå»ºè®®:")
    print("="*60)
    
    if success:
        print("âœ… ä»£ç ä¿®å¤æˆåŠŸï¼ç°åœ¨æœ‰ä¸¤ç§æ–¹æ¡ˆå¤„ç†æ•°æ®åº“ï¼š")
        print("")
        print("æ–¹æ¡ˆA - åˆ é™¤ç°æœ‰è¡¨ï¼ˆæ¨èï¼Œå¦‚æœæ•°æ®ä¸é‡è¦ï¼‰ï¼š")
        print("  1. è¿æ¥æ•°æ®åº“åˆ é™¤ç°æœ‰è¡¨ï¼š")
        print("     DROP TABLE IF EXISTS discovered_trajectories;")
        print("  2. é‡æ–°è¿è¡Œå¤šæ¨¡æ€è½¨è¿¹æ£€ç´¢ï¼Œä¼šè‡ªåŠ¨åˆ›å»ºæ–°è¡¨ç»“æ„")
        print("")
        print("æ–¹æ¡ˆB - ä¿®æ”¹ç°æœ‰è¡¨ç»“æ„ï¼ˆä¿ç•™å·²æœ‰æ•°æ®ï¼‰ï¼š")
        print("  1. åœ¨æ•°æ®åº“ä¸­æ‰§è¡ŒSQLè„šæœ¬ï¼š")
        print("     psql -U postgres -d postgres -f fix_existing_table_structure.sql")
        print("  2. æˆ–æ‰‹åŠ¨æ‰§è¡ŒSQLæ–‡ä»¶ä¸­çš„å‘½ä»¤")
        print("")
        print("ç„¶åé‡æ–°æµ‹è¯•ï¼š")
        print("python -m spdatalab.fusion.multimodal_trajectory_retrieval \\")
        print("  --text 'bicycle crossing intersection' \\")
        print("  --collection 'ddi_collection_camera_encoded_1' \\")
        print("  --output-table 'discovered_trajectories' \\")
        print("  --verbose")
    else:
        print("âŒ ä»£ç ä¿®å¤å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

if __name__ == "__main__":
    main()
