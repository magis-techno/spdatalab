"""æµ‹è¯•è´¨æ£€è½¨è¿¹æŸ¥è¯¢æ¨¡å—ï¼ˆä¸‡çº§æ•°æ®ä¼˜åŒ–ç‰ˆï¼‰

æµ‹è¯•æ–°åŠŸèƒ½ï¼š
1. å¤šExcelæ–‡ä»¶å¤„ç†
2. æ•°æ®è¿‡æ»¤åŠŸèƒ½
3. å¹¶è¡Œå¤„ç†æ€§èƒ½
4. å¤§æ•°æ®å¤„ç†èƒ½åŠ›
5. é…ç½®å‚æ•°éªŒè¯
"""

import logging
import tempfile
import pandas as pd
from pathlib import Path
import time
from unittest.mock import patch, MagicMock

from spdatalab.dataset.quality_check_trajectory_query import (
    QualityCheckConfig,
    QualityCheckTrajectoryQuery,
    ExcelDataParser,
    ResultFieldProcessor,
    process_quality_check_excel
)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def create_sample_excel_data(num_records: int = 100, include_invalid: bool = True) -> pd.DataFrame:
    """åˆ›å»ºæµ‹è¯•ç”¨çš„Excelæ•°æ®"""
    import random
    
    data = []
    
    for i in range(num_records):
        # åˆ›å»ºæœ‰æ•ˆè®°å½•
        if i % 10 != 0 or not include_invalid:  # 90%çš„è®°å½•æ˜¯æœ‰æ•ˆçš„
            record = {
                'task_name': f'é©¾é©¶è¡Œä¸ºæ ‡æ³¨_v3_uturn_{i}',
                'annotator': f'annotator_{i % 5}',
                'autoscene_id': f'scene_id_{i:04d}',
                'result': random.choice(['å‹çº¿è¡Œé©¶', 'è¶…é€Ÿè¡Œé©¶', ['å‹çº¿è¡Œé©¶', 'æ€¥åˆ¹è½¦']]),
                'description': [[0.0, 4.0], [13.0, 20.0]] if i % 3 == 0 else [],
                'other_scenario': random.choice(['å‹æ–‘é©¬çº¿', '', 'è¿è§„å˜é“'])
            }
        else:
            # åˆ›å»ºæ— æ•ˆè®°å½•ï¼ˆæ— resultå’Œother_scenarioï¼‰
            record = {
                'task_name': f'æ— æ•ˆä»»åŠ¡_{i}',
                'annotator': f'annotator_{i % 5}',
                'autoscene_id': f'scene_id_{i:04d}',
                'result': '',
                'description': [],
                'other_scenario': ''
            }
        
        data.append(record)
    
    return pd.DataFrame(data)

def test_data_filtering():
    """æµ‹è¯•æ•°æ®è¿‡æ»¤åŠŸèƒ½"""
    logger.info("ğŸ§ª æµ‹è¯•æ•°æ®è¿‡æ»¤åŠŸèƒ½")
    
    config = QualityCheckConfig(filter_invalid_records=True)
    parser = ExcelDataParser(config)
    
    # åˆ›å»ºåŒ…å«æ— æ•ˆæ•°æ®çš„æµ‹è¯•æ•°æ®
    df = create_sample_excel_data(100, include_invalid=True)
    
    # æµ‹è¯•è¿‡æ»¤å‰åçš„æ•°æ®é‡
    logger.info(f"åŸå§‹æ•°æ®: {len(df)} æ¡")
    
    filtered_df = parser._filter_valid_records(df)
    logger.info(f"è¿‡æ»¤åæ•°æ®: {len(filtered_df)} æ¡")
    
    # éªŒè¯è¿‡æ»¤æ•ˆæœ
    assert len(filtered_df) < len(df), "è¿‡æ»¤åº”è¯¥å‡å°‘æ•°æ®é‡"
    
    # éªŒè¯è¿‡æ»¤åçš„æ•°æ®éƒ½æ˜¯æœ‰æ•ˆçš„
    for _, row in filtered_df.iterrows():
        result_valid = pd.notna(row['result']) and row['result'] != '' and row['result'] != 'nan'
        other_valid = pd.notna(row['other_scenario']) and row['other_scenario'] != '' and row['other_scenario'] != 'nan'
        assert result_valid or other_valid, f"è¿‡æ»¤åçš„è®°å½•åº”è¯¥è‡³å°‘æœ‰ä¸€ä¸ªæœ‰æ•ˆå­—æ®µ: {row}"
    
    logger.info("âœ… æ•°æ®è¿‡æ»¤åŠŸèƒ½æµ‹è¯•é€šè¿‡")

def test_result_field_processing():
    """æµ‹è¯•ç»“æœå­—æ®µå¤„ç†åŠŸèƒ½"""
    logger.info("ğŸ§ª æµ‹è¯•ç»“æœå­—æ®µå¤„ç†åŠŸèƒ½")
    
    processor = ResultFieldProcessor()
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {
            'result': "å‹çº¿è¡Œé©¶",
            'other_scenario': "å‹æ–‘é©¬çº¿",
            'expected': ['å‹æ–‘é©¬çº¿', 'å‹çº¿è¡Œé©¶']
        },
        {
            'result': ['å‹çº¿è¡Œé©¶', 'å‹çº¿è¡Œé©¶'],
            'other_scenario': ['å‹æ–‘é©¬çº¿'],
            'expected': ['å‹æ–‘é©¬çº¿', 'å‹çº¿è¡Œé©¶']
        },
        {
            'result': [],
            'other_scenario': "è¿è§„å˜é“",
            'expected': ['è¿è§„å˜é“']
        },
        {
            'result': '',
            'other_scenario': '',
            'expected': []
        }
    ]
    
    for i, case in enumerate(test_cases, 1):
        result = processor.merge_and_clean_results(case['result'], case['other_scenario'])
        assert result == case['expected'], f"æµ‹è¯•ç”¨ä¾‹ {i} å¤±è´¥: æœŸæœ› {case['expected']}, å®é™… {result}"
        logger.info(f"âœ… æµ‹è¯•ç”¨ä¾‹ {i} é€šè¿‡")
    
    logger.info("âœ… ç»“æœå­—æ®µå¤„ç†åŠŸèƒ½æµ‹è¯•é€šè¿‡")

def test_multiple_excel_files():
    """æµ‹è¯•å¤šExcelæ–‡ä»¶å¤„ç†åŠŸèƒ½"""
    logger.info("ğŸ§ª æµ‹è¯•å¤šExcelæ–‡ä»¶å¤„ç†åŠŸèƒ½")
    
    config = QualityCheckConfig()
    parser = ExcelDataParser(config)
    
    # åˆ›å»ºä¸´æ—¶Excelæ–‡ä»¶
    temp_files = []
    
    try:
        for i in range(3):
            df = create_sample_excel_data(50, include_invalid=False)
            temp_file = tempfile.NamedTemporaryFile(suffix='.xlsx', delete=False)
            df.to_excel(temp_file.name, index=False)
            temp_files.append(temp_file.name)
            temp_file.close()
        
        # æµ‹è¯•å¤šæ–‡ä»¶åŠ è½½
        all_records = parser.load_multiple_excel_files(temp_files)
        
        # éªŒè¯ç»“æœ
        assert len(all_records) == 150, f"åº”è¯¥åŠ è½½150æ¡è®°å½•ï¼Œå®é™…åŠ è½½ {len(all_records)} æ¡"
        
        logger.info(f"âœ… æˆåŠŸåŠ è½½ {len(all_records)} æ¡è®°å½•ä» {len(temp_files)} ä¸ªæ–‡ä»¶")
        
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        for temp_file in temp_files:
            try:
                Path(temp_file).unlink()
            except:
                pass
    
    logger.info("âœ… å¤šExcelæ–‡ä»¶å¤„ç†åŠŸèƒ½æµ‹è¯•é€šè¿‡")

def test_config_validation():
    """æµ‹è¯•é…ç½®å‚æ•°éªŒè¯"""
    logger.info("ğŸ§ª æµ‹è¯•é…ç½®å‚æ•°éªŒè¯")
    
    # æµ‹è¯•é»˜è®¤é…ç½®
    config_default = QualityCheckConfig()
    assert config_default.enable_parallel_processing == True
    assert config_default.filter_invalid_records == True
    assert config_default.max_workers == 4
    
    # æµ‹è¯•è‡ªå®šä¹‰é…ç½®
    config_custom = QualityCheckConfig(
        max_workers=8,
        enable_parallel_processing=False,
        large_data_threshold=10000,
        chunk_processing_size=2000
    )
    
    assert config_custom.max_workers == 8
    assert config_custom.enable_parallel_processing == False
    assert config_custom.large_data_threshold == 10000
    assert config_custom.chunk_processing_size == 2000
    
    logger.info("âœ… é…ç½®å‚æ•°éªŒè¯æµ‹è¯•é€šè¿‡")

def test_performance_comparison():
    """æµ‹è¯•æ€§èƒ½å¯¹æ¯”ï¼ˆæ¨¡æ‹Ÿï¼‰"""
    logger.info("ğŸ§ª æµ‹è¯•æ€§èƒ½å¯¹æ¯”ï¼ˆæ¨¡æ‹Ÿï¼‰")
    
    # æ¨¡æ‹Ÿä¸åŒé…ç½®çš„æ€§èƒ½æµ‹è¯•
    configs = [
        ("æ ‡å‡†é…ç½®", QualityCheckConfig(enable_parallel_processing=False, chunk_processing_size=500)),
        ("å¹¶è¡Œé…ç½®", QualityCheckConfig(enable_parallel_processing=True, max_workers=4, chunk_processing_size=500)),
        ("å¤§æ•°æ®é…ç½®", QualityCheckConfig(enable_parallel_processing=True, max_workers=8, chunk_processing_size=1000))
    ]
    
    # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
    for name, config in configs:
        start_time = time.time()
        
        # æ¨¡æ‹Ÿå¤„ç†1000æ¡è®°å½•
        simulated_records = 1000
        simulated_time = 0.001 if config.enable_parallel_processing else 0.002
        time.sleep(simulated_time)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        
        end_time = time.time()
        duration = end_time - start_time
        
        logger.info(f"ğŸ“Š {name}: æ¨¡æ‹Ÿå¤„ç† {simulated_records} æ¡è®°å½•ç”¨æ—¶ {duration:.3f}s")
    
    logger.info("âœ… æ€§èƒ½å¯¹æ¯”æµ‹è¯•å®Œæˆ")

@patch('spdatalab.dataset.quality_check_trajectory_query.hive_cursor')
def test_scene_mapping_caching(mock_cursor):
    """æµ‹è¯•åœºæ™¯æ˜ å°„ç¼“å­˜åŠŸèƒ½"""
    logger.info("ğŸ§ª æµ‹è¯•åœºæ™¯æ˜ å°„ç¼“å­˜åŠŸèƒ½")
    
    # æ¨¡æ‹Ÿæ•°æ®åº“æŸ¥è¯¢ç»“æœ
    mock_cur = MagicMock()
    mock_cursor.return_value.__enter__.return_value = mock_cur
    
    mock_cur.description = [('scene_id',), ('dataset_name',), ('event_id',), ('event_name',)]
    mock_cur.fetchall.return_value = [
        ('scene_001', 'dataset_001', 1, 'event_001'),
        ('scene_002', 'dataset_002', 2, 'event_002')
    ]
    
    # æµ‹è¯•ç¼“å­˜åŠŸèƒ½
    from spdatalab.dataset.quality_check_trajectory_query import SceneIdMapper
    
    config = QualityCheckConfig(cache_scene_mappings=True)
    mapper = SceneIdMapper(config)
    
    # ç¬¬ä¸€æ¬¡æŸ¥è¯¢
    scene_ids = ['scene_001', 'scene_002']
    mappings1 = mapper.batch_query_scene_mappings(scene_ids)
    
    # ç¬¬äºŒæ¬¡æŸ¥è¯¢ç›¸åŒIDï¼ˆåº”è¯¥ä»ç¼“å­˜è·å–ï¼‰
    mappings2 = mapper.batch_query_scene_mappings(scene_ids)
    
    # éªŒè¯ç»“æœä¸€è‡´
    assert mappings1 == mappings2
    assert len(mappings1) == 2
    
    # éªŒè¯ç¬¬äºŒæ¬¡æŸ¥è¯¢æ²¡æœ‰è°ƒç”¨æ•°æ®åº“ï¼ˆé€šè¿‡è°ƒç”¨æ¬¡æ•°éªŒè¯ï¼‰
    # ç¬¬ä¸€æ¬¡è°ƒç”¨äº†æ•°æ®åº“ï¼Œç¬¬äºŒæ¬¡åº”è¯¥å®Œå…¨ä»ç¼“å­˜è·å–
    
    logger.info("âœ… åœºæ™¯æ˜ å°„ç¼“å­˜åŠŸèƒ½æµ‹è¯•é€šè¿‡")

def test_chunk_processing():
    """æµ‹è¯•åˆ†å—å¤„ç†åŠŸèƒ½"""
    logger.info("ğŸ§ª æµ‹è¯•åˆ†å—å¤„ç†åŠŸèƒ½")
    
    from spdatalab.dataset.quality_check_trajectory_query import QualityCheckRecord
    
    # åˆ›å»ºæµ‹è¯•è®°å½•
    records = []
    for i in range(25):
        record = QualityCheckRecord(
            task_name=f'task_{i}',
            annotator=f'annotator_{i}',
            autoscene_id=f'scene_{i}',
            result=['å‹çº¿è¡Œé©¶'],
            description=[[0.0, 4.0]],
            other_scenario=['å‹æ–‘é©¬çº¿']
        )
        records.append(record)
    
    # æµ‹è¯•åˆ†å—é€»è¾‘
    chunk_size = 10
    chunks = []
    
    for i in range(0, len(records), chunk_size):
        chunk = records[i:i+chunk_size]
        chunks.append(chunk)
    
    # éªŒè¯åˆ†å—ç»“æœ
    assert len(chunks) == 3  # 25æ¡è®°å½•ï¼Œæ¯å—10æ¡ï¼Œåº”è¯¥åˆ†ä¸º3å—
    assert len(chunks[0]) == 10
    assert len(chunks[1]) == 10
    assert len(chunks[2]) == 5
    
    logger.info(f"âœ… åˆ†å—å¤„ç†æµ‹è¯•é€šè¿‡: {len(records)} æ¡è®°å½•åˆ†ä¸º {len(chunks)} å—")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹è´¨æ£€è½¨è¿¹æŸ¥è¯¢æ¨¡å—ä¼˜åŒ–åŠŸèƒ½æµ‹è¯•")
    
    try:
        # æ‰§è¡Œå„é¡¹æµ‹è¯•
        test_config_validation()
        test_result_field_processing()
        test_data_filtering()
        test_multiple_excel_files()
        test_scene_mapping_caching()
        test_chunk_processing()
        test_performance_comparison()
        
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        return 1
    
    return 0

if __name__ == '__main__':
    import sys
    sys.exit(main()) 