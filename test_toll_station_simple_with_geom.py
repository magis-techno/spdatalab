#!/usr/bin/env python3
"""
ç®€åŒ–çš„æ”¶è´¹ç«™åˆ†ææµ‹è¯•ï¼ˆåŒ…å«å‡ ä½•æ•°æ®ï¼‰
"""

import sys
from pathlib import Path
from sqlalchemy import text
import pandas as pd

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

try:
    from src.spdatalab.fusion.toll_station_analysis import TollStationAnalyzer, TollStationAnalysisConfig
    print("âœ… æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

def main():
    """ç®€åŒ–çš„æµ‹è¯•æµç¨‹"""
    print("ğŸ§ª æ”¶è´¹ç«™åˆ†æç®€åŒ–æµ‹è¯•")
    print("-" * 40)
    
    try:
        # é…ç½®
        config = TollStationAnalysisConfig()
        config.buffer_distance_meters = 1000.0  # 1å…¬é‡Œç¼“å†²åŒº
        analyzer = TollStationAnalyzer(config)
        
        # 1. æŸ¥æ‰¾æ”¶è´¹ç«™
        print("1ï¸âƒ£ æŸ¥æ‰¾æ”¶è´¹ç«™...")
        toll_stations_df, analysis_id = analyzer.find_toll_stations(limit=2)
        print(f"   æ‰¾åˆ° {len(toll_stations_df)} ä¸ªæ”¶è´¹ç«™")
        
        # æ£€æŸ¥æ”¶è´¹ç«™ä¿å­˜
        with analyzer.local_engine.connect() as conn:
            toll_count = conn.execute(text(f"""
                SELECT COUNT(*) FROM {analyzer.config.toll_station_table} 
                WHERE analysis_id = '{analysis_id}'
            """)).scalar()
        print(f"   ä¿å­˜äº† {toll_count} ä¸ªæ”¶è´¹ç«™")
        
        # 2. åˆ†æè½¨è¿¹
        print("2ï¸âƒ£ åˆ†æè½¨è¿¹...")
        trajectory_results = analyzer.analyze_trajectories_in_toll_stations(analysis_id)
        print(f"   æ‰¾åˆ° {len(trajectory_results)} ä¸ªæ•°æ®é›†-æ”¶è´¹ç«™ç»„åˆ")
        
        # æ£€æŸ¥è½¨è¿¹ä¿å­˜
        with analyzer.local_engine.connect() as conn:
            traj_stats = conn.execute(text(f"""
                SELECT 
                    COUNT(*) as total,
                    COUNT(geometry) as with_geom
                FROM {analyzer.config.trajectory_results_table} 
                WHERE analysis_id = '{analysis_id}'
            """)).fetchone()
        
        print(f"   ä¿å­˜äº† {traj_stats[0]} ä¸ªè½¨è¿¹åˆ†æç»“æœ")
        print(f"   å…¶ä¸­ {traj_stats[1]} ä¸ªæœ‰å‡ ä½•æ•°æ®")
        
        # 3. æ£€æŸ¥å‡ ä½•è´¨é‡
        print("3ï¸âƒ£ æ£€æŸ¥å‡ ä½•è´¨é‡...")
        
        # æ”¶è´¹ç«™å‡ ä½•
        with analyzer.local_engine.connect() as conn:
            toll_geom = conn.execute(text(f"""
                SELECT 
                    COUNT(geometry) as geom_count
                FROM {analyzer.config.toll_station_table}
                WHERE analysis_id = '{analysis_id}'
            """)).fetchone()
        
        print(f"   æ”¶è´¹ç«™: {toll_geom[0]}ä¸ªå‡ ä½•")
        
        # è½¨è¿¹å‡ ä½•æ ·æœ¬
        with analyzer.local_engine.connect() as conn:
            traj_sample = pd.read_sql(text(f"""
                SELECT 
                    dataset_name,
                    point_count,
                    CASE WHEN geometry IS NOT NULL THEN 'YES' ELSE 'NO' END as has_geom
                FROM {analyzer.config.trajectory_results_table}
                WHERE analysis_id = '{analysis_id}'
                ORDER BY point_count DESC
                LIMIT 3
            """), conn)
        
        print("   è½¨è¿¹æ ·æœ¬:")
        for _, row in traj_sample.iterrows():
            print(f"     {row['dataset_name']}: {row['point_count']}ç‚¹, å‡ ä½•={row['has_geom']}")
        
        # 4. æ±‡æ€»
        summary = analyzer.get_analysis_summary(analysis_id)
        print("4ï¸âƒ£ åˆ†ææ±‡æ€»:")
        print(f"   æ”¶è´¹ç«™æ•°é‡: {summary.get('total_toll_stations', 0)}")
        print(f"   æ•°æ®é›†æ•°é‡: {summary.get('unique_datasets', 0)}")
        print(f"   æ€»è½¨è¿¹ç‚¹æ•°: {summary.get('total_points', 0):,}")
        
        print(f"\nâœ… æµ‹è¯•å®Œæˆï¼åˆ†æID: {analysis_id}")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 