#!/usr/bin/env python3
"""
æµ‹è¯•ç›´æ¥å‡ ä½•ç›¸äº¤åŠŸèƒ½ï¼ˆæ— ç¼“å†²åŒºï¼‰
"""

import sys
from pathlib import Path
from sqlalchemy import text

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

try:
    from src.spdatalab.fusion.toll_station_analysis import TollStationAnalyzer
    print("âœ… æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

def main():
    """æµ‹è¯•ç›´æ¥å‡ ä½•ç›¸äº¤"""
    print("ğŸ§ª æµ‹è¯•ç›´æ¥å‡ ä½•ç›¸äº¤ï¼ˆæ— ç¼“å†²åŒºï¼‰")
    print("-" * 40)
    
    try:
        analyzer = TollStationAnalyzer()
        
        # 1. æŸ¥æ‰¾æ”¶è´¹ç«™
        print("1ï¸âƒ£ æŸ¥æ‰¾æ”¶è´¹ç«™...")
        toll_stations_df, analysis_id = analyzer.find_toll_stations(limit=2)
        print(f"   æ‰¾åˆ° {len(toll_stations_df)} ä¸ªæ”¶è´¹ç«™")
        
        if toll_stations_df.empty:
            print("âŒ æ²¡æœ‰æ”¶è´¹ç«™æ•°æ®ï¼Œé€€å‡ºæµ‹è¯•")
            return
        
        # æ£€æŸ¥æ”¶è´¹ç«™ä¿å­˜
        with analyzer.local_engine.connect() as conn:
            toll_count = conn.execute(text(f"""
                SELECT COUNT(*) FROM {analyzer.config.toll_station_table} 
                WHERE analysis_id = '{analysis_id}'
            """)).scalar()
        print(f"   ä¿å­˜äº† {toll_count} ä¸ªæ”¶è´¹ç«™")
        
        # 2. ç›´æ¥å‡ ä½•ç›¸äº¤åˆ†æ
        print("2ï¸âƒ£ ç›´æ¥å‡ ä½•ç›¸äº¤åˆ†æ...")
        trajectory_results = analyzer.analyze_trajectories_in_toll_stations(analysis_id)
        print(f"   æ‰¾åˆ° {len(trajectory_results)} ä¸ªæ•°æ®é›†-æ”¶è´¹ç«™ç»„åˆ")
        
        # 3. æ£€æŸ¥ç»“æœ
        print("3ï¸âƒ£ æ£€æŸ¥åˆ†æç»“æœ...")
        
        if not trajectory_results.empty:
            # æ˜¾ç¤ºå‰å‡ ä¸ªç»“æœ
            print("   å‰3ä¸ªç»“æœ:")
            for _, row in trajectory_results.head(3).iterrows():
                print(f"     {row['dataset_name']} @ æ”¶è´¹ç«™{row['toll_station_id']}: {row['point_count']}ç‚¹")
            
            # æ£€æŸ¥ä¿å­˜åˆ°æ•°æ®åº“çš„ç»“æœ
            with analyzer.local_engine.connect() as conn:
                saved_count = conn.execute(text(f"""
                    SELECT COUNT(*) FROM {analyzer.config.trajectory_results_table} 
                    WHERE analysis_id = '{analysis_id}'
                """)).scalar()
                
                geom_count = conn.execute(text(f"""
                    SELECT COUNT(*) FROM {analyzer.config.trajectory_results_table} 
                    WHERE analysis_id = '{analysis_id}' AND geometry IS NOT NULL
                """)).scalar()
            
            print(f"   ä¿å­˜äº† {saved_count} ä¸ªè½¨è¿¹åˆ†æç»“æœ")
            print(f"   å…¶ä¸­ {geom_count} ä¸ªæœ‰å‡ ä½•æ•°æ®")
        else:
            print("   âš ï¸ æ²¡æœ‰æ‰¾åˆ°ç›¸äº¤çš„è½¨è¿¹æ•°æ®")
            print("   è¿™å¯èƒ½æ˜¯å› ä¸º:")
            print("     - æ”¶è´¹ç«™å‡ ä½•ä¸è½¨è¿¹æ•°æ®ä¸åœ¨åŒä¸€åŒºåŸŸ")
            print("     - æ”¶è´¹ç«™å‡ ä½•èŒƒå›´å¤ªå°ï¼Œæ²¡æœ‰è½¨è¿¹ç‚¹ç›´æ¥ç›¸äº¤")
        
        # 4. åˆ†ææ±‡æ€»
        print("4ï¸âƒ£ åˆ†ææ±‡æ€»...")
        summary = analyzer.get_analysis_summary(analysis_id)
        print(f"   æ”¶è´¹ç«™æ•°é‡: {summary.get('total_toll_stations', 0)}")
        print(f"   æ•°æ®é›†æ•°é‡: {summary.get('unique_datasets', 0)}")
        print(f"   æ€»è½¨è¿¹ç‚¹æ•°: {summary.get('total_points', 0):,}")
        
        print(f"\nâœ… æµ‹è¯•å®Œæˆï¼åˆ†æID: {analysis_id}")
        print("ğŸ’¡ ä½¿ç”¨ç›´æ¥å‡ ä½•ç›¸äº¤ï¼Œæ— ç¼“å†²åŒºæ‰©å±•")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 