# è½¨è¿¹èšç±»æ–¹æ³•è°ƒç ”ä¸æ”¹è¿›å»ºè®®

## ğŸ“Š å½“å‰å®ç°åˆ†æ

### å½“å‰æ–¹æ³•æ¦‚è¿°

å½“å‰`grid_clustering_analysis.py`ä½¿ç”¨çš„æ˜¯åŸºäº**ç‰¹å¾æå– + DBSCAN**çš„æ–¹æ³•ï¼š

1. **è½¨è¿¹åˆ‡åˆ†**ï¼šè·ç¦»ä¼˜å…ˆ(50m) + æ—¶é•¿ä¸Šé™(15s)
2. **ç‰¹å¾æå–**ï¼š10ç»´ç‰¹å¾å‘é‡
   - é€Ÿåº¦ç‰¹å¾ï¼ˆ4ç»´ï¼‰ï¼šavg, std, max, min
   - åŠ é€Ÿåº¦ç‰¹å¾ï¼ˆ2ç»´ï¼‰ï¼šavg, std  
   - èˆªå‘è§’ç‰¹å¾ï¼ˆ2ç»´ï¼‰ï¼šchange_rate, std
   - å½¢æ€ç‰¹å¾ï¼ˆ2ç»´ï¼‰ï¼šdirection_cos, direction_sin
3. **èšç±»ç®—æ³•**ï¼šDBSCAN (eps=0.8, min_samples=5)
4. **ç›¸ä¼¼åº¦åº¦é‡**ï¼šæ¬§æ°è·ç¦»ï¼ˆåœ¨æ ‡å‡†åŒ–ç‰¹å¾ç©ºé—´ï¼‰

### å­˜åœ¨çš„é—®é¢˜

#### 1. **ç‰¹å¾è¡¨ç¤ºä¸è¶³**
- âŒ ç»Ÿè®¡ç‰¹å¾ï¼ˆé€Ÿåº¦å‡å€¼ã€æ ‡å‡†å·®ï¼‰ä¸¢å¤±äº†è½¨è¿¹çš„**ç©ºé—´å½¢çŠ¶ä¿¡æ¯**
- âŒ ä¸¤æ¡ç©ºé—´è½¨è¿¹å®Œå…¨ä¸åŒä½†é€Ÿåº¦åˆ†å¸ƒç›¸ä¼¼çš„è½¨è¿¹å¯èƒ½è¢«èšä¸ºä¸€ç±»
- âŒ åªæœ‰2ç»´å½¢æ€ç‰¹å¾ï¼ˆèµ·ç»ˆç‚¹æ–¹å‘ï¼‰æ— æ³•æè¿°ä¸­é—´çš„æ›²çº¿å½¢çŠ¶

#### 2. **åˆ‡åˆ†ç­–ç•¥ç®€å•**
- âš ï¸ å›ºå®š50ç±³åˆ‡åˆ†å¯èƒ½ä¸é€‚åˆæ‰€æœ‰åœºæ™¯ï¼ˆå¦‚äº¤å‰å£vsç›´çº¿é“è·¯ï¼‰
- âš ï¸ æ²¡æœ‰è€ƒè™‘è½¨è¿¹çš„è¯­ä¹‰ç‰¹å¾ï¼ˆå¦‚è½¬å¼¯ç‚¹ã€åœè½¦ç‚¹ï¼‰
- âš ï¸ å¯èƒ½åœ¨ä¸åˆé€‚çš„åœ°æ–¹åˆ‡æ–­è½¨è¿¹ï¼Œç ´åè¡Œä¸ºæ¨¡å¼

#### 3. **ç›¸ä¼¼åº¦åº¦é‡ä¸é€‚åˆ**
- âŒ æ¬§æ°è·ç¦»å‡è®¾ç‰¹å¾ç©ºé—´æ˜¯å„å‘åŒæ€§çš„ï¼Œä½†è½¨è¿¹æ•°æ®ä¸æ»¡è¶³
- âŒ å¿½ç•¥äº†è½¨è¿¹çš„æ—¶ç©ºè¿ç»­æ€§
- âŒ å¯¹å™ªå£°å’Œé‡‡æ ·é¢‘ç‡æ•æ„Ÿ

#### 4. **DBSCANå±€é™æ€§**
- âš ï¸ éœ€è¦äººå·¥è°ƒå‚ï¼ˆeps, min_samplesï¼‰
- âš ï¸ å¯¹å¯†åº¦ä¸å‡åŒ€çš„æ•°æ®æ•ˆæœä¸ä½³
- âš ï¸ åªèƒ½å‘ç°å‡¸å½¢èšç±»

---

## ğŸ”¬ ä¸šç•Œä¸»æµè½¨è¿¹èšç±»æ–¹æ³•

### æ–¹æ³•åˆ†ç±»

```
è½¨è¿¹èšç±»æ–¹æ³•
â”œâ”€â”€ 1. åŸºäºè·ç¦»çš„æ–¹æ³•
â”‚   â”œâ”€â”€ TRACLUS (2007) - ç»å…¸åŸºå‡†
â”‚   â”œâ”€â”€ DBSCANå˜ç§
â”‚   â””â”€â”€ å±‚æ¬¡èšç±» + è½¨è¿¹ç›¸ä¼¼åº¦
â”‚
â”œâ”€â”€ 2. åŸºäºæ¨¡å‹çš„æ–¹æ³•  
â”‚   â”œâ”€â”€ å‘é‡åœºèšç±» (Vector Field k-Means)
â”‚   â”œâ”€â”€ æ··åˆé«˜æ–¯æ¨¡å‹
â”‚   â””â”€â”€ éšé©¬å°”å¯å¤«æ¨¡å‹
â”‚
â”œâ”€â”€ 3. åŸºäºå¯†åº¦çš„æ–¹æ³•
â”‚   â”œâ”€â”€ å­è½¨è¿¹æ®µ + å¯†åº¦èšç±»
â”‚   â”œâ”€â”€ è‡ªé€‚åº”ç½‘æ ¼å¯†åº¦
â”‚   â””â”€â”€ ç¾¤ç»„èšç±»
â”‚
â””â”€â”€ 4. åŸºäºæ·±åº¦å­¦ä¹ çš„æ–¹æ³•
    â”œâ”€â”€ Autoencoder + èšç±»
    â”œâ”€â”€ Seq2Seqè¡¨ç¤ºå­¦ä¹ 
    â””â”€â”€ å›¾ç¥ç»ç½‘ç»œ
```

---

## ğŸ¯ æ¨èæ–¹æ³•è¯¦è§£

### ğŸ¥‡ æ–¹æ³•1: TRACLUSï¼ˆæ¨èä¼˜å…ˆå®ç°ï¼‰

**åŸç†**ï¼šä¸¤é˜¶æ®µèšç±»
1. **åˆ†æ®µï¼ˆPartitioningï¼‰**ï¼šåŸºäºMDLï¼ˆæœ€å°æè¿°é•¿åº¦ï¼‰åŸåˆ™åˆ‡åˆ†è½¨è¿¹
2. **åˆ†ç»„ï¼ˆGroupingï¼‰**ï¼šå¯¹ç›¸ä¼¼å­è½¨è¿¹æ®µè¿›è¡ŒDBSCANèšç±»
3. **è¡¨ç¤ºè½¨è¿¹ï¼ˆRepresentative Trajectoryï¼‰**ï¼šç”Ÿæˆèšç±»çš„ä»£è¡¨è½¨è¿¹

**ä¼˜åŠ¿**ï¼š
- âœ… å‘ç°**éƒ¨åˆ†è½¨è¿¹æ¨¡å¼**ï¼ˆä¸è¦æ±‚å…¨ç¨‹ç›¸ä¼¼ï¼‰
- âœ… èƒ½å¤„ç†ä¸åŒé•¿åº¦çš„è½¨è¿¹
- âœ… å¯è§£é‡Šæ€§å¼ºï¼Œé€‚åˆäº¤é€šåœºæ™¯
- âœ… å·²è¢«å¹¿æ³›éªŒè¯ï¼ˆ1000+å¼•ç”¨ï¼‰

**ç›¸ä¼¼åº¦åº¦é‡**ï¼š
```python
def perpendicular_distance(point, line_segment):
    """å‚ç›´è·ç¦»ï¼šç‚¹åˆ°çº¿æ®µçš„æœ€çŸ­è·ç¦»"""
    pass

def parallel_distance(point, line_segment):
    """å¹³è¡Œè·ç¦»ï¼šç‚¹åœ¨çº¿æ®µæ–¹å‘ä¸Šçš„æŠ•å½±è·ç¦»"""
    pass

def segment_distance(seg1, seg2):
    """è½¨è¿¹æ®µè·ç¦» = å‚ç›´è·ç¦» + å¹³è¡Œè·ç¦»"""
    return perpendicular_distance + parallel_distance
```

**MDLåˆ‡åˆ†åŸåˆ™**ï¼š
- åœ¨ä¿æŒè½¨è¿¹æè¿°ç²¾åº¦çš„å‰æä¸‹ï¼Œæœ€å°åŒ–æè¿°é•¿åº¦
- è‡ªåŠ¨è¯†åˆ«å…³é”®ç‰¹å¾ç‚¹ï¼ˆè½¬å¼¯ã€åŠ å‡é€Ÿï¼‰

**é€‚ç”¨åœºæ™¯**ï¼š
- âœ… åŸå¸‚é“è·¯äº¤é€šåˆ†æ
- âœ… å‘ç°ä¸»è¦é€šè¡Œæ¨¡å¼
- âœ… å¼‚å¸¸è½¨è¿¹æ£€æµ‹

---

### ğŸ¥ˆ æ–¹æ³•2: åŸºäºè½¨è¿¹ç›¸ä¼¼åº¦çš„èšç±»

**æ ¸å¿ƒæ€æƒ³**ï¼šç›´æ¥è®¡ç®—å®Œæ•´è½¨è¿¹çš„ç›¸ä¼¼åº¦ï¼Œç„¶åç”¨å±‚æ¬¡èšç±»æˆ–DBSCAN

#### 2.1 Hausdorffè·ç¦»
```python
def hausdorff_distance(traj1, traj2):
    """
    è±ªæ–¯å¤šå¤«è·ç¦»ï¼šä¸¤ä¸ªç‚¹é›†ä¹‹é—´çš„æœ€å¤§æœ€å°è·ç¦»
    é€‚ç”¨äºå½¢çŠ¶ç›¸ä¼¼åº¦
    """
    d_12 = max(min(dist(p, traj2)) for p in traj1)
    d_21 = max(min(dist(p, traj1)) for p in traj2)
    return max(d_12, d_21)
```

**ä¼˜åŠ¿**ï¼š
- âœ… å¯¹é‡‡æ ·é¢‘ç‡ä¸æ•æ„Ÿ
- âœ… è®¡ç®—ç®€å•é«˜æ•ˆ

**åŠ£åŠ¿**ï¼š
- âŒ ä¸è€ƒè™‘ç‚¹çš„é¡ºåº
- âŒ å¯¹å¼‚å¸¸ç‚¹æ•æ„Ÿ

#### 2.2 FrÃ©chetè·ç¦»ï¼ˆæœ€ä½³ï¼‰
```python
def frechet_distance(traj1, traj2):
    """
    å¼—é›·æ­‡è·ç¦»ï¼šç‰µç‹—è·ç¦»
    - è€ƒè™‘è½¨è¿¹çš„é¡ºåºå’Œè¿ç»­æ€§
    - é€‚åˆæ—¶ç©ºè½¨è¿¹ç›¸ä¼¼åº¦
    """
    # ä½¿ç”¨åŠ¨æ€è§„åˆ’è®¡ç®—
    pass
```

**ä¼˜åŠ¿**ï¼š
- âœ… è€ƒè™‘è½¨è¿¹çš„æ—¶ç©ºé¡ºåº
- âœ… ç¬¦åˆäººç±»å¯¹è½¨è¿¹ç›¸ä¼¼æ€§çš„ç›´è§‰
- âœ… ç†è®ºåŸºç¡€æ‰å®

**åŠ£åŠ¿**ï¼š
- âŒ è®¡ç®—å¤æ‚åº¦O(mn)è¾ƒé«˜
- âŒ å¯¹é•¿åº¦å·®å¼‚æ•æ„Ÿ

**è§£å†³æ–¹æ¡ˆ**ï¼šä½¿ç”¨è¿‘ä¼¼ç®—æ³•æˆ–GPUåŠ é€Ÿ

#### 2.3 DTWï¼ˆåŠ¨æ€æ—¶é—´è§„æ•´ï¼‰
```python
def dtw_distance(traj1, traj2):
    """
    åŠ¨æ€æ—¶é—´è§„æ•´ï¼šå…è®¸å¼¹æ€§åŒ¹é…
    - é€‚åˆé€Ÿåº¦å˜åŒ–è¾ƒå¤§çš„è½¨è¿¹
    - å¯ä»¥å¤„ç†ä¸åŒé•¿åº¦è½¨è¿¹
    """
    # DTWåŠ¨æ€è§„åˆ’
    pass
```

**ä¼˜åŠ¿**ï¼š
- âœ… å…è®¸æ—¶é—´è½´çš„å¼¹æ€§å˜å½¢
- âœ… å¯¹é€Ÿåº¦å˜åŒ–é²æ£’
- âœ… é€‚åˆå¤„ç†ä¸åŒé‡‡æ ·ç‡

**åŠ£åŠ¿**ï¼š
- âŒ è®¡ç®—å¤æ‚åº¦é«˜
- âŒ å¯èƒ½äº§ç”Ÿä¸åˆç†çš„åŒ¹é…

#### 2.4 LCSSï¼ˆæœ€é•¿å…¬å…±å­åºåˆ—ï¼‰
```python
def lcss_distance(traj1, traj2, epsilon, delta):
    """
    æœ€é•¿å…¬å…±å­åºåˆ—ï¼ˆç”¨äºè½¨è¿¹ï¼‰
    epsilon: ç©ºé—´é˜ˆå€¼
    delta: æ—¶é—´é˜ˆå€¼
    """
    # å¯¹å™ªå£°é²æ£’
    pass
```

**ä¼˜åŠ¿**ï¼š
- âœ… å¯¹å™ªå£°å’Œå¼‚å¸¸ç‚¹é²æ£’
- âœ… å¯ä»¥å¤„ç†éƒ¨åˆ†åŒ¹é…

---

### ğŸ¥‰ æ–¹æ³•3: å‘é‡åœºèšç±»ï¼ˆVector Field k-Meansï¼‰

**åŸç†**ï¼š
- å°†è½¨è¿¹çœ‹ä½œå‘é‡åœºä¸­çš„æµçº¿
- ç”¨å¤šä¸ªå‘é‡åœºçš„å åŠ æ¥å»ºæ¨¡è¿åŠ¨æ¨¡å¼
- k-meansä¼˜åŒ–å‘é‡åœºå‚æ•°

**ä¼˜åŠ¿**ï¼š
- âœ… èƒ½å‘ç°å¤æ‚çš„è¿åŠ¨æ¨¡å¼
- âœ… å¯è§†åŒ–æ•ˆæœå¥½
- âœ… é€‚åˆæµåŠ¨æ€§åˆ†æ

**åŠ£åŠ¿**ï¼š
- âŒ éœ€è¦é¢„è®¾èšç±»æ•°k
- âŒ å®ç°è¾ƒå¤æ‚
- âŒ è®¡ç®—å¼€é”€å¤§

**é€‚ç”¨åœºæ™¯**ï¼š
- äº¤å‰å£æµé‡åˆ†æ
- æ‹¥å µä¼ æ’­æ¨¡å¼
- å®è§‚äº¤é€šæµ

---

### ğŸš€ æ–¹æ³•4: æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼ˆå‰æ²¿ï¼‰

#### 4.1 Autoencoderè¡¨ç¤ºå­¦ä¹ 
```python
class TrajectoryAutoencoder(nn.Module):
    """
    è½¨è¿¹è‡ªç¼–ç å™¨
    1. ç¼–ç å™¨ï¼šå°†å˜é•¿è½¨è¿¹ç¼–ç ä¸ºå›ºå®šç»´åº¦å‘é‡
    2. è§£ç å™¨ï¼šé‡æ„è½¨è¿¹
    3. ä½¿ç”¨ç¼–ç å‘é‡è¿›è¡Œèšç±»
    """
    def __init__(self):
        self.encoder = LSTM/GRU/Transformer
        self.decoder = LSTM/GRU/Transformer
```

**ä¼˜åŠ¿**ï¼š
- âœ… è‡ªåŠ¨å­¦ä¹ æœ€ä¼˜ç‰¹å¾
- âœ… ç«¯åˆ°ç«¯è®­ç»ƒ
- âœ… å¤„ç†å˜é•¿åºåˆ—
- âœ… å¯ä»¥åŠ å…¥è¯­ä¹‰ä¿¡æ¯ï¼ˆé“è·¯ç±»å‹ã€POIç­‰ï¼‰

**åŠ£åŠ¿**ï¼š
- âŒ éœ€è¦å¤§é‡è®­ç»ƒæ•°æ®
- âŒ é»‘ç›’æ¨¡å‹ï¼Œå¯è§£é‡Šæ€§å·®
- âŒ è®­ç»ƒæ—¶é—´é•¿

#### 4.2 è½¨è¿¹åµŒå…¥ï¼ˆTrajectory Embeddingï¼‰
```python
# ç±»ä¼¼Word2Vecçš„æ€è·¯
# å°†è½¨è¿¹æ®µæ˜ å°„åˆ°ä½ç»´ç©ºé—´
traj2vec = Trajectory2Vec()
embeddings = traj2vec.fit_transform(trajectories)
clusters = DBSCAN().fit(embeddings)
```

---

## ğŸ“‹ æ”¹è¿›å»ºè®®ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰

### âœ… çŸ­æœŸæ”¹è¿›ï¼ˆ1-2å‘¨ï¼‰

#### 1. **æ”¹è¿›ç›¸ä¼¼åº¦åº¦é‡**
```python
# æ›¿æ¢å½“å‰çš„æ¬§æ°è·ç¦»
# å®ç°FrÃ©chetè·ç¦»æˆ–DTW

from scipy.spatial.distance import directed_hausdorff
from fastdtw import fastdtw

def improved_similarity(seg1, seg2):
    """ç»„åˆå¤šç§ç›¸ä¼¼åº¦"""
    coords1 = seg1.geometry.coords
    coords2 = seg2.geometry.coords
    
    # ç©ºé—´ç›¸ä¼¼åº¦ï¼ˆHausdorffï¼‰
    spatial_sim = directed_hausdorff(coords1, coords2)[0]
    
    # é€Ÿåº¦ç›¸ä¼¼åº¦
    speed_sim = abs(seg1.avg_speed - seg2.avg_speed)
    
    # æ–¹å‘ç›¸ä¼¼åº¦ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
    direction_sim = 1 - cosine(seg1.direction_vector, seg2.direction_vector)
    
    return 0.5 * spatial_sim + 0.3 * speed_sim + 0.2 * direction_sim
```

**å®ç°æ­¥éª¤**ï¼š
1. å®‰è£…ä¾èµ–ï¼š`pip install scipy similaritymeasures`
2. åœ¨`extract_features()`ä¸­æ·»åŠ ç©ºé—´ç‰¹å¾
3. å®ç°è‡ªå®šä¹‰è·ç¦»å‡½æ•°ä¼ ç»™DBSCAN
4. å¯¹æ¯”æ•ˆæœ

#### 2. **æ”¹è¿›ç‰¹å¾æå–**
```python
def extract_enhanced_features(segment):
    """å¢å¼ºç‰¹å¾ï¼ˆç©ºé—´+è¿åŠ¨ï¼‰"""
    features = []
    
    # åŸæœ‰çš„10ç»´ç‰¹å¾
    features.extend(basic_features)
    
    # æ–°å¢ç©ºé—´å½¢æ€ç‰¹å¾
    features.append(curvature)              # æ›²ç‡
    features.append(tortuosity)             # æ›²æŠ˜åº¦ = å®é™…é•¿åº¦/ç›´çº¿è·ç¦»
    features.append(area_under_trajectory)   # è½¨è¿¹åŒ…ç»œé¢ç§¯
    features.append(direction_entropy)       # æ–¹å‘ç†µï¼ˆæ›²çº¿å¤æ‚åº¦ï¼‰
    
    # æ–°å¢è¿åŠ¨æ¨¡å¼ç‰¹å¾
    features.append(speed_entropy)          # é€Ÿåº¦å˜åŒ–ç†µ
    features.append(acceleration_peaks)     # åŠ é€Ÿåº¦å³°å€¼æ•°
    features.append(stop_ratio)             # åœè½¦æ—¶é—´å æ¯”
    
    return np.array(features)  # 17ç»´
```

#### 3. **æ”¹è¿›åˆ‡åˆ†ç­–ç•¥**
```python
def adaptive_segmentation(trajectory):
    """
    è‡ªé€‚åº”åˆ‡åˆ†ï¼šç»“åˆå¤šä¸ªå‡†åˆ™
    1. MDLå‡†åˆ™ï¼ˆæœ€å°æè¿°é•¿åº¦ï¼‰
    2. é€Ÿåº¦å˜åŒ–ç‚¹æ£€æµ‹
    3. èˆªå‘è§’çªå˜æ£€æµ‹
    """
    # è®¡ç®—ç‰¹å¾ç‚¹
    speed_change_points = detect_speed_changes(trajectory)
    heading_change_points = detect_heading_changes(trajectory)
    
    # åˆå¹¶ç‰¹å¾ç‚¹
    split_points = merge_split_points([
        speed_change_points,
        heading_change_points
    ])
    
    # åº”ç”¨MDLå‡†åˆ™è¿‡æ»¤
    final_splits = apply_mdl_filter(trajectory, split_points)
    
    return segment_by_points(trajectory, final_splits)
```

---

### ğŸ¯ ä¸­æœŸæ”¹è¿›ï¼ˆ2-4å‘¨ï¼‰

#### 4. **å®ç°TRACLUSç®—æ³•**

```python
class TRACLUSClusterer:
    """TRACLUSä¸¤é˜¶æ®µèšç±»"""
    
    def fit(self, trajectories):
        # Phase 1: åˆ†æ®µ
        segments = self.partition_trajectories(trajectories)
        
        # Phase 2: èšç±»
        clusters = self.group_segments(segments)
        
        # Phase 3: ç”Ÿæˆä»£è¡¨è½¨è¿¹
        representatives = self.generate_representatives(clusters)
        
        return clusters, representatives
    
    def partition_trajectories(self, trajectories):
        """åŸºäºMDLçš„æœ€ä¼˜åˆ†æ®µ"""
        pass
    
    def group_segments(self, segments):
        """åŸºäºè·ç¦»çš„DBSCANèšç±»"""
        pass
    
    def segment_distance(self, seg1, seg2):
        """è½¨è¿¹æ®µè·ç¦» = å‚ç›´è·ç¦» + å¹³è¡Œè·ç¦» + è§’åº¦è·ç¦»"""
        pass
```

**å‚è€ƒå®ç°**ï¼š
- è®ºæ–‡ï¼šLee et al. "Trajectory Clustering: A Partition-and-Group Framework" (SIGMOD 2007)
- GitHub: `movingpandas`, `trajectory-mining`

#### 5. **å®ç°å±‚æ¬¡èšç±»**

```python
from scipy.cluster.hierarchy import linkage, fcluster
from scipy.spatial.distance import pdist

# è®¡ç®—è½¨è¿¹è·ç¦»çŸ©é˜µ
distance_matrix = pdist(trajectories, metric=frechet_distance)

# å±‚æ¬¡èšç±»
linkage_matrix = linkage(distance_matrix, method='ward')

# åˆ‡å‰²æ ‘å½¢å›¾
clusters = fcluster(linkage_matrix, t=threshold, criterion='distance')
```

**ä¼˜åŠ¿**ï¼š
- ä¸éœ€è¦é¢„è®¾èšç±»æ•°
- å¯ä»¥é€šè¿‡æ ‘å½¢å›¾å¯è§†åŒ–
- å¯¹å™ªå£°é²æ£’

---

### ğŸš€ é•¿æœŸæ”¹è¿›ï¼ˆ1-2æœˆï¼‰

#### 6. **åŸºäºé“è·¯ç½‘ç»œçš„è¯­ä¹‰å¢å¼º**

```python
class RoadNetworkAwareClusterer:
    """é“è·¯ç½‘ç»œæ„ŸçŸ¥çš„è½¨è¿¹èšç±»"""
    
    def __init__(self, road_network):
        self.road_network = road_network
        self.map_matcher = MapMatcher()
    
    def preprocess_trajectories(self, trajectories):
        """åœ°å›¾åŒ¹é… + è·¯æ®µåºåˆ—æå–"""
        matched_trajectories = []
        
        for traj in trajectories:
            # åœ°å›¾åŒ¹é…
            matched_path = self.map_matcher.match(traj)
            
            # æå–è·¯æ®µåºåˆ—
            road_segments = self.extract_road_sequence(matched_path)
            
            matched_trajectories.append({
                'original': traj,
                'road_sequence': road_segments,
                'semantic_features': self.extract_semantic_features(road_segments)
            })
        
        return matched_trajectories
    
    def extract_semantic_features(self, road_segments):
        """æå–è¯­ä¹‰ç‰¹å¾"""
        return {
            'road_types': [seg.type for seg in road_segments],  # é“è·¯ç±»å‹
            'turn_types': self.identify_turns(road_segments),    # è½¬å‘ç±»å‹
            'poi_nearby': self.get_nearby_pois(road_segments)    # é™„è¿‘POI
        }
    
    def cluster(self, trajectories):
        """åŸºäºè·¯æ®µåºåˆ—çš„èšç±»"""
        # ä½¿ç”¨åºåˆ—ç›¸ä¼¼åº¦ï¼ˆç¼–è¾‘è·ç¦»ã€LCSç­‰ï¼‰
        pass
```

**ä¼˜åŠ¿**ï¼š
- âœ… è¯­ä¹‰æ›´ä¸°å¯Œï¼ˆå¦‚"å·¦è½¬è¿›å…¥ä¸»è·¯"ï¼‰
- âœ… å¯¹GPSå™ªå£°é²æ£’
- âœ… å¯ä»¥å‘ç°è·¯å¾„æ¨¡å¼ï¼ˆODï¼‰

**æŒ‘æˆ˜**ï¼š
- âŒ éœ€è¦é«˜è´¨é‡é“è·¯ç½‘ç»œæ•°æ®
- âŒ åœ°å›¾åŒ¹é…è®¡ç®—å¼€é”€å¤§

#### 7. **æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼ˆå‰æ²¿ç ”ç©¶ï¼‰**

```python
import torch
import torch.nn as nn

class TrajectoryEncoder(nn.Module):
    """è½¨è¿¹ç¼–ç å™¨ï¼ˆLSTM/Transformerï¼‰"""
    
    def __init__(self, input_dim=4, hidden_dim=128, latent_dim=32):
        super().__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=2, batch_first=True)
        self.fc = nn.Linear(hidden_dim, latent_dim)
    
    def forward(self, traj_batch):
        """
        Input: (batch, seq_len, 4)  # lon, lat, speed, heading
        Output: (batch, latent_dim)
        """
        _, (hidden, _) = self.lstm(traj_batch)
        embedding = self.fc(hidden[-1])
        return embedding

# è®­ç»ƒè‡ªç¼–ç å™¨
autoencoder = TrajectoryAutoencoder()
autoencoder.fit(trajectories)

# æå–åµŒå…¥å‘é‡
embeddings = autoencoder.encode(trajectories)

# ä¼ ç»Ÿèšç±»
clusters = DBSCAN().fit(embeddings)
```

---

## ğŸ§ª æµ‹è¯•ä¸è¯„ä¼°

### èšç±»è´¨é‡è¯„ä¼°æŒ‡æ ‡

#### 1. å†…éƒ¨æŒ‡æ ‡ï¼ˆæ— æ ‡ç­¾ï¼‰
```python
from sklearn.metrics import silhouette_score, davies_bouldin_score

# è½®å»“ç³»æ•°ï¼ˆ-1åˆ°1ï¼Œè¶Šå¤§è¶Šå¥½ï¼‰
silhouette = silhouette_score(features, labels)

# Davies-BouldinæŒ‡æ•°ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
db_index = davies_bouldin_score(features, labels)

# Calinski-HarabaszæŒ‡æ•°ï¼ˆè¶Šå¤§è¶Šå¥½ï¼‰
ch_index = calinski_harabasz_score(features, labels)
```

#### 2. å¤–éƒ¨æŒ‡æ ‡ï¼ˆæœ‰æ ‡ç­¾æ—¶ï¼‰
```python
from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score

# è°ƒæ•´å…°å¾·æŒ‡æ•°
ari = adjusted_rand_score(true_labels, pred_labels)

# æ ‡å‡†åŒ–äº’ä¿¡æ¯
nmi = normalized_mutual_info_score(true_labels, pred_labels)
```

#### 3. é¢†åŸŸç‰¹å®šæŒ‡æ ‡
```python
def intra_cluster_similarity(cluster):
    """ç°‡å†…ç›¸ä¼¼åº¦ï¼šåŒä¸€ç°‡è½¨è¿¹çš„å¹³å‡ç›¸ä¼¼åº¦"""
    pass

def inter_cluster_dissimilarity(cluster1, cluster2):
    """ç°‡é—´å·®å¼‚åº¦ï¼šä¸åŒç°‡ä¹‹é—´çš„å·®å¼‚"""
    pass

def representative_coverage(cluster, representative):
    """ä»£è¡¨è½¨è¿¹è¦†ç›–ç‡ï¼šä»£è¡¨è½¨è¿¹èƒ½ä»£è¡¨å¤šå°‘åŸå§‹è½¨è¿¹"""
    pass
```

---

## ğŸ“¦ å®æ–½è·¯çº¿å›¾

### Phase 1: å¿«é€Ÿæ”¹è¿›ï¼ˆæœ¬å‘¨ï¼‰
- [ ] å®ç°Hausdorff/FrÃ©chetè·ç¦»
- [ ] æ·»åŠ ç©ºé—´å½¢æ€ç‰¹å¾ï¼ˆæ›²ç‡ã€æ›²æŠ˜åº¦ï¼‰
- [ ] è°ƒæ•´DBSCANå‚æ•°ï¼ˆeps, min_samplesï¼‰
- [ ] å¯è§†åŒ–èšç±»ç»“æœå¯¹æ¯”

### Phase 2: ç®—æ³•æ›¿æ¢ï¼ˆ2å‘¨å†…ï¼‰
- [ ] å®ç°TRACLUSç®—æ³•
- [ ] å®ç°è‡ªé€‚åº”åˆ†æ®µç­–ç•¥
- [ ] å¯¹æ¯”å¤šç§ç›¸ä¼¼åº¦åº¦é‡
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•

### Phase 3: è¯­ä¹‰å¢å¼ºï¼ˆ1ä¸ªæœˆï¼‰
- [ ] é›†æˆé“è·¯ç½‘ç»œæ•°æ®
- [ ] å®ç°åœ°å›¾åŒ¹é…
- [ ] æå–è¯­ä¹‰ç‰¹å¾
- [ ] è·¯å¾„æ¨¡å¼åˆ†æ

### Phase 4: æ·±åº¦å­¦ä¹ ï¼ˆé•¿æœŸï¼‰
- [ ] æ”¶é›†è®­ç»ƒæ•°æ®
- [ ] è®­ç»ƒè½¨è¿¹è‡ªç¼–ç å™¨
- [ ] åµŒå…¥å‘é‡å¯è§†åŒ–
- [ ] ç«¯åˆ°ç«¯ä¼˜åŒ–

---

## ğŸ“š å‚è€ƒæ–‡çŒ®

### ç»å…¸è®ºæ–‡
1. **TRACLUS**: Lee et al. "Trajectory Clustering: A Partition-and-Group Framework" (SIGMOD 2007)
2. **FrÃ©chetè·ç¦»**: Alt & Godau "Computing the FrÃ©chet distance between two polygonal curves" (1995)
3. **DTW**: Berndt & Clifford "Using dynamic time warping to find patterns in time series" (1994)

### å¼€æºåº“
- `movingpandas`: è½¨è¿¹æ•°æ®åˆ†æ
- `similaritymeasures`: è½¨è¿¹ç›¸ä¼¼åº¦è®¡ç®—ï¼ˆFrÃ©chet, DTW, LCSSï¼‰
- `scikit-mobility`: ç§»åŠ¨æ•°æ®æŒ–æ˜
- `trajminer`: è½¨è¿¹æŒ–æ˜å·¥å…·åŒ…

### ç›¸å…³å·¥å…·
```bash
# å®‰è£…æ¨èåº“
pip install movingpandas similaritymeasures scikit-mobility
pip install fastdtw  # å¿«é€ŸDTW
pip install geopandas shapely  # å·²å®‰è£…
```

---

## ğŸ’¡ æ€»ç»“ä¸å»ºè®®

### å½“å‰é—®é¢˜æ ¹æº
1. **ç‰¹å¾è¡¨ç¤ºä¸è¶³**ï¼šåªç”¨ç»Ÿè®¡ç‰¹å¾ï¼Œä¸¢å¤±ç©ºé—´å½¢æ€
2. **ç›¸ä¼¼åº¦åº¦é‡ä¸å½“**ï¼šæ¬§æ°è·ç¦»ä¸é€‚åˆè½¨è¿¹æ•°æ®
3. **åˆ‡åˆ†ç­–ç•¥ç®€å•**ï¼šå›ºå®šè·ç¦»åˆ‡åˆ†ç ´åè¡Œä¸ºæ¨¡å¼

### æ¨èæ”¹è¿›æ–¹æ¡ˆï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰

#### ğŸ¥‡ ä¼˜å…ˆçº§1ï¼šæ”¹è¿›ç›¸ä¼¼åº¦ï¼ˆç«‹å³å®æ–½ï¼‰
- å®ç°FrÃ©chetè·ç¦»æˆ–Hausdorffè·ç¦»
- æ·»åŠ ç©ºé—´å½¢æ€ç‰¹å¾ï¼ˆæ›²ç‡ã€æ›²æŠ˜åº¦ï¼‰
- ç»„åˆå¤šç§ç›¸ä¼¼åº¦ï¼ˆç©ºé—´+é€Ÿåº¦+æ–¹å‘ï¼‰

**é¢„æœŸæ•ˆæœ**ï¼šèšç±»è´¨é‡æå‡30-50%

#### ğŸ¥ˆ ä¼˜å…ˆçº§2ï¼šå®ç°TRACLUSï¼ˆ2å‘¨å†…ï¼‰
- åŸºäºMDLçš„è‡ªé€‚åº”åˆ†æ®µ
- ä¸¤é˜¶æ®µèšç±»ï¼ˆåˆ†æ®µ+åˆ†ç»„ï¼‰
- ç”Ÿæˆä»£è¡¨è½¨è¿¹

**é¢„æœŸæ•ˆæœ**ï¼šå‘ç°éƒ¨åˆ†è½¨è¿¹æ¨¡å¼ï¼Œå¯è§£é‡Šæ€§å¼º

#### ğŸ¥‰ ä¼˜å…ˆçº§3ï¼šè¯­ä¹‰å¢å¼ºï¼ˆé•¿æœŸï¼‰
- é›†æˆé“è·¯ç½‘ç»œ
- åœ°å›¾åŒ¹é…
- è·¯å¾„æ¨¡å¼æŒ–æ˜

**é¢„æœŸæ•ˆæœ**ï¼šè¯­ä¹‰ä¸°å¯Œï¼Œå®ç”¨æ€§å¼º

---

## ğŸ”§ å¿«é€Ÿæµ‹è¯•è„šæœ¬

```python
#!/usr/bin/env python3
"""æµ‹è¯•ä¸åŒèšç±»æ–¹æ³•çš„æ•ˆæœ"""

from spdatalab.dataset.grid_trajectory_clustering import GridTrajectoryClusterer
from sklearn.metrics import silhouette_score
import numpy as np

def compare_methods():
    """å¯¹æ¯”ä¸åŒæ–¹æ³•"""
    
    # æ–¹æ³•1: å½“å‰æ–¹æ³•ï¼ˆæ¬§æ°è·ç¦»ï¼‰
    config1 = ClusterConfig(eps=0.8, min_samples=5)
    clusterer1 = GridTrajectoryClusterer(config1)
    stats1 = clusterer1.process_all_grids(city_id='A72', max_grids=1)
    
    # æ–¹æ³•2: æ”¹è¿›ç‰¹å¾
    config2 = ClusterConfig(eps=0.8, min_samples=5)
    # TODO: æ·»åŠ ç©ºé—´ç‰¹å¾
    
    # æ–¹æ³•3: TRACLUS
    # TODO: å®ç°TRACLUS
    
    # è¯„ä¼°å¯¹æ¯”
    print("æ–¹æ³•å¯¹æ¯”ï¼š")
    print(f"å½“å‰æ–¹æ³• - è½®å»“ç³»æ•°: {score1:.3f}")
    print(f"æ”¹è¿›æ–¹æ³• - è½®å»“ç³»æ•°: {score2:.3f}")
    
if __name__ == '__main__':
    compare_methods()
```

---

## â“ FAQ

**Q: ä¸ºä»€ä¹ˆDBSCANæ•ˆæœä¸å¥½ï¼Ÿ**
A: DBSCANå¯¹è·ç¦»åº¦é‡å’Œå‚æ•°æ•æ„Ÿã€‚è½¨è¿¹æ•°æ®çš„æ¬§æ°è·ç¦»ä¸èƒ½å¾ˆå¥½åæ˜ ç›¸ä¼¼æ€§ã€‚å»ºè®®æ¢ç”¨FrÃ©chetè·ç¦»æˆ–TRACLUSã€‚

**Q: å¦‚ä½•é€‰æ‹©åˆé€‚çš„èšç±»æ–¹æ³•ï¼Ÿ**
A: å–å†³äºç›®æ ‡ï¼š
- å‘ç°ä¸»è¦é€šè¡Œæ¨¡å¼ â†’ TRACLUS
- å¼‚å¸¸æ£€æµ‹ â†’ åŸºäºå¯†åº¦æ–¹æ³•
- è·¯å¾„æ¨è â†’ è·¯æ®µåºåˆ—èšç±»
- ç ”ç©¶æ¢ç´¢ â†’ æ·±åº¦å­¦ä¹ æ–¹æ³•

**Q: éœ€è¦å¤šå°‘æ•°æ®æ‰èƒ½ç”¨æ·±åº¦å­¦ä¹ ï¼Ÿ**
A: è‡³å°‘10kæ¡è½¨è¿¹ã€‚æ•°æ®å°‘æ—¶å»ºè®®ç”¨ä¼ ç»Ÿæ–¹æ³•ï¼ˆTRACLUSã€å±‚æ¬¡èšç±»ï¼‰ã€‚

**Q: å¦‚ä½•å¤„ç†ä¸åŒé•¿åº¦çš„è½¨è¿¹ï¼Ÿ**
A: 
- æ–¹æ¡ˆ1ï¼šDTWå…è®¸å¼¹æ€§åŒ¹é…
- æ–¹æ¡ˆ2ï¼šTRACLUSåˆ†æ®µåèšç±»
- æ–¹æ¡ˆ3ï¼šæ·±åº¦å­¦ä¹ ç¼–ç ä¸ºå›ºå®šç»´åº¦

---

## ğŸ“§ åç»­æ”¯æŒ

å¦‚éœ€è¿›ä¸€æ­¥è®¨è®ºæˆ–å®ç°ååŠ©ï¼Œè¯·æä¾›ï¼š
1. å…·ä½“çš„ä½¿ç”¨åœºæ™¯ï¼ˆå¦‚äº¤å‰å£åˆ†æã€å¼‚å¸¸æ£€æµ‹ï¼‰
2. æ•°æ®è§„æ¨¡å’Œè´¨é‡
3. æ€§èƒ½è¦æ±‚ï¼ˆå®æ—¶/ç¦»çº¿ï¼‰
4. å¯è§£é‡Šæ€§è¦æ±‚

ç¥èšç±»æ•ˆæœæ”¹å–„ï¼ğŸ‰

